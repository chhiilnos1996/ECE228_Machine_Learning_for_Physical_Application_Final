{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whale Detection Challenge : 2_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method overview : FFT to convert the sound tracks into spectrograms, and apply distinct preprocessing methods such as clipping, noise removal, PCEN and filters. After preprocessing we feed the spectrograms into state of the art light CNN models such as Resnet 18, VGG 16 or GoogleNet to identify right whale call patterns and perform classification. We may also try the removal of pooling layers in the networks and see if it causes better outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.3.1\n",
      "Torchvision Version:  0.4.2\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "feature_extract = True\n",
    "groups = 3\n",
    "vis_batch = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/val_prep_2layers/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-97305b1c136a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Create training and validation datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mimage_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_prep_2layers/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_transforms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;31m# Create training and validation dataloaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mdataloaders_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-97305b1c136a>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Create training and validation datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mimage_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_prep_2layers/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_transforms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;31m# Create training and validation dataloaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mdataloaders_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    207\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                                           \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                                           is_valid_file=is_valid_file)\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m     91\u001b[0m         super(DatasetFolder, self).__init__(root, transform=transform,\n\u001b[1;32m     92\u001b[0m                                             target_transform=target_transform)\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m_find_classes\u001b[0;34m(self, dir)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# Faster and available in Python 3.5 and above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/val_prep_2layers/'"
     ]
    }
   ],
   "source": [
    "data_dir = \"data/\"\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((40,500)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((40,500)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x+\"_prep_2layers/\"), data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=8) for x in ['train', 'val']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 2-layer model\n",
    "class small_model(nn.Module):\n",
    "    # input size 40*500\n",
    "    # image = cv2.resize(image, (40, 500), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "    def __init__(self):\n",
    "        super(small_model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=7, stride=1, padding=(3, 3), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=True)\n",
    "        self.dropout = nn.Dropout2d(p = 0.3)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=7, stride=1, padding=(3, 3), bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(4, 100), stride=(4, 100), padding=0, dilation=1, ceil_mode=True)\n",
    "\n",
    "        self.flat = nn.Flatten()\n",
    "        \n",
    "        self.fc1 = nn.Linear(128, 100)\n",
    "        self.fc2 = nn.Linear(100, 2)\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "#         self.dropout = nn.Dropout2d(p = 0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # CNN 1\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.dropout(self.pool1(x))\n",
    "        \n",
    "        # CNN 2\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.dropout(self.pool2(x))\n",
    "        \n",
    "        # Flatten\n",
    "        x = self.flat(x)\n",
    "        \n",
    "        # Dense\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        # Output\n",
    "        x = self.softmax(self.fc2(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "def initialize_model(num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = small_model()\n",
    "    num_ftrs = model_ft.fc1.out_features\n",
    "    model_ft.fc2 = nn.Linear(num_ftrs, num_classes)\n",
    "    input_size = (40, 500)  \n",
    "    return model_ft, input_size\n",
    "\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training fuction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "    history = {'train_loss':[],'train_acc':[],'val_loss':[],'val_acc':[]}\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0\n",
    "            running_corrects = 0\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'train':\n",
    "                history['train_loss'].append(epoch_loss)\n",
    "                history['train_acc'].append(epoch_acc)\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                history['val_loss'].append(epoch_loss)\n",
    "                history['val_acc'].append(epoch_acc)\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, history, best_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t conv1.weight\n",
      "\t bn1.weight\n",
      "\t bn1.bias\n",
      "\t conv2.weight\n",
      "\t bn2.weight\n",
      "\t bn2.bias\n",
      "\t fc1.weight\n",
      "\t fc1.bias\n",
      "\t fc2.weight\n",
      "\t fc2.bias\n"
     ]
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(params_to_update, lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:40: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4376 Acc: 0.8757\n",
      "val Loss: 0.5472 Acc: 0.7660\n",
      "\n",
      "Epoch 1/99\n",
      "----------\n",
      "train Loss: 0.4375 Acc: 0.8757\n",
      "val Loss: 0.5472 Acc: 0.7660\n",
      "\n",
      "Epoch 2/99\n",
      "----------\n",
      "train Loss: 0.4376 Acc: 0.8757\n",
      "val Loss: 0.5472 Acc: 0.7660\n",
      "\n",
      "Epoch 3/99\n",
      "----------\n",
      "train Loss: 0.4376 Acc: 0.8757\n",
      "val Loss: 0.5472 Acc: 0.7660\n",
      "\n",
      "Epoch 4/99\n",
      "----------\n",
      "train Loss: 0.4375 Acc: 0.8757\n",
      "val Loss: 0.5472 Acc: 0.7660\n",
      "\n",
      "Epoch 5/99\n",
      "----------\n",
      "train Loss: 0.4376 Acc: 0.8757\n",
      "val Loss: 0.5472 Acc: 0.7660\n",
      "\n",
      "Epoch 6/99\n",
      "----------\n",
      "train Loss: 0.4375 Acc: 0.8757\n",
      "val Loss: 0.5472 Acc: 0.7660\n",
      "\n",
      "Epoch 7/99\n",
      "----------\n",
      "train Loss: 0.4377 Acc: 0.8757\n",
      "val Loss: 0.5472 Acc: 0.7660\n",
      "\n",
      "Epoch 8/99\n",
      "----------\n",
      "train Loss: 0.4376 Acc: 0.8757\n",
      "val Loss: 0.5472 Acc: 0.7660\n",
      "\n",
      "Epoch 9/99\n",
      "----------\n",
      "train Loss: 0.4376 Acc: 0.8757\n",
      "val Loss: 0.5472 Acc: 0.7660\n",
      "\n",
      "Epoch 10/99\n",
      "----------\n",
      "train Loss: 0.4375 Acc: 0.8757\n",
      "val Loss: 0.5472 Acc: 0.7660\n",
      "\n",
      "Epoch 11/99\n",
      "----------\n",
      "train Loss: 0.4375 Acc: 0.8757\n",
      "val Loss: 0.5472 Acc: 0.7660\n",
      "\n",
      "Epoch 12/99\n",
      "----------\n",
      "train Loss: 0.4374 Acc: 0.8757\n",
      "val Loss: 0.5472 Acc: 0.7660\n",
      "\n",
      "Epoch 13/99\n",
      "----------\n",
      "train Loss: 0.4375 Acc: 0.8757\n",
      "val Loss: 0.5472 Acc: 0.7660\n",
      "\n",
      "Epoch 14/99\n",
      "----------\n",
      "train Loss: 0.4376 Acc: 0.8757\n",
      "val Loss: 0.5472 Acc: 0.7660\n",
      "\n",
      "Epoch 15/99\n",
      "----------\n",
      "train Loss: 0.4375 Acc: 0.8757\n",
      "val Loss: 0.5472 Acc: 0.7660\n",
      "\n",
      "Epoch 16/99\n",
      "----------\n",
      "train Loss: 0.4374 Acc: 0.8757\n",
      "val Loss: 0.5472 Acc: 0.7660\n",
      "\n",
      "Epoch 17/99\n",
      "----------\n",
      "train Loss: 0.4371 Acc: 0.8757\n",
      "val Loss: 0.5468 Acc: 0.7660\n",
      "\n",
      "Epoch 18/99\n",
      "----------\n",
      "train Loss: 0.4370 Acc: 0.8757\n",
      "val Loss: 0.5448 Acc: 0.7660\n",
      "\n",
      "Epoch 19/99\n",
      "----------\n",
      "train Loss: 0.4280 Acc: 0.8786\n",
      "val Loss: 0.5031 Acc: 0.7793\n",
      "\n",
      "Epoch 20/99\n",
      "----------\n",
      "train Loss: 0.4295 Acc: 0.8815\n",
      "val Loss: 0.4801 Acc: 0.8160\n",
      "\n",
      "Epoch 21/99\n",
      "----------\n",
      "train Loss: 0.4130 Acc: 0.8988\n",
      "val Loss: 0.4674 Acc: 0.8360\n",
      "\n",
      "Epoch 22/99\n",
      "----------\n",
      "train Loss: 0.4077 Acc: 0.9104\n",
      "val Loss: 0.4504 Acc: 0.8630\n",
      "\n",
      "Epoch 23/99\n",
      "----------\n",
      "train Loss: 0.4005 Acc: 0.9220\n",
      "val Loss: 0.4509 Acc: 0.8580\n",
      "\n",
      "Epoch 24/99\n",
      "----------\n",
      "train Loss: 0.4047 Acc: 0.9104\n",
      "val Loss: 0.4454 Acc: 0.8657\n",
      "\n",
      "Epoch 25/99\n",
      "----------\n",
      "train Loss: 0.3907 Acc: 0.9277\n",
      "val Loss: 0.4466 Acc: 0.8630\n",
      "\n",
      "Epoch 26/99\n",
      "----------\n",
      "train Loss: 0.3849 Acc: 0.9306\n",
      "val Loss: 0.4402 Acc: 0.8657\n",
      "\n",
      "Epoch 27/99\n",
      "----------\n",
      "train Loss: 0.3851 Acc: 0.9306\n",
      "val Loss: 0.4415 Acc: 0.8637\n",
      "\n",
      "Epoch 28/99\n",
      "----------\n",
      "train Loss: 0.3721 Acc: 0.9451\n",
      "val Loss: 0.4385 Acc: 0.8687\n",
      "\n",
      "Epoch 29/99\n",
      "----------\n",
      "train Loss: 0.3739 Acc: 0.9451\n",
      "val Loss: 0.4449 Acc: 0.8613\n",
      "\n",
      "Epoch 30/99\n",
      "----------\n",
      "train Loss: 0.3767 Acc: 0.9422\n",
      "val Loss: 0.4413 Acc: 0.8620\n",
      "\n",
      "Epoch 31/99\n",
      "----------\n",
      "train Loss: 0.3724 Acc: 0.9451\n",
      "val Loss: 0.4385 Acc: 0.8667\n",
      "\n",
      "Epoch 32/99\n",
      "----------\n",
      "train Loss: 0.3833 Acc: 0.9191\n",
      "val Loss: 0.4382 Acc: 0.8670\n",
      "\n",
      "Epoch 33/99\n",
      "----------\n",
      "train Loss: 0.3724 Acc: 0.9509\n",
      "val Loss: 0.4378 Acc: 0.8697\n",
      "\n",
      "Epoch 34/99\n",
      "----------\n",
      "train Loss: 0.3759 Acc: 0.9335\n",
      "val Loss: 0.4393 Acc: 0.8647\n",
      "\n",
      "Epoch 35/99\n",
      "----------\n",
      "train Loss: 0.3731 Acc: 0.9422\n",
      "val Loss: 0.4379 Acc: 0.8690\n",
      "\n",
      "Epoch 36/99\n",
      "----------\n",
      "train Loss: 0.3673 Acc: 0.9480\n",
      "val Loss: 0.4378 Acc: 0.8680\n",
      "\n",
      "Epoch 37/99\n",
      "----------\n",
      "train Loss: 0.3612 Acc: 0.9566\n",
      "val Loss: 0.4371 Acc: 0.8717\n",
      "\n",
      "Epoch 38/99\n",
      "----------\n",
      "train Loss: 0.3593 Acc: 0.9595\n",
      "val Loss: 0.4363 Acc: 0.8707\n",
      "\n",
      "Epoch 39/99\n",
      "----------\n",
      "train Loss: 0.3477 Acc: 0.9740\n",
      "val Loss: 0.4358 Acc: 0.8700\n",
      "\n",
      "Epoch 40/99\n",
      "----------\n",
      "train Loss: 0.3782 Acc: 0.9335\n",
      "val Loss: 0.4354 Acc: 0.8710\n",
      "\n",
      "Epoch 41/99\n",
      "----------\n",
      "train Loss: 0.3680 Acc: 0.9422\n",
      "val Loss: 0.4363 Acc: 0.8693\n",
      "\n",
      "Epoch 42/99\n",
      "----------\n",
      "train Loss: 0.3639 Acc: 0.9509\n",
      "val Loss: 0.4359 Acc: 0.8713\n",
      "\n",
      "Epoch 43/99\n",
      "----------\n",
      "train Loss: 0.3563 Acc: 0.9624\n",
      "val Loss: 0.4356 Acc: 0.8710\n",
      "\n",
      "Epoch 44/99\n",
      "----------\n",
      "train Loss: 0.3568 Acc: 0.9653\n",
      "val Loss: 0.4364 Acc: 0.8720\n",
      "\n",
      "Epoch 45/99\n",
      "----------\n",
      "train Loss: 0.3515 Acc: 0.9682\n",
      "val Loss: 0.4362 Acc: 0.8707\n",
      "\n",
      "Epoch 46/99\n",
      "----------\n",
      "train Loss: 0.3569 Acc: 0.9624\n",
      "val Loss: 0.4360 Acc: 0.8697\n",
      "\n",
      "Epoch 47/99\n",
      "----------\n",
      "train Loss: 0.3484 Acc: 0.9711\n",
      "val Loss: 0.4366 Acc: 0.8710\n",
      "\n",
      "Epoch 48/99\n",
      "----------\n",
      "train Loss: 0.3681 Acc: 0.9393\n",
      "val Loss: 0.4360 Acc: 0.8723\n",
      "\n",
      "Epoch 49/99\n",
      "----------\n",
      "train Loss: 0.3494 Acc: 0.9711\n",
      "val Loss: 0.4357 Acc: 0.8733\n",
      "\n",
      "Epoch 50/99\n",
      "----------\n",
      "train Loss: 0.3440 Acc: 0.9711\n",
      "val Loss: 0.4362 Acc: 0.8697\n",
      "\n",
      "Epoch 51/99\n",
      "----------\n",
      "train Loss: 0.3514 Acc: 0.9595\n",
      "val Loss: 0.4359 Acc: 0.8713\n",
      "\n",
      "Epoch 52/99\n",
      "----------\n",
      "train Loss: 0.3465 Acc: 0.9682\n",
      "val Loss: 0.4365 Acc: 0.8707\n",
      "\n",
      "Epoch 53/99\n",
      "----------\n",
      "train Loss: 0.3620 Acc: 0.9566\n",
      "val Loss: 0.4367 Acc: 0.8707\n",
      "\n",
      "Epoch 54/99\n",
      "----------\n",
      "train Loss: 0.3378 Acc: 0.9827\n",
      "val Loss: 0.4365 Acc: 0.8710\n",
      "\n",
      "Epoch 55/99\n",
      "----------\n",
      "train Loss: 0.3514 Acc: 0.9624\n",
      "val Loss: 0.4370 Acc: 0.8713\n",
      "\n",
      "Epoch 56/99\n",
      "----------\n",
      "train Loss: 0.3468 Acc: 0.9682\n",
      "val Loss: 0.4356 Acc: 0.8717\n",
      "\n",
      "Epoch 57/99\n",
      "----------\n",
      "train Loss: 0.3457 Acc: 0.9740\n",
      "val Loss: 0.4352 Acc: 0.8717\n",
      "\n",
      "Epoch 58/99\n",
      "----------\n",
      "train Loss: 0.3494 Acc: 0.9682\n",
      "val Loss: 0.4350 Acc: 0.8723\n",
      "\n",
      "Epoch 59/99\n",
      "----------\n",
      "train Loss: 0.3454 Acc: 0.9653\n",
      "val Loss: 0.4359 Acc: 0.8717\n",
      "\n",
      "Epoch 60/99\n",
      "----------\n",
      "train Loss: 0.3388 Acc: 0.9827\n",
      "val Loss: 0.4367 Acc: 0.8707\n",
      "\n",
      "Epoch 61/99\n",
      "----------\n",
      "train Loss: 0.3420 Acc: 0.9711\n",
      "val Loss: 0.4361 Acc: 0.8710\n",
      "\n",
      "Epoch 62/99\n",
      "----------\n",
      "train Loss: 0.3338 Acc: 0.9855\n",
      "val Loss: 0.4358 Acc: 0.8710\n",
      "\n",
      "Epoch 63/99\n",
      "----------\n",
      "train Loss: 0.3385 Acc: 0.9769\n",
      "val Loss: 0.4354 Acc: 0.8740\n",
      "\n",
      "Epoch 64/99\n",
      "----------\n",
      "train Loss: 0.3463 Acc: 0.9682\n",
      "val Loss: 0.4348 Acc: 0.8740\n",
      "\n",
      "Epoch 65/99\n",
      "----------\n",
      "train Loss: 0.3382 Acc: 0.9769\n",
      "val Loss: 0.4353 Acc: 0.8727\n",
      "\n",
      "Epoch 66/99\n",
      "----------\n",
      "train Loss: 0.3337 Acc: 0.9855\n",
      "val Loss: 0.4363 Acc: 0.8710\n",
      "\n",
      "Epoch 67/99\n",
      "----------\n",
      "train Loss: 0.3369 Acc: 0.9827\n",
      "val Loss: 0.4348 Acc: 0.8723\n",
      "\n",
      "Epoch 68/99\n",
      "----------\n",
      "train Loss: 0.3341 Acc: 0.9798\n",
      "val Loss: 0.4354 Acc: 0.8730\n",
      "\n",
      "Epoch 69/99\n",
      "----------\n",
      "train Loss: 0.3468 Acc: 0.9566\n",
      "val Loss: 0.4361 Acc: 0.8730\n",
      "\n",
      "Epoch 70/99\n",
      "----------\n",
      "train Loss: 0.3290 Acc: 0.9855\n",
      "val Loss: 0.4354 Acc: 0.8713\n",
      "\n",
      "Epoch 71/99\n",
      "----------\n",
      "train Loss: 0.3362 Acc: 0.9798\n",
      "val Loss: 0.4362 Acc: 0.8723\n",
      "\n",
      "Epoch 72/99\n",
      "----------\n",
      "train Loss: 0.3320 Acc: 0.9798\n",
      "val Loss: 0.4352 Acc: 0.8730\n",
      "\n",
      "Epoch 73/99\n",
      "----------\n",
      "train Loss: 0.3301 Acc: 0.9827\n",
      "val Loss: 0.4349 Acc: 0.8757\n",
      "\n",
      "Epoch 74/99\n",
      "----------\n",
      "train Loss: 0.3284 Acc: 0.9913\n",
      "val Loss: 0.4349 Acc: 0.8740\n",
      "\n",
      "Epoch 75/99\n",
      "----------\n",
      "train Loss: 0.3331 Acc: 0.9827\n",
      "val Loss: 0.4343 Acc: 0.8733\n",
      "\n",
      "Epoch 76/99\n",
      "----------\n",
      "train Loss: 0.3328 Acc: 0.9798\n",
      "val Loss: 0.4358 Acc: 0.8707\n",
      "\n",
      "Epoch 77/99\n",
      "----------\n",
      "train Loss: 0.3399 Acc: 0.9711\n",
      "val Loss: 0.4365 Acc: 0.8710\n",
      "\n",
      "Epoch 78/99\n",
      "----------\n",
      "train Loss: 0.3365 Acc: 0.9769\n",
      "val Loss: 0.4344 Acc: 0.8740\n",
      "\n",
      "Epoch 79/99\n",
      "----------\n",
      "train Loss: 0.3323 Acc: 0.9884\n",
      "val Loss: 0.4353 Acc: 0.8717\n",
      "\n",
      "Epoch 80/99\n",
      "----------\n",
      "train Loss: 0.3362 Acc: 0.9798\n",
      "val Loss: 0.4360 Acc: 0.8717\n",
      "\n",
      "Epoch 81/99\n",
      "----------\n",
      "train Loss: 0.3316 Acc: 0.9798\n",
      "val Loss: 0.4369 Acc: 0.8723\n",
      "\n",
      "Epoch 82/99\n",
      "----------\n",
      "train Loss: 0.3368 Acc: 0.9740\n",
      "val Loss: 0.4353 Acc: 0.8730\n",
      "\n",
      "Epoch 83/99\n",
      "----------\n",
      "train Loss: 0.3275 Acc: 0.9884\n",
      "val Loss: 0.4355 Acc: 0.8713\n",
      "\n",
      "Epoch 84/99\n",
      "----------\n",
      "train Loss: 0.3317 Acc: 0.9855\n",
      "val Loss: 0.4357 Acc: 0.8720\n",
      "\n",
      "Epoch 85/99\n",
      "----------\n",
      "train Loss: 0.3262 Acc: 0.9884\n",
      "val Loss: 0.4349 Acc: 0.8743\n",
      "\n",
      "Epoch 86/99\n",
      "----------\n",
      "train Loss: 0.3321 Acc: 0.9855\n",
      "val Loss: 0.4352 Acc: 0.8723\n",
      "\n",
      "Epoch 87/99\n",
      "----------\n",
      "train Loss: 0.3262 Acc: 0.9942\n",
      "val Loss: 0.4357 Acc: 0.8707\n",
      "\n",
      "Epoch 88/99\n",
      "----------\n",
      "train Loss: 0.3265 Acc: 0.9884\n",
      "val Loss: 0.4350 Acc: 0.8737\n",
      "\n",
      "Epoch 89/99\n",
      "----------\n",
      "train Loss: 0.3354 Acc: 0.9798\n",
      "val Loss: 0.4362 Acc: 0.8703\n",
      "\n",
      "Epoch 90/99\n",
      "----------\n",
      "train Loss: 0.3244 Acc: 0.9913\n",
      "val Loss: 0.4352 Acc: 0.8747\n",
      "\n",
      "Epoch 91/99\n",
      "----------\n",
      "train Loss: 0.3274 Acc: 0.9884\n",
      "val Loss: 0.4353 Acc: 0.8733\n",
      "\n",
      "Epoch 92/99\n",
      "----------\n",
      "train Loss: 0.3311 Acc: 0.9855\n",
      "val Loss: 0.4354 Acc: 0.8737\n",
      "\n",
      "Epoch 93/99\n",
      "----------\n",
      "train Loss: 0.3297 Acc: 0.9855\n",
      "val Loss: 0.4354 Acc: 0.8727\n",
      "\n",
      "Epoch 94/99\n",
      "----------\n",
      "train Loss: 0.3266 Acc: 0.9884\n",
      "val Loss: 0.4349 Acc: 0.8730\n",
      "\n",
      "Epoch 95/99\n",
      "----------\n",
      "train Loss: 0.3241 Acc: 0.9884\n",
      "val Loss: 0.4345 Acc: 0.8730\n",
      "\n",
      "Epoch 96/99\n",
      "----------\n",
      "train Loss: 0.3321 Acc: 0.9827\n",
      "val Loss: 0.4347 Acc: 0.8753\n",
      "\n",
      "Epoch 97/99\n",
      "----------\n",
      "train Loss: 0.3263 Acc: 0.9884\n",
      "val Loss: 0.4343 Acc: 0.8740\n",
      "\n",
      "Epoch 98/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3241 Acc: 0.9913\n",
      "val Loss: 0.4349 Acc: 0.8757\n",
      "\n",
      "Epoch 99/99\n",
      "----------\n",
      "train Loss: 0.3222 Acc: 0.9913\n",
      "val Loss: 0.4350 Acc: 0.8757\n",
      "\n",
      "Training complete in 4m 58s\n",
      "Best val Acc: 0.875667\n",
      "odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'conv2.weight', 'bn2.weight', 'bn2.bias', 'bn2.running_mean', 'bn2.running_var', 'bn2.num_batches_tracked', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias'])\n"
     ]
    }
   ],
   "source": [
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist, best_acc = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs)\n",
    "torch.save(model_ft.state_dict(), 'model_weight/2_layer_model_'+str(num_epochs))\n",
    "print(model_ft.state_dict().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train_loss', 'train_acc', 'val_loss', 'val_acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8757, device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(hist.keys())\n",
    "\n",
    "#### Fill in plot #####\n",
    "#Plot accuracy vs epoch\n",
    "plt.subplot(211)\n",
    "\n",
    "plt.plot(hist['train_acc'])\n",
    "plt.plot(hist['val_acc'])\n",
    "plt.title('accuracy : 2_layer_model')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "#Plot loss vs epoch\n",
    "plt.subplot(212)\n",
    "plt.plot(hist['train_loss'])\n",
    "plt.plot(hist['val_loss'])\n",
    "plt.title('loss : 2_layer_model')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "print(best_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load model and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'conv2.weight', 'bn2.weight', 'bn2.bias', 'bn2.running_mean', 'bn2.running_var', 'bn2.num_batches_tracked', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias'])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for GoogLeNet:\n\tMissing key(s) in state_dict: \"conv1.conv.weight\", \"conv1.bn.weight\", \"conv1.bn.bias\", \"conv1.bn.running_mean\", \"conv1.bn.running_var\", \"conv2.conv.weight\", \"conv2.bn.weight\", \"conv2.bn.bias\", \"conv2.bn.running_mean\", \"conv2.bn.running_var\", \"conv3.conv.weight\", \"conv3.bn.weight\", \"conv3.bn.bias\", \"conv3.bn.running_mean\", \"conv3.bn.running_var\", \"inception3a.branch1.conv.weight\", \"inception3a.branch1.bn.weight\", \"inception3a.branch1.bn.bias\", \"inception3a.branch1.bn.running_mean\", \"inception3a.branch1.bn.running_var\", \"inception3a.branch2.0.conv.weight\", \"inception3a.branch2.0.bn.weight\", \"inception3a.branch2.0.bn.bias\", \"inception3a.branch2.0.bn.running_mean\", \"inception3a.branch2.0.bn.running_var\", \"inception3a.branch2.1.conv.weight\", \"inception3a.branch2.1.bn.weight\", \"inception3a.branch2.1.bn.bias\", \"inception3a.branch2.1.bn.running_mean\", \"inception3a.branch2.1.bn.running_var\", \"inception3a.branch3.0.conv.weight\", \"inception3a.branch3.0.bn.weight\", \"inception3a.branch3.0.bn.bias\", \"inception3a.branch3.0.bn.running_mean\", \"inception3a.branch3.0.bn.running_var\", \"inception3a.branch3.1.conv.weight\", \"inception3a.branch3.1.bn.weight\", \"inception3a.branch3.1.bn.bias\", \"inception3a.branch3.1.bn.running_mean\", \"inception3a.branch3.1.bn.running_var\", \"inception3a.branch4.1.conv.weight\", \"inception3a.branch4.1.bn.weight\", \"inception3a.branch4.1.bn.bias\", \"inception3a.branch4.1.bn.running_mean\", \"inception3a.branch4.1.bn.running_var\", \"inception3b.branch1.conv.weight\", \"inception3b.branch1.bn.weight\", \"inception3b.branch1.bn.bias\", \"inception3b.branch1.bn.running_mean\", \"inception3b.branch1.bn.running_var\", \"inception3b.branch2.0.conv.weight\", \"inception3b.branch2.0.bn.weight\", \"inception3b.branch2.0.bn.bias\", \"inception3b.branch2.0.bn.running_mean\", \"inception3b.branch2.0.bn.running_var\", \"inception3b.branch2.1.conv.weight\", \"inception3b.branch2.1.bn.weight\", \"inception3b.branch2.1.bn.bias\", \"inception3b.branch2.1.bn.running_mean\", \"inception3b.branch2.1.bn.running_var\", \"inception3b.branch3.0.conv.weight\", \"inception3b.branch3.0.bn.weight\", \"inception3b.branch3.0.bn.bias\", \"inception3b.branch3.0.bn.running_mean\", \"inception3b.branch3.0.bn.running_var\", \"inception3b.branch3.1.conv.weight\", \"inception3b.branch3.1.bn.weight\", \"inception3b.branch3.1.bn.bias\", \"inception3b.branch3.1.bn.running_mean\", \"inception3b.branch3.1.bn.running_var\", \"inception3b.branch4.1.conv.weight\", \"inception3b.branch4.1.bn.weight\", \"inception3b.branch4.1.bn.bias\", \"inception3b.branch4.1.bn.running_mean\", \"inception3b.branch4.1.bn.running_var\", \"inception4a.branch1.conv.weight\", \"inception4a.branch1.bn.weight\", \"inception4a.branch1.bn.bias\", \"inception4a.branch1.bn.running_mean\", \"inception4a.branch1.bn.running_var\", \"inception4a.branch2.0.conv.weight\", \"inception4a.branch2.0.bn.weight\", \"inception4a.branch2.0.bn.bias\", \"inception4a.branch2.0.bn.running_mean\", \"inception4a.branch2.0.bn.running_var\", \"inception4a.branch2.1.conv.weight\", \"inception4a.branch2.1.bn.weight\", \"inception4a.branch2.1.bn.bias\", \"inception4a.branch2.1.bn.running_mean\", \"inception4a.branch2.1.bn.running_var\", \"inception4a.branch3.0.conv.weight\", \"inception4a.branch3.0.bn.weight\", \"inception4a.branch3.0.bn.bias\", \"inception4a.branch3.0.bn.running_mean\", \"inception4a.branch3.0.bn.running_var\", \"inception4a.branch3.1.conv.weight\", \"inception4a.branch3.1.bn.weight\", \"inception4a.branch3.1.bn.bias\", \"inception4a.branch3.1.bn.running_mean\", \"inception4a.branch3.1.bn.running_var\", \"inception4a.branch4.1.conv.weight\", \"inception4a.branch4.1.bn.weight\", \"inception4a.branch4.1.bn.bias\", \"inception4a.branch4.1.bn.running_mean\", \"inception4a.branch4.1.bn.running_var\", \"inception4b.branch1.conv.weight\", \"inception4b.branch1.bn.weight\", \"inception4b.branch1.bn.bias\", \"inception4b.branch1.bn.running_mean\", \"inception4b.branch1.bn.running_var\", \"inception4b.branch2.0.conv.weight\", \"inception4b.branch2.0.bn.weight\", \"inception4b.branch2.0.bn.bias\", \"inception4b.branch2.0.bn.running_mean\", \"inception4b.branch2.0.bn.running_var\", \"inception4b.branch2.1.conv.weight\", \"inception4b.branch2.1.bn.weight\", \"inception4b.branch2.1.bn.bias\", \"inception4b.branch2.1.bn.running_mean\", \"inception4b.branch2.1.bn.running_var\", \"inception4b.branch3.0.conv.weight\", \"inception4b.branch3.0.bn.weight\", \"inception4b.branch3.0.bn.bias\", \"inception4b.branch3.0.bn.running_mean\", \"inception4b.branch3.0.bn.running_var\", \"inception4b.branch3.1.conv.weight\", \"inception4b.branch3.1.bn.weight\", \"inception4b.branch3.1.bn.bias\", \"inception4b.branch3.1.bn.running_mean\", \"inception4b.branch3.1.bn.running_var\", \"inception4b.branch4.1.conv.weight\", \"inception4b.branch4.1.bn.weight\", \"inception4b.branch4.1.bn.bias\", \"inception4b.branch4.1.bn.running_mean\", \"inception4b.branch4.1.bn.running_var\", \"inception4c.branch1.conv.weight\", \"inception4c.branch1.bn.weight\", \"inception4c.branch1.bn.bias\", \"inception4c.branch1.bn.running_mean\", \"inception4c.branch1.bn.running_var\", \"inception4c.branch2.0.conv.weight\", \"inception4c.branch2.0.bn.weight\", \"inception4c.branch2.0.bn.bias\", \"inception4c.branch2.0.bn.running_mean\", \"inception4c.branch2.0.bn.running_var\", \"inception4c.branch2.1.conv.weight\", \"inception4c.branch2.1.bn.weight\", \"inception4c.branch2.1.bn.bias\", \"inception4c.branch2.1.bn.running_mean\", \"inception4c.branch2.1.bn.running_var\", \"inception4c.branch3.0.conv.weight\", \"inception4c.branch3.0.bn.weight\", \"inception4c.branch3.0.bn.bias\", \"inception4c.branch3.0.bn.running_mean\", \"inception4c.branch3.0.bn.running_var\", \"inception4c.branch3.1.conv.weight\", \"inception4c.branch3.1.bn.weight\", \"inception4c.branch3.1.bn.bias\", \"inception4c.branch3.1.bn.running_mean\", \"inception4c.branch3.1.bn.running_var\", \"inception4c.branch4.1.conv.weight\", \"inception4c.branch4.1.bn.weight\", \"inception4c.branch4.1.bn.bias\", \"inception4c.branch4.1.bn.running_mean\", \"inception4c.branch4.1.bn.running_var\", \"inception4d.branch1.conv.weight\", \"inception4d.branch1.bn.weight\", \"inception4d.branch1.bn.bias\", \"inception4d.branch1.bn.running_mean\", \"inception4d.branch1.bn.running_var\", \"inception4d.branch2.0.conv.weight\", \"inception4d.branch2.0.bn.weight\", \"inception4d.branch2.0.bn.bias\", \"inception4d.branch2.0.bn.running_mean\", \"inception4d.branch2.0.bn.running_var\", \"inception4d.branch2.1.conv.weight\", \"inception4d.branch2.1.bn.weight\", \"inception4d.branch2.1.bn.bias\", \"inception4d.branch2.1.bn.running_mean\", \"inception4d.branch2.1.bn.running_var\", \"inception4d.branch3.0.conv.weight\", \"inception4d.branch3.0.bn.weight\", \"inception4d.branch3.0.bn.bias\", \"inception4d.branch3.0.bn.running_mean\", \"inception4d.branch3.0.bn.running_var\", \"inception4d.branch3.1.conv.weight\", \"inception4d.branch3.1.bn.weight\", \"inception4d.branch3.1.bn.bias\", \"inception4d.branch3.1.bn.running_mean\", \"inception4d.branch3.1.bn.running_var\", \"inception4d.branch4.1.conv.weight\", \"inception4d.branch4.1.bn.weight\", \"inception4d.branch4.1.bn.bias\", \"inception4d.branch4.1.bn.running_mean\", \"inception4d.branch4.1.bn.running_var\", \"inception4e.branch1.conv.weight\", \"inception4e.branch1.bn.weight\", \"inception4e.branch1.bn.bias\", \"inception4e.branch1.bn.running_mean\", \"inception4e.branch1.bn.running_var\", \"inception4e.branch2.0.conv.weight\", \"inception4e.branch2.0.bn.weight\", \"inception4e.branch2.0.bn.bias\", \"inception4e.branch2.0.bn.running_mean\", \"inception4e.branch2.0.bn.running_var\", \"inception4e.branch2.1.conv.weight\", \"inception4e.branch2.1.bn.weight\", \"inception4e.branch2.1.bn.bias\", \"inception4e.branch2.1.bn.running_mean\", \"inception4e.branch2.1.bn.running_var\", \"inception4e.branch3.0.conv.weight\", \"inception4e.branch3.0.bn.weight\", \"inception4e.branch3.0.bn.bias\", \"inception4e.branch3.0.bn.running_mean\", \"inception4e.branch3.0.bn.running_var\", \"inception4e.branch3.1.conv.weight\", \"inception4e.branch3.1.bn.weight\", \"inception4e.branch3.1.bn.bias\", \"inception4e.branch3.1.bn.running_mean\", \"inception4e.branch3.1.bn.running_var\", \"inception4e.branch4.1.conv.weight\", \"inception4e.branch4.1.bn.weight\", \"inception4e.branch4.1.bn.bias\", \"inception4e.branch4.1.bn.running_mean\", \"inception4e.branch4.1.bn.running_var\", \"inception5a.branch1.conv.weight\", \"inception5a.branch1.bn.weight\", \"inception5a.branch1.bn.bias\", \"inception5a.branch1.bn.running_mean\", \"inception5a.branch1.bn.running_var\", \"inception5a.branch2.0.conv.weight\", \"inception5a.branch2.0.bn.weight\", \"inception5a.branch2.0.bn.bias\", \"inception5a.branch2.0.bn.running_mean\", \"inception5a.branch2.0.bn.running_var\", \"inception5a.branch2.1.conv.weight\", \"inception5a.branch2.1.bn.weight\", \"inception5a.branch2.1.bn.bias\", \"inception5a.branch2.1.bn.running_mean\", \"inception5a.branch2.1.bn.running_var\", \"inception5a.branch3.0.conv.weight\", \"inception5a.branch3.0.bn.weight\", \"inception5a.branch3.0.bn.bias\", \"inception5a.branch3.0.bn.running_mean\", \"inception5a.branch3.0.bn.running_var\", \"inception5a.branch3.1.conv.weight\", \"inception5a.branch3.1.bn.weight\", \"inception5a.branch3.1.bn.bias\", \"inception5a.branch3.1.bn.running_mean\", \"inception5a.branch3.1.bn.running_var\", \"inception5a.branch4.1.conv.weight\", \"inception5a.branch4.1.bn.weight\", \"inception5a.branch4.1.bn.bias\", \"inception5a.branch4.1.bn.running_mean\", \"inception5a.branch4.1.bn.running_var\", \"inception5b.branch1.conv.weight\", \"inception5b.branch1.bn.weight\", \"inception5b.branch1.bn.bias\", \"inception5b.branch1.bn.running_mean\", \"inception5b.branch1.bn.running_var\", \"inception5b.branch2.0.conv.weight\", \"inception5b.branch2.0.bn.weight\", \"inception5b.branch2.0.bn.bias\", \"inception5b.branch2.0.bn.running_mean\", \"inception5b.branch2.0.bn.running_var\", \"inception5b.branch2.1.conv.weight\", \"inception5b.branch2.1.bn.weight\", \"inception5b.branch2.1.bn.bias\", \"inception5b.branch2.1.bn.running_mean\", \"inception5b.branch2.1.bn.running_var\", \"inception5b.branch3.0.conv.weight\", \"inception5b.branch3.0.bn.weight\", \"inception5b.branch3.0.bn.bias\", \"inception5b.branch3.0.bn.running_mean\", \"inception5b.branch3.0.bn.running_var\", \"inception5b.branch3.1.conv.weight\", \"inception5b.branch3.1.bn.weight\", \"inception5b.branch3.1.bn.bias\", \"inception5b.branch3.1.bn.running_mean\", \"inception5b.branch3.1.bn.running_var\", \"inception5b.branch4.1.conv.weight\", \"inception5b.branch4.1.bn.weight\", \"inception5b.branch4.1.bn.bias\", \"inception5b.branch4.1.bn.running_mean\", \"inception5b.branch4.1.bn.running_var\", \"fc.weight\", \"fc.bias\". \n\tUnexpected key(s) in state_dict: \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"bn1.num_batches_tracked\", \"bn2.weight\", \"bn2.bias\", \"bn2.running_mean\", \"bn2.running_var\", \"bn2.num_batches_tracked\", \"fc1.weight\", \"fc1.bias\", \"fc2.weight\", \"fc2.bias\", \"conv1.weight\", \"conv2.weight\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-9fb5e044317e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mvis_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvis_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mvis_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_vis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvis_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvis_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvis_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'outputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-9fb5e044317e>\u001b[0m in \u001b[0;36mforward_vis\u001b[0;34m(vis_loader, groups)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_weight/2_layer_model_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_weight/2_layer_model_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# Set model to evaluate mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 839\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    840\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for GoogLeNet:\n\tMissing key(s) in state_dict: \"conv1.conv.weight\", \"conv1.bn.weight\", \"conv1.bn.bias\", \"conv1.bn.running_mean\", \"conv1.bn.running_var\", \"conv2.conv.weight\", \"conv2.bn.weight\", \"conv2.bn.bias\", \"conv2.bn.running_mean\", \"conv2.bn.running_var\", \"conv3.conv.weight\", \"conv3.bn.weight\", \"conv3.bn.bias\", \"conv3.bn.running_mean\", \"conv3.bn.running_var\", \"inception3a.branch1.conv.weight\", \"inception3a.branch1.bn.weight\", \"inception3a.branch1.bn.bias\", \"inception3a.branch1.bn.running_mean\", \"inception3a.branch1.bn.running_var\", \"inception3a.branch2.0.conv.weight\", \"inception3a.branch2.0.bn.weight\", \"inception3a.branch2.0.bn.bias\", \"inception3a.branch2.0.bn.running_mean\", \"inception3a.branch2.0.bn.running_var\", \"inception3a.branch2.1.conv.weight\", \"inception3a.branch2.1.bn.weight\", \"inception3a.branch2.1.bn.bias\", \"inception3a.branch2.1.bn.running_mean\", \"inception3a.branch2.1.bn.running_var\", \"inception3a.branch3.0.conv.weight\", \"inception3a.branch3.0.bn.weight\", \"inception3a.branch3.0.bn.bias\", \"inception3a.branch3.0.bn.running_mean\", \"inception3a.branch3.0.bn.running_var\", \"inception3a.branch3.1.conv.weight\", \"inception3a.branch3.1.bn.weight\", \"inception3a.branch3.1.bn.bias\", \"inception3a.branch3.1.bn.running_mean\", \"inception3a.branch3.1.bn.running_var\", \"inception3a.branch4.1.conv.weight\", \"inception3a.branch4.1.bn.weight\", \"inception3a.branch4.1.bn.bias\", \"inception3a.branch4.1.bn.running_mean\", \"inception3a.branch4.1.bn.running_var\", \"inception3b.branch1.conv.weight\", \"inception3b.branch1.bn.weight\", \"inception3b.branch1.bn.bias\", \"inception3b.branch1.bn.running_mean\", \"inception3b.branch1.bn.running_var\", \"inception3b.branch2.0.conv.weight\", \"inception3b.branch2.0.bn.weight\", \"inception3b.branch2.0.bn.bias\", \"inception3b.branch2.0.bn.running_mean\", \"inception3b.branch2.0.bn.running_var\", \"inception3b.branch2.1.conv.weight\", \"inception3b.branch2.1.bn.weight\", \"inception3b.branch2.1.bn.bias\", \"inception3b.branch2.1.bn.running_mean\", \"inception3b.branch2.1.bn.running_var\", \"inception3b.branch3.0.conv.weight\", \"inception3b.branch3.0.bn.weight\", \"inception3b.branch3.0.bn.bias\", \"inception3b.branch3.0.bn.running_mean\", \"inception3b.branch3.0.bn.running_var\", \"inception3b.branch3.1.conv.weight\", \"inception3b.branch3.1.bn.weight\", \"inception3b.branch3.1.bn.bias\", \"inception3b.branch3.1.bn.running_mean\", \"inception3b.branch3.1.bn.running_var\", \"inception3b.branch4.1.conv.weight\", \"inception3b.branch4.1.bn.weight\", \"inception3b.branch4.1.bn.bias\", \"inception3b.branch4.1.bn.running_mean\", \"inception3b.branch4.1.bn.running_var\", \"inception4a.branch1.conv.weight\", \"inception4a.branch1.bn.weight\", \"inception4a.branch1.bn.bias\", \"inception4a.branch1.bn.running_mean\", \"inception4a.branch1.bn.running_var\", \"inception4a.branch2.0.conv.weight\", \"inception4a.branch2.0.bn.weight\", \"inception4a.branch2.0.bn.bias\", \"inception4a.branch2.0.bn.running_mean\", \"inception4a.branch2.0.bn.running_var\", \"inception4a.branch2.1.conv.weight\", \"inception4a.branch2.1.bn.weight\", \"inception4a.branch2.1.bn.bias\", \"inception4a.branch2.1.bn.running_mean\", \"inception4a.branch2.1.bn.running_var\", \"inception4a.branch3.0.conv.weight\", \"inception4a.branch3.0.bn.weight\", \"inception4a.branch3.0.bn.bias\", \"inception4a.branch3.0.bn.running_mean\", \"inception4a.branch3.0.bn.running_var\", \"inception4a.branch3.1.conv.weight\", \"inception4a.branch3.1.bn.weight\", \"inception4a.branch3.1.bn.bias\", \"inception4a.branch3.1.bn.running_mean\", \"inception4a.branch3.1.bn.running_var\", \"inception4a.branch4.1.conv.weight\", \"inception4a.branch4.1.bn.weight\", \"inception4a.branch4.1.bn.bias\", \"inception4a.branch4.1.bn.running_mean\", \"inception4a.branch4.1.bn.running_var\", \"inception4b.branch1.conv.weight\", \"inception4b.branch1.bn.weight\", \"inception4b.branch1.bn.bias\", \"inception4b.branch1.bn.running_mean\", \"inception4b.branch1.bn.running_var\", \"inception4b.branch2.0.conv.weight\", \"inception4b.branch2.0.bn.weight\", \"inception4b.branch2.0.bn.bias\", \"inception4b.branch2.0.bn.running_mean\", \"inception4b.branch2.0.bn.running_var\", \"inception4b.branch2.1.conv.weight\", \"inception4b.branch2.1.bn.weight\", \"inception4b.branch2.1.bn.bias\", \"inception4b.branch2.1.bn.running_mean\", \"inception4b.branch2.1.bn.running_var\", \"inception4b.branch3.0.conv.weight\", \"inception4b.branch3.0.bn.weight\", \"inception4b.branch3.0.bn.bias\", \"inception4b.branch3.0.bn.running_mean\", \"inception4b.branch3.0.bn.running_var\", \"inception4b.branch3.1.conv.weight\", \"inception4b.branch3.1.bn.weight\", \"inception4b.branch3.1.bn.bias\", \"inception4b.branch3.1.bn.running_mean\", \"inception4b.branch3.1.bn.running_var\", \"inception4b.branch4.1.conv.weight\", \"inception4b.branch4.1.bn.weight\", \"inception4b.branch4.1.bn.bias\", \"inception4b.branch4.1.bn.running_mean\", \"inception4b.branch4.1.bn.running_var\", \"inception4c.branch1.conv.weight\", \"inception4c.branch1.bn.weight\", \"inception4c.branch1.bn.bias\", \"inception4c.branch1.bn.running_mean\", \"inception4c.branch1.bn.running_var\", \"inception4c.branch2.0.conv.weight\", \"inception4c.branch2.0.bn.weight\", \"inception4c.branch2.0.bn.bias\", \"inception4c.branch2.0.bn.running_mean\", \"inception4c.branch2.0.bn.running_var\", \"inception4c.branch2.1.conv.weight\", \"inception4c.branch2.1.bn.weight\", \"inception4c.branch2.1.bn.bias\", \"inception4c.branch2.1.bn.running_mean\", \"inception4c.branch2.1.bn.running_var\", \"inception4c.branch3.0.conv.weight\", \"inception4c.branch3.0.bn.weight\", \"inception4c.branch3.0.bn.bias\", \"inception4c.branch3.0.bn.running_mean\", \"inception4c.branch3.0.bn.running_var\", \"inception4c.branch3.1.conv.weight\", \"inception4c.branch3.1.bn.weight\", \"inception4c.branch3.1.bn.bias\", \"inception4c.branch3.1.bn.running_mean\", \"inception4c.branch3.1.bn.running_var\", \"inception4c.branch4.1.conv.weight\", \"inception4c.branch4.1.bn.weight\", \"inception4c.branch4.1.bn.bias\", \"inception4c.branch4.1.bn.running_mean\", \"inception4c.branch4.1.bn.running_var\", \"inception4d.branch1.conv.weight\", \"inception4d.branch1.bn.weight\", \"inception4d.branch1.bn.bias\", \"inception4d.branch1.bn.running_mean\", \"inception4d.branch1.bn.running_var\", \"inception4d.branch2.0.conv.weight\", \"inception4d.branch2.0.bn.weight\", \"inception4d.branch2.0.bn.bias\", \"inception4d.branch2.0.bn.running_mean\", \"inception4d.branch2.0.bn.running_var\", \"inception4d.branch2.1.conv.weight\", \"inception4d.branch2.1.bn.weight\", \"inception4d.branch2.1.bn.bias\", \"inception4d.branch2.1.bn.running_mean\", \"inception4d.branch2.1.bn.running_var\", \"inception4d.branch3.0.conv.weight\", \"inception4d.branch3.0.bn.weight\", \"inception4d.branch3.0.bn.bias\", \"inception4d.branch3.0.bn.running_mean\", \"inception4d.branch3.0.bn.running_var\", \"inception4d.branch3.1.conv.weight\", \"inception4d.branch3.1.bn.weight\", \"inception4d.branch3.1.bn.bias\", \"inception4d.branch3.1.bn.running_mean\", \"inception4d.branch3.1.bn.running_var\", \"inception4d.branch4.1.conv.weight\", \"inception4d.branch4.1.bn.weight\", \"inception4d.branch4.1.bn.bias\", \"inception4d.branch4.1.bn.running_mean\", \"inception4d.branch4.1.bn.running_var\", \"inception4e.branch1.conv.weight\", \"inception4e.branch1.bn.weight\", \"inception4e.branch1.bn.bias\", \"inception4e.branch1.bn.running_mean\", \"inception4e.branch1.bn.running_var\", \"inception4e.branch2.0.conv.weight\", \"inception4e.branch2.0.bn.weight\", \"inception4e.branch2.0.bn.bias\", \"inception4e.branch2.0.bn.running_mean\", \"inception4e.branch2.0.bn.running_var\", \"inception4e.branch2.1.conv.weight\", \"inception4e.branch2.1.bn.weight\", \"inception4e.branch2.1.bn.bias\", \"inception4e.branch2.1.bn.running_mean\", \"inception4e.branch2.1.bn.running_var\", \"inception4e.branch3.0.conv.weight\", \"inception4e.branch3.0.bn.weight\", \"inception4e.branch3.0.bn.bias\", \"inception4e.branch3.0.bn.running_mean\", \"inception4e.branch3.0.bn.running_var\", \"inception4e.branch3.1.conv.weight\", \"inception4e.branch3.1.bn.weight\", \"inception4e.branch3.1.bn.bias\", \"inception4e.branch3.1.bn.running_mean\", \"inception4e.branch3.1.bn.running_var\", \"inception4e.branch4.1.conv.weight\", \"inception4e.branch4.1.bn.weight\", \"inception4e.branch4.1.bn.bias\", \"inception4e.branch4.1.bn.running_mean\", \"inception4e.branch4.1.bn.running_var\", \"inception5a.branch1.conv.weight\", \"inception5a.branch1.bn.weight\", \"inception5a.branch1.bn.bias\", \"inception5a.branch1.bn.running_mean\", \"inception5a.branch1.bn.running_var\", \"inception5a.branch2.0.conv.weight\", \"inception5a.branch2.0.bn.weight\", \"inception5a.branch2.0.bn.bias\", \"inception5a.branch2.0.bn.running_mean\", \"inception5a.branch2.0.bn.running_var\", \"inception5a.branch2.1.conv.weight\", \"inception5a.branch2.1.bn.weight\", \"inception5a.branch2.1.bn.bias\", \"inception5a.branch2.1.bn.running_mean\", \"inception5a.branch2.1.bn.running_var\", \"inception5a.branch3.0.conv.weight\", \"inception5a.branch3.0.bn.weight\", \"inception5a.branch3.0.bn.bias\", \"inception5a.branch3.0.bn.running_mean\", \"inception5a.branch3.0.bn.running_var\", \"inception5a.branch3.1.conv.weight\", \"inception5a.branch3.1.bn.weight\", \"inception5a.branch3.1.bn.bias\", \"inception5a.branch3.1.bn.running_mean\", \"inception5a.branch3.1.bn.running_var\", \"inception5a.branch4.1.conv.weight\", \"inception5a.branch4.1.bn.weight\", \"inception5a.branch4.1.bn.bias\", \"inception5a.branch4.1.bn.running_mean\", \"inception5a.branch4.1.bn.running_var\", \"inception5b.branch1.conv.weight\", \"inception5b.branch1.bn.weight\", \"inception5b.branch1.bn.bias\", \"inception5b.branch1.bn.running_mean\", \"inception5b.branch1.bn.running_var\", \"inception5b.branch2.0.conv.weight\", \"inception5b.branch2.0.bn.weight\", \"inception5b.branch2.0.bn.bias\", \"inception5b.branch2.0.bn.running_mean\", \"inception5b.branch2.0.bn.running_var\", \"inception5b.branch2.1.conv.weight\", \"inception5b.branch2.1.bn.weight\", \"inception5b.branch2.1.bn.bias\", \"inception5b.branch2.1.bn.running_mean\", \"inception5b.branch2.1.bn.running_var\", \"inception5b.branch3.0.conv.weight\", \"inception5b.branch3.0.bn.weight\", \"inception5b.branch3.0.bn.bias\", \"inception5b.branch3.0.bn.running_mean\", \"inception5b.branch3.0.bn.running_var\", \"inception5b.branch3.1.conv.weight\", \"inception5b.branch3.1.bn.weight\", \"inception5b.branch3.1.bn.bias\", \"inception5b.branch3.1.bn.running_mean\", \"inception5b.branch3.1.bn.running_var\", \"inception5b.branch4.1.conv.weight\", \"inception5b.branch4.1.bn.weight\", \"inception5b.branch4.1.bn.bias\", \"inception5b.branch4.1.bn.running_mean\", \"inception5b.branch4.1.bn.running_var\", \"fc.weight\", \"fc.bias\". \n\tUnexpected key(s) in state_dict: \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"bn1.num_batches_tracked\", \"bn2.weight\", \"bn2.bias\", \"bn2.running_mean\", \"bn2.running_var\", \"bn2.num_batches_tracked\", \"fc1.weight\", \"fc1.bias\", \"fc2.weight\", \"fc2.bias\", \"conv1.weight\", \"conv2.weight\". "
     ]
    }
   ],
   "source": [
    "def forward_vis(vis_loader, groups):\n",
    "    since = time.time()\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    model = models.googlenet(aux_logits=False)\n",
    "    set_parameter_requires_grad(model, feature_extract)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    # load best model weights\n",
    "    state_dict = torch.load('model_weight/2_layer_model_'+str(num_epochs))\n",
    "    print(state_dict.keys())\n",
    "    model.load_state_dict(torch.load('model_weight/2_layer_model_'+str(num_epochs)))\n",
    "    model.to(device)\n",
    "    model.eval()   # Set model to evaluate mode\n",
    "    # Iterate over data.\n",
    "    cnt=0\n",
    "    vis_dict = {'inputs':np.empty([groups,vis_batch,3,224,224]),'outputs':np.empty([groups,vis_batch,num_classes]),'labels':np.empty([groups,vis_batch]),'preds':np.empty([groups,vis_batch])}\n",
    "    for inputs, labels in vis_loader:\n",
    "            if(cnt==groups):\n",
    "                break;\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            vis_dict['inputs'][cnt,:,:,:,:]=inputs.cpu().numpy()\n",
    "            vis_dict['labels'][cnt,:]=labels.cpu().numpy()\n",
    "            # forward\n",
    "            # track history if only in train\n",
    "            with torch.set_grad_enabled(False):\n",
    "            # Get model outputs and calculate loss\n",
    "            # Special case for inception because in training it has an auxiliary output. In train\n",
    "            #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "            #   but in testing we only consider the final output.\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                vis_dict['outputs'][cnt,:,:]=outputs.cpu().numpy()\n",
    "                vis_dict['preds'][cnt,:]=preds.cpu().numpy()\n",
    "            cnt+=1\n",
    "            \n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print()\n",
    "    print('Inference complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    return vis_dict\n",
    "\n",
    "vis_loader = torch.utils.data.DataLoader(image_datasets['val'], batch_size=vis_batch, shuffle=True, num_workers=8)\n",
    "vis_dict = forward_vis(vis_loader, groups)\n",
    "print(vis_dict['inputs'].shape)\n",
    "print(vis_dict['outputs'].shape)\n",
    "print(vis_dict['labels'].shape)\n",
    "print(vis_dict['preds'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(groups) :\n",
    "    for j in range(vis_batch) :\n",
    "        plt.figure(figsize=(15,15))\n",
    "        plt.subplot(groups,vis_batch,4*i+j+1)\n",
    "        image = np.moveaxis(np.squeeze(vis_dict['inputs'][i,j]), 0, -1)\n",
    "        image = (image-np.amin(image))/(np.amax(image)-np.amin(image))\n",
    "        plt.imshow(image)\n",
    "        plt.tick_params(\n",
    "        axis='both',          # changes apply to the x-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        bottom=False,      # ticks along the bottom edge are off\n",
    "        left=False,         # ticks along the left edge are off\n",
    "        labelbottom=False,\n",
    "        labelleft=False) # labels along the bottom edge are off\n",
    "        plt.title('preprocessed '+str(i)+' '+str(j))\n",
    "        plt.xlabel('label : '+str(vis_dict['labels'][i,j])+', pred : '+str(vis_dict['preds'][i,j])+', output : '+str(vis_dict['outputs'][i,j,:]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
