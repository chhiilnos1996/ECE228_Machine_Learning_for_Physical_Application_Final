{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whale Detection Challenge : 2_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method overview : FFT to convert the sound tracks into spectrograms, and apply distinct preprocessing methods such as clipping, noise removal, PCEN and filters. After preprocessing we feed the spectrograms into state of the art light CNN models such as Resnet 18, VGG 16 or GoogleNet to identify right whale call patterns and perform classification. We may also try the removal of pooling layers in the networks and see if it causes better outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.3.1\n",
      "Torchvision Version:  0.4.2\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "feature_extract = True\n",
    "groups = 3\n",
    "vis_batch = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"data/\"\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((40,500)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((40,500)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x+\"_prep_10_2layers/\"), data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=8) for x in ['train', 'val']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 2-layer model\n",
    "class small_model(nn.Module):\n",
    "    # input size 40*500\n",
    "    # image = cv2.resize(image, (40, 500), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "    def __init__(self):\n",
    "        super(small_model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=7, stride=1, padding=(3, 3), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=True)\n",
    "        self.dropout = nn.Dropout2d(p = 0.3)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=7, stride=1, padding=(3, 3), bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(4, 100), stride=(4, 100), padding=0, dilation=1, ceil_mode=True)\n",
    "\n",
    "        self.flat = nn.Flatten()\n",
    "        \n",
    "        self.fc1 = nn.Linear(128, 100)\n",
    "        self.fc2 = nn.Linear(100, 2)\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "#         self.dropout = nn.Dropout2d(p = 0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # CNN 1\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.dropout(self.pool1(x))\n",
    "        \n",
    "        # CNN 2\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.dropout(self.pool2(x))\n",
    "        \n",
    "        # Flatten\n",
    "        x = self.flat(x)\n",
    "        \n",
    "        # Dense\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        # Output\n",
    "        x = self.softmax(self.fc2(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small_model(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool1): MaxPool2d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=True)\n",
      "  (dropout): Dropout2d(p=0.3, inplace=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool2): MaxPool2d(kernel_size=(4, 100), stride=(4, 100), padding=0, dilation=1, ceil_mode=True)\n",
      "  (flat): Flatten()\n",
      "  (fc1): Linear(in_features=128, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=2, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "def initialize_model(num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = small_model()\n",
    "    num_ftrs = model_ft.fc1.out_features\n",
    "    model_ft.fc2 = nn.Linear(num_ftrs, num_classes)\n",
    "    input_size = (40, 500)  \n",
    "    return model_ft, input_size\n",
    "\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training fuction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "    history = {'train_loss':[],'train_acc':[],'val_loss':[],'val_acc':[]}\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0\n",
    "            running_corrects = 0\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'train':\n",
    "                history['train_loss'].append(epoch_loss)\n",
    "                history['train_acc'].append(epoch_acc)\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                history['val_loss'].append(epoch_loss)\n",
    "                history['val_acc'].append(epoch_acc)\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, history, best_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t conv1.weight\n",
      "\t bn1.weight\n",
      "\t bn1.bias\n",
      "\t conv2.weight\n",
      "\t bn2.weight\n",
      "\t bn2.bias\n",
      "\t fc1.weight\n",
      "\t fc1.bias\n",
      "\t fc2.weight\n",
      "\t fc2.bias\n"
     ]
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(params_to_update, lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:40: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5533 Acc: 0.7607\n",
      "val Loss: 0.5448 Acc: 0.7660\n",
      "\n",
      "Epoch 1/99\n",
      "----------\n",
      "train Loss: 0.5453 Acc: 0.7660\n",
      "val Loss: 0.5259 Acc: 0.7660\n",
      "\n",
      "Epoch 2/99\n",
      "----------\n",
      "train Loss: 0.5148 Acc: 0.7913\n",
      "val Loss: 0.4574 Acc: 0.8627\n",
      "\n",
      "Epoch 3/99\n",
      "----------\n",
      "train Loss: 0.4790 Acc: 0.8350\n",
      "val Loss: 0.4554 Acc: 0.8657\n",
      "\n",
      "Epoch 4/99\n",
      "----------\n",
      "train Loss: 0.4726 Acc: 0.8340\n",
      "val Loss: 0.4386 Acc: 0.8730\n",
      "\n",
      "Epoch 5/99\n",
      "----------\n",
      "train Loss: 0.4568 Acc: 0.8520\n",
      "val Loss: 0.4358 Acc: 0.8747\n",
      "\n",
      "Epoch 6/99\n",
      "----------\n",
      "train Loss: 0.4543 Acc: 0.8563\n",
      "val Loss: 0.4303 Acc: 0.8790\n",
      "\n",
      "Epoch 7/99\n",
      "----------\n",
      "train Loss: 0.4491 Acc: 0.8600\n",
      "val Loss: 0.4313 Acc: 0.8777\n",
      "\n",
      "Epoch 8/99\n",
      "----------\n",
      "train Loss: 0.4365 Acc: 0.8790\n",
      "val Loss: 0.4296 Acc: 0.8800\n",
      "\n",
      "Epoch 9/99\n",
      "----------\n",
      "train Loss: 0.4442 Acc: 0.8653\n",
      "val Loss: 0.4266 Acc: 0.8790\n",
      "\n",
      "Epoch 10/99\n",
      "----------\n",
      "train Loss: 0.4422 Acc: 0.8650\n",
      "val Loss: 0.4254 Acc: 0.8810\n",
      "\n",
      "Epoch 11/99\n",
      "----------\n",
      "train Loss: 0.4352 Acc: 0.8750\n",
      "val Loss: 0.4280 Acc: 0.8810\n",
      "\n",
      "Epoch 12/99\n",
      "----------\n",
      "train Loss: 0.4380 Acc: 0.8700\n",
      "val Loss: 0.4241 Acc: 0.8813\n",
      "\n",
      "Epoch 13/99\n",
      "----------\n",
      "train Loss: 0.4342 Acc: 0.8753\n",
      "val Loss: 0.4251 Acc: 0.8830\n",
      "\n",
      "Epoch 14/99\n",
      "----------\n",
      "train Loss: 0.4328 Acc: 0.8803\n",
      "val Loss: 0.4229 Acc: 0.8820\n",
      "\n",
      "Epoch 15/99\n",
      "----------\n",
      "train Loss: 0.4274 Acc: 0.8837\n",
      "val Loss: 0.4217 Acc: 0.8857\n",
      "\n",
      "Epoch 16/99\n",
      "----------\n",
      "train Loss: 0.4326 Acc: 0.8750\n",
      "val Loss: 0.4210 Acc: 0.8837\n",
      "\n",
      "Epoch 17/99\n",
      "----------\n",
      "train Loss: 0.4283 Acc: 0.8830\n",
      "val Loss: 0.4220 Acc: 0.8827\n",
      "\n",
      "Epoch 18/99\n",
      "----------\n",
      "train Loss: 0.4243 Acc: 0.8837\n",
      "val Loss: 0.4206 Acc: 0.8847\n",
      "\n",
      "Epoch 19/99\n",
      "----------\n",
      "train Loss: 0.4263 Acc: 0.8807\n",
      "val Loss: 0.4218 Acc: 0.8843\n",
      "\n",
      "Epoch 20/99\n",
      "----------\n",
      "train Loss: 0.4198 Acc: 0.8903\n",
      "val Loss: 0.4200 Acc: 0.8883\n",
      "\n",
      "Epoch 21/99\n",
      "----------\n",
      "train Loss: 0.4202 Acc: 0.8917\n",
      "val Loss: 0.4198 Acc: 0.8877\n",
      "\n",
      "Epoch 22/99\n",
      "----------\n",
      "train Loss: 0.4178 Acc: 0.8907\n",
      "val Loss: 0.4197 Acc: 0.8857\n",
      "\n",
      "Epoch 23/99\n",
      "----------\n",
      "train Loss: 0.4188 Acc: 0.8920\n",
      "val Loss: 0.4198 Acc: 0.8890\n",
      "\n",
      "Epoch 24/99\n",
      "----------\n",
      "train Loss: 0.4143 Acc: 0.8973\n",
      "val Loss: 0.4189 Acc: 0.8867\n",
      "\n",
      "Epoch 25/99\n",
      "----------\n",
      "train Loss: 0.4133 Acc: 0.8983\n",
      "val Loss: 0.4171 Acc: 0.8917\n",
      "\n",
      "Epoch 26/99\n",
      "----------\n",
      "train Loss: 0.4105 Acc: 0.8977\n",
      "val Loss: 0.4188 Acc: 0.8880\n",
      "\n",
      "Epoch 27/99\n",
      "----------\n",
      "train Loss: 0.4083 Acc: 0.9043\n",
      "val Loss: 0.4172 Acc: 0.8913\n",
      "\n",
      "Epoch 28/99\n",
      "----------\n",
      "train Loss: 0.4074 Acc: 0.9057\n",
      "val Loss: 0.4219 Acc: 0.8880\n",
      "\n",
      "Epoch 29/99\n",
      "----------\n",
      "train Loss: 0.4056 Acc: 0.9093\n",
      "val Loss: 0.4172 Acc: 0.8910\n",
      "\n",
      "Epoch 30/99\n",
      "----------\n",
      "train Loss: 0.4068 Acc: 0.9037\n",
      "val Loss: 0.4165 Acc: 0.8913\n",
      "\n",
      "Epoch 31/99\n",
      "----------\n",
      "train Loss: 0.4008 Acc: 0.9163\n",
      "val Loss: 0.4189 Acc: 0.8900\n",
      "\n",
      "Epoch 32/99\n",
      "----------\n",
      "train Loss: 0.3994 Acc: 0.9147\n",
      "val Loss: 0.4171 Acc: 0.8887\n",
      "\n",
      "Epoch 33/99\n",
      "----------\n",
      "train Loss: 0.3989 Acc: 0.9160\n",
      "val Loss: 0.4177 Acc: 0.8897\n",
      "\n",
      "Epoch 34/99\n",
      "----------\n",
      "train Loss: 0.3993 Acc: 0.9117\n",
      "val Loss: 0.4162 Acc: 0.8933\n",
      "\n",
      "Epoch 35/99\n",
      "----------\n",
      "train Loss: 0.3979 Acc: 0.9147\n",
      "val Loss: 0.4170 Acc: 0.8883\n",
      "\n",
      "Epoch 36/99\n",
      "----------\n",
      "train Loss: 0.3941 Acc: 0.9207\n",
      "val Loss: 0.4200 Acc: 0.8903\n",
      "\n",
      "Epoch 37/99\n",
      "----------\n",
      "train Loss: 0.3918 Acc: 0.9230\n",
      "val Loss: 0.4171 Acc: 0.8917\n",
      "\n",
      "Epoch 38/99\n",
      "----------\n",
      "train Loss: 0.3878 Acc: 0.9263\n",
      "val Loss: 0.4160 Acc: 0.8897\n",
      "\n",
      "Epoch 39/99\n",
      "----------\n",
      "train Loss: 0.3903 Acc: 0.9243\n",
      "val Loss: 0.4180 Acc: 0.8937\n",
      "\n",
      "Epoch 40/99\n",
      "----------\n",
      "train Loss: 0.3887 Acc: 0.9240\n",
      "val Loss: 0.4155 Acc: 0.8877\n",
      "\n",
      "Epoch 41/99\n",
      "----------\n",
      "train Loss: 0.3876 Acc: 0.9270\n",
      "val Loss: 0.4144 Acc: 0.8907\n",
      "\n",
      "Epoch 42/99\n",
      "----------\n",
      "train Loss: 0.3846 Acc: 0.9280\n",
      "val Loss: 0.4156 Acc: 0.8917\n",
      "\n",
      "Epoch 43/99\n",
      "----------\n",
      "train Loss: 0.3881 Acc: 0.9290\n",
      "val Loss: 0.4151 Acc: 0.8923\n",
      "\n",
      "Epoch 44/99\n",
      "----------\n",
      "train Loss: 0.3815 Acc: 0.9353\n",
      "val Loss: 0.4143 Acc: 0.8937\n",
      "\n",
      "Epoch 45/99\n",
      "----------\n",
      "train Loss: 0.3775 Acc: 0.9373\n",
      "val Loss: 0.4143 Acc: 0.8957\n",
      "\n",
      "Epoch 46/99\n",
      "----------\n",
      "train Loss: 0.3833 Acc: 0.9320\n",
      "val Loss: 0.4169 Acc: 0.8917\n",
      "\n",
      "Epoch 47/99\n",
      "----------\n",
      "train Loss: 0.3794 Acc: 0.9373\n",
      "val Loss: 0.4161 Acc: 0.8870\n",
      "\n",
      "Epoch 48/99\n",
      "----------\n",
      "train Loss: 0.3752 Acc: 0.9397\n",
      "val Loss: 0.4167 Acc: 0.8910\n",
      "\n",
      "Epoch 49/99\n",
      "----------\n",
      "train Loss: 0.3732 Acc: 0.9417\n",
      "val Loss: 0.4179 Acc: 0.8893\n",
      "\n",
      "Epoch 50/99\n",
      "----------\n",
      "train Loss: 0.3727 Acc: 0.9443\n",
      "val Loss: 0.4150 Acc: 0.8910\n",
      "\n",
      "Epoch 51/99\n",
      "----------\n",
      "train Loss: 0.3768 Acc: 0.9360\n",
      "val Loss: 0.4154 Acc: 0.8897\n",
      "\n",
      "Epoch 52/99\n",
      "----------\n",
      "train Loss: 0.3705 Acc: 0.9473\n",
      "val Loss: 0.4159 Acc: 0.8923\n",
      "\n",
      "Epoch 53/99\n",
      "----------\n",
      "train Loss: 0.3698 Acc: 0.9467\n",
      "val Loss: 0.4171 Acc: 0.8903\n",
      "\n",
      "Epoch 54/99\n",
      "----------\n",
      "train Loss: 0.3681 Acc: 0.9500\n",
      "val Loss: 0.4162 Acc: 0.8910\n",
      "\n",
      "Epoch 55/99\n",
      "----------\n",
      "train Loss: 0.3681 Acc: 0.9477\n",
      "val Loss: 0.4164 Acc: 0.8910\n",
      "\n",
      "Epoch 56/99\n",
      "----------\n",
      "train Loss: 0.3655 Acc: 0.9520\n",
      "val Loss: 0.4196 Acc: 0.8880\n",
      "\n",
      "Epoch 57/99\n",
      "----------\n",
      "train Loss: 0.3652 Acc: 0.9477\n",
      "val Loss: 0.4155 Acc: 0.8890\n",
      "\n",
      "Epoch 58/99\n",
      "----------\n",
      "train Loss: 0.3623 Acc: 0.9523\n",
      "val Loss: 0.4161 Acc: 0.8907\n",
      "\n",
      "Epoch 59/99\n",
      "----------\n",
      "train Loss: 0.3617 Acc: 0.9527\n",
      "val Loss: 0.4162 Acc: 0.8887\n",
      "\n",
      "Epoch 60/99\n",
      "----------\n",
      "train Loss: 0.3629 Acc: 0.9537\n",
      "val Loss: 0.4163 Acc: 0.8920\n",
      "\n",
      "Epoch 61/99\n",
      "----------\n",
      "train Loss: 0.3592 Acc: 0.9587\n",
      "val Loss: 0.4147 Acc: 0.8903\n",
      "\n",
      "Epoch 62/99\n",
      "----------\n",
      "train Loss: 0.3588 Acc: 0.9570\n",
      "val Loss: 0.4151 Acc: 0.8900\n",
      "\n",
      "Epoch 63/99\n",
      "----------\n",
      "train Loss: 0.3579 Acc: 0.9583\n",
      "val Loss: 0.4155 Acc: 0.8913\n",
      "\n",
      "Epoch 64/99\n",
      "----------\n",
      "train Loss: 0.3574 Acc: 0.9570\n",
      "val Loss: 0.4161 Acc: 0.8910\n",
      "\n",
      "Epoch 65/99\n",
      "----------\n",
      "train Loss: 0.3555 Acc: 0.9607\n",
      "val Loss: 0.4157 Acc: 0.8923\n",
      "\n",
      "Epoch 66/99\n",
      "----------\n",
      "train Loss: 0.3514 Acc: 0.9660\n",
      "val Loss: 0.4170 Acc: 0.8893\n",
      "\n",
      "Epoch 67/99\n",
      "----------\n",
      "train Loss: 0.3514 Acc: 0.9643\n",
      "val Loss: 0.4159 Acc: 0.8920\n",
      "\n",
      "Epoch 68/99\n",
      "----------\n",
      "train Loss: 0.3531 Acc: 0.9620\n",
      "val Loss: 0.4150 Acc: 0.8937\n",
      "\n",
      "Epoch 69/99\n",
      "----------\n",
      "train Loss: 0.3535 Acc: 0.9620\n",
      "val Loss: 0.4141 Acc: 0.8920\n",
      "\n",
      "Epoch 70/99\n",
      "----------\n",
      "train Loss: 0.3521 Acc: 0.9647\n",
      "val Loss: 0.4153 Acc: 0.8937\n",
      "\n",
      "Epoch 71/99\n",
      "----------\n",
      "train Loss: 0.3524 Acc: 0.9627\n",
      "val Loss: 0.4149 Acc: 0.8957\n",
      "\n",
      "Epoch 72/99\n",
      "----------\n",
      "train Loss: 0.3475 Acc: 0.9670\n",
      "val Loss: 0.4145 Acc: 0.8923\n",
      "\n",
      "Epoch 73/99\n",
      "----------\n",
      "train Loss: 0.3530 Acc: 0.9627\n",
      "val Loss: 0.4151 Acc: 0.8903\n",
      "\n",
      "Epoch 74/99\n",
      "----------\n",
      "train Loss: 0.3485 Acc: 0.9660\n",
      "val Loss: 0.4154 Acc: 0.8907\n",
      "\n",
      "Epoch 75/99\n",
      "----------\n",
      "train Loss: 0.3475 Acc: 0.9680\n",
      "val Loss: 0.4153 Acc: 0.8937\n",
      "\n",
      "Epoch 76/99\n",
      "----------\n",
      "train Loss: 0.3468 Acc: 0.9697\n",
      "val Loss: 0.4154 Acc: 0.8893\n",
      "\n",
      "Epoch 77/99\n",
      "----------\n",
      "train Loss: 0.3461 Acc: 0.9693\n",
      "val Loss: 0.4145 Acc: 0.8947\n",
      "\n",
      "Epoch 78/99\n",
      "----------\n",
      "train Loss: 0.3449 Acc: 0.9720\n",
      "val Loss: 0.4147 Acc: 0.8947\n",
      "\n",
      "Epoch 79/99\n",
      "----------\n",
      "train Loss: 0.3449 Acc: 0.9710\n",
      "val Loss: 0.4144 Acc: 0.8933\n",
      "\n",
      "Epoch 80/99\n",
      "----------\n",
      "train Loss: 0.3446 Acc: 0.9703\n",
      "val Loss: 0.4171 Acc: 0.8883\n",
      "\n",
      "Epoch 81/99\n",
      "----------\n",
      "train Loss: 0.3428 Acc: 0.9727\n",
      "val Loss: 0.4153 Acc: 0.8910\n",
      "\n",
      "Epoch 82/99\n",
      "----------\n",
      "train Loss: 0.3458 Acc: 0.9700\n",
      "val Loss: 0.4145 Acc: 0.8940\n",
      "\n",
      "Epoch 83/99\n",
      "----------\n",
      "train Loss: 0.3460 Acc: 0.9700\n",
      "val Loss: 0.4230 Acc: 0.8843\n",
      "\n",
      "Epoch 84/99\n",
      "----------\n",
      "train Loss: 0.3447 Acc: 0.9703\n",
      "val Loss: 0.4156 Acc: 0.8907\n",
      "\n",
      "Epoch 85/99\n",
      "----------\n",
      "train Loss: 0.3429 Acc: 0.9720\n",
      "val Loss: 0.4159 Acc: 0.8907\n",
      "\n",
      "Epoch 86/99\n",
      "----------\n",
      "train Loss: 0.3393 Acc: 0.9760\n",
      "val Loss: 0.4152 Acc: 0.8920\n",
      "\n",
      "Epoch 87/99\n",
      "----------\n",
      "train Loss: 0.3422 Acc: 0.9737\n",
      "val Loss: 0.4172 Acc: 0.8907\n",
      "\n",
      "Epoch 88/99\n",
      "----------\n",
      "train Loss: 0.3414 Acc: 0.9743\n",
      "val Loss: 0.4151 Acc: 0.8917\n",
      "\n",
      "Epoch 89/99\n",
      "----------\n",
      "train Loss: 0.3405 Acc: 0.9733\n",
      "val Loss: 0.4144 Acc: 0.8930\n",
      "\n",
      "Epoch 90/99\n",
      "----------\n",
      "train Loss: 0.3366 Acc: 0.9790\n",
      "val Loss: 0.4153 Acc: 0.8920\n",
      "\n",
      "Epoch 91/99\n",
      "----------\n",
      "train Loss: 0.3391 Acc: 0.9757\n",
      "val Loss: 0.4146 Acc: 0.8920\n",
      "\n",
      "Epoch 92/99\n",
      "----------\n",
      "train Loss: 0.3381 Acc: 0.9777\n",
      "val Loss: 0.4153 Acc: 0.8943\n",
      "\n",
      "Epoch 93/99\n",
      "----------\n",
      "train Loss: 0.3398 Acc: 0.9763\n",
      "val Loss: 0.4176 Acc: 0.8930\n",
      "\n",
      "Epoch 94/99\n",
      "----------\n",
      "train Loss: 0.3368 Acc: 0.9797\n",
      "val Loss: 0.4172 Acc: 0.8923\n",
      "\n",
      "Epoch 95/99\n",
      "----------\n",
      "train Loss: 0.3375 Acc: 0.9773\n",
      "val Loss: 0.4148 Acc: 0.8937\n",
      "\n",
      "Epoch 96/99\n",
      "----------\n",
      "train Loss: 0.3399 Acc: 0.9747\n",
      "val Loss: 0.4161 Acc: 0.8900\n",
      "\n",
      "Epoch 97/99\n",
      "----------\n",
      "train Loss: 0.3364 Acc: 0.9783\n",
      "val Loss: 0.4176 Acc: 0.8873\n",
      "\n",
      "Epoch 98/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3354 Acc: 0.9797\n",
      "val Loss: 0.4156 Acc: 0.8900\n",
      "\n",
      "Epoch 99/99\n",
      "----------\n",
      "train Loss: 0.3353 Acc: 0.9807\n",
      "val Loss: 0.4169 Acc: 0.8883\n",
      "\n",
      "Training complete in 7m 15s\n",
      "Best val Acc: 0.895667\n",
      "odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'conv2.weight', 'bn2.weight', 'bn2.bias', 'bn2.running_mean', 'bn2.running_var', 'bn2.num_batches_tracked', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias'])\n"
     ]
    }
   ],
   "source": [
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist, best_acc = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs)\n",
    "torch.save(model_ft.state_dict(), 'model_weight/2_layer_model_'+str(num_epochs))\n",
    "print(model_ft.state_dict().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train_loss', 'train_acc', 'val_loss', 'val_acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8957, device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(hist.keys())\n",
    "\n",
    "#### Fill in plot #####\n",
    "#Plot accuracy vs epoch\n",
    "plt.subplot(211)\n",
    "\n",
    "plt.plot(hist['train_acc'])\n",
    "plt.plot(hist['val_acc'])\n",
    "plt.title('accuracy : 2_layer_model')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "#Plot loss vs epoch\n",
    "plt.subplot(212)\n",
    "plt.plot(hist['train_loss'])\n",
    "plt.plot(hist['val_loss'])\n",
    "plt.title('loss : 2_layer_model')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "print(best_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load model and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'conv2.weight', 'bn2.weight', 'bn2.bias', 'bn2.running_mean', 'bn2.running_var', 'bn2.num_batches_tracked', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias'])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for GoogLeNet:\n\tMissing key(s) in state_dict: \"conv1.conv.weight\", \"conv1.bn.weight\", \"conv1.bn.bias\", \"conv1.bn.running_mean\", \"conv1.bn.running_var\", \"conv2.conv.weight\", \"conv2.bn.weight\", \"conv2.bn.bias\", \"conv2.bn.running_mean\", \"conv2.bn.running_var\", \"conv3.conv.weight\", \"conv3.bn.weight\", \"conv3.bn.bias\", \"conv3.bn.running_mean\", \"conv3.bn.running_var\", \"inception3a.branch1.conv.weight\", \"inception3a.branch1.bn.weight\", \"inception3a.branch1.bn.bias\", \"inception3a.branch1.bn.running_mean\", \"inception3a.branch1.bn.running_var\", \"inception3a.branch2.0.conv.weight\", \"inception3a.branch2.0.bn.weight\", \"inception3a.branch2.0.bn.bias\", \"inception3a.branch2.0.bn.running_mean\", \"inception3a.branch2.0.bn.running_var\", \"inception3a.branch2.1.conv.weight\", \"inception3a.branch2.1.bn.weight\", \"inception3a.branch2.1.bn.bias\", \"inception3a.branch2.1.bn.running_mean\", \"inception3a.branch2.1.bn.running_var\", \"inception3a.branch3.0.conv.weight\", \"inception3a.branch3.0.bn.weight\", \"inception3a.branch3.0.bn.bias\", \"inception3a.branch3.0.bn.running_mean\", \"inception3a.branch3.0.bn.running_var\", \"inception3a.branch3.1.conv.weight\", \"inception3a.branch3.1.bn.weight\", \"inception3a.branch3.1.bn.bias\", \"inception3a.branch3.1.bn.running_mean\", \"inception3a.branch3.1.bn.running_var\", \"inception3a.branch4.1.conv.weight\", \"inception3a.branch4.1.bn.weight\", \"inception3a.branch4.1.bn.bias\", \"inception3a.branch4.1.bn.running_mean\", \"inception3a.branch4.1.bn.running_var\", \"inception3b.branch1.conv.weight\", \"inception3b.branch1.bn.weight\", \"inception3b.branch1.bn.bias\", \"inception3b.branch1.bn.running_mean\", \"inception3b.branch1.bn.running_var\", \"inception3b.branch2.0.conv.weight\", \"inception3b.branch2.0.bn.weight\", \"inception3b.branch2.0.bn.bias\", \"inception3b.branch2.0.bn.running_mean\", \"inception3b.branch2.0.bn.running_var\", \"inception3b.branch2.1.conv.weight\", \"inception3b.branch2.1.bn.weight\", \"inception3b.branch2.1.bn.bias\", \"inception3b.branch2.1.bn.running_mean\", \"inception3b.branch2.1.bn.running_var\", \"inception3b.branch3.0.conv.weight\", \"inception3b.branch3.0.bn.weight\", \"inception3b.branch3.0.bn.bias\", \"inception3b.branch3.0.bn.running_mean\", \"inception3b.branch3.0.bn.running_var\", \"inception3b.branch3.1.conv.weight\", \"inception3b.branch3.1.bn.weight\", \"inception3b.branch3.1.bn.bias\", \"inception3b.branch3.1.bn.running_mean\", \"inception3b.branch3.1.bn.running_var\", \"inception3b.branch4.1.conv.weight\", \"inception3b.branch4.1.bn.weight\", \"inception3b.branch4.1.bn.bias\", \"inception3b.branch4.1.bn.running_mean\", \"inception3b.branch4.1.bn.running_var\", \"inception4a.branch1.conv.weight\", \"inception4a.branch1.bn.weight\", \"inception4a.branch1.bn.bias\", \"inception4a.branch1.bn.running_mean\", \"inception4a.branch1.bn.running_var\", \"inception4a.branch2.0.conv.weight\", \"inception4a.branch2.0.bn.weight\", \"inception4a.branch2.0.bn.bias\", \"inception4a.branch2.0.bn.running_mean\", \"inception4a.branch2.0.bn.running_var\", \"inception4a.branch2.1.conv.weight\", \"inception4a.branch2.1.bn.weight\", \"inception4a.branch2.1.bn.bias\", \"inception4a.branch2.1.bn.running_mean\", \"inception4a.branch2.1.bn.running_var\", \"inception4a.branch3.0.conv.weight\", \"inception4a.branch3.0.bn.weight\", \"inception4a.branch3.0.bn.bias\", \"inception4a.branch3.0.bn.running_mean\", \"inception4a.branch3.0.bn.running_var\", \"inception4a.branch3.1.conv.weight\", \"inception4a.branch3.1.bn.weight\", \"inception4a.branch3.1.bn.bias\", \"inception4a.branch3.1.bn.running_mean\", \"inception4a.branch3.1.bn.running_var\", \"inception4a.branch4.1.conv.weight\", \"inception4a.branch4.1.bn.weight\", \"inception4a.branch4.1.bn.bias\", \"inception4a.branch4.1.bn.running_mean\", \"inception4a.branch4.1.bn.running_var\", \"inception4b.branch1.conv.weight\", \"inception4b.branch1.bn.weight\", \"inception4b.branch1.bn.bias\", \"inception4b.branch1.bn.running_mean\", \"inception4b.branch1.bn.running_var\", \"inception4b.branch2.0.conv.weight\", \"inception4b.branch2.0.bn.weight\", \"inception4b.branch2.0.bn.bias\", \"inception4b.branch2.0.bn.running_mean\", \"inception4b.branch2.0.bn.running_var\", \"inception4b.branch2.1.conv.weight\", \"inception4b.branch2.1.bn.weight\", \"inception4b.branch2.1.bn.bias\", \"inception4b.branch2.1.bn.running_mean\", \"inception4b.branch2.1.bn.running_var\", \"inception4b.branch3.0.conv.weight\", \"inception4b.branch3.0.bn.weight\", \"inception4b.branch3.0.bn.bias\", \"inception4b.branch3.0.bn.running_mean\", \"inception4b.branch3.0.bn.running_var\", \"inception4b.branch3.1.conv.weight\", \"inception4b.branch3.1.bn.weight\", \"inception4b.branch3.1.bn.bias\", \"inception4b.branch3.1.bn.running_mean\", \"inception4b.branch3.1.bn.running_var\", \"inception4b.branch4.1.conv.weight\", \"inception4b.branch4.1.bn.weight\", \"inception4b.branch4.1.bn.bias\", \"inception4b.branch4.1.bn.running_mean\", \"inception4b.branch4.1.bn.running_var\", \"inception4c.branch1.conv.weight\", \"inception4c.branch1.bn.weight\", \"inception4c.branch1.bn.bias\", \"inception4c.branch1.bn.running_mean\", \"inception4c.branch1.bn.running_var\", \"inception4c.branch2.0.conv.weight\", \"inception4c.branch2.0.bn.weight\", \"inception4c.branch2.0.bn.bias\", \"inception4c.branch2.0.bn.running_mean\", \"inception4c.branch2.0.bn.running_var\", \"inception4c.branch2.1.conv.weight\", \"inception4c.branch2.1.bn.weight\", \"inception4c.branch2.1.bn.bias\", \"inception4c.branch2.1.bn.running_mean\", \"inception4c.branch2.1.bn.running_var\", \"inception4c.branch3.0.conv.weight\", \"inception4c.branch3.0.bn.weight\", \"inception4c.branch3.0.bn.bias\", \"inception4c.branch3.0.bn.running_mean\", \"inception4c.branch3.0.bn.running_var\", \"inception4c.branch3.1.conv.weight\", \"inception4c.branch3.1.bn.weight\", \"inception4c.branch3.1.bn.bias\", \"inception4c.branch3.1.bn.running_mean\", \"inception4c.branch3.1.bn.running_var\", \"inception4c.branch4.1.conv.weight\", \"inception4c.branch4.1.bn.weight\", \"inception4c.branch4.1.bn.bias\", \"inception4c.branch4.1.bn.running_mean\", \"inception4c.branch4.1.bn.running_var\", \"inception4d.branch1.conv.weight\", \"inception4d.branch1.bn.weight\", \"inception4d.branch1.bn.bias\", \"inception4d.branch1.bn.running_mean\", \"inception4d.branch1.bn.running_var\", \"inception4d.branch2.0.conv.weight\", \"inception4d.branch2.0.bn.weight\", \"inception4d.branch2.0.bn.bias\", \"inception4d.branch2.0.bn.running_mean\", \"inception4d.branch2.0.bn.running_var\", \"inception4d.branch2.1.conv.weight\", \"inception4d.branch2.1.bn.weight\", \"inception4d.branch2.1.bn.bias\", \"inception4d.branch2.1.bn.running_mean\", \"inception4d.branch2.1.bn.running_var\", \"inception4d.branch3.0.conv.weight\", \"inception4d.branch3.0.bn.weight\", \"inception4d.branch3.0.bn.bias\", \"inception4d.branch3.0.bn.running_mean\", \"inception4d.branch3.0.bn.running_var\", \"inception4d.branch3.1.conv.weight\", \"inception4d.branch3.1.bn.weight\", \"inception4d.branch3.1.bn.bias\", \"inception4d.branch3.1.bn.running_mean\", \"inception4d.branch3.1.bn.running_var\", \"inception4d.branch4.1.conv.weight\", \"inception4d.branch4.1.bn.weight\", \"inception4d.branch4.1.bn.bias\", \"inception4d.branch4.1.bn.running_mean\", \"inception4d.branch4.1.bn.running_var\", \"inception4e.branch1.conv.weight\", \"inception4e.branch1.bn.weight\", \"inception4e.branch1.bn.bias\", \"inception4e.branch1.bn.running_mean\", \"inception4e.branch1.bn.running_var\", \"inception4e.branch2.0.conv.weight\", \"inception4e.branch2.0.bn.weight\", \"inception4e.branch2.0.bn.bias\", \"inception4e.branch2.0.bn.running_mean\", \"inception4e.branch2.0.bn.running_var\", \"inception4e.branch2.1.conv.weight\", \"inception4e.branch2.1.bn.weight\", \"inception4e.branch2.1.bn.bias\", \"inception4e.branch2.1.bn.running_mean\", \"inception4e.branch2.1.bn.running_var\", \"inception4e.branch3.0.conv.weight\", \"inception4e.branch3.0.bn.weight\", \"inception4e.branch3.0.bn.bias\", \"inception4e.branch3.0.bn.running_mean\", \"inception4e.branch3.0.bn.running_var\", \"inception4e.branch3.1.conv.weight\", \"inception4e.branch3.1.bn.weight\", \"inception4e.branch3.1.bn.bias\", \"inception4e.branch3.1.bn.running_mean\", \"inception4e.branch3.1.bn.running_var\", \"inception4e.branch4.1.conv.weight\", \"inception4e.branch4.1.bn.weight\", \"inception4e.branch4.1.bn.bias\", \"inception4e.branch4.1.bn.running_mean\", \"inception4e.branch4.1.bn.running_var\", \"inception5a.branch1.conv.weight\", \"inception5a.branch1.bn.weight\", \"inception5a.branch1.bn.bias\", \"inception5a.branch1.bn.running_mean\", \"inception5a.branch1.bn.running_var\", \"inception5a.branch2.0.conv.weight\", \"inception5a.branch2.0.bn.weight\", \"inception5a.branch2.0.bn.bias\", \"inception5a.branch2.0.bn.running_mean\", \"inception5a.branch2.0.bn.running_var\", \"inception5a.branch2.1.conv.weight\", \"inception5a.branch2.1.bn.weight\", \"inception5a.branch2.1.bn.bias\", \"inception5a.branch2.1.bn.running_mean\", \"inception5a.branch2.1.bn.running_var\", \"inception5a.branch3.0.conv.weight\", \"inception5a.branch3.0.bn.weight\", \"inception5a.branch3.0.bn.bias\", \"inception5a.branch3.0.bn.running_mean\", \"inception5a.branch3.0.bn.running_var\", \"inception5a.branch3.1.conv.weight\", \"inception5a.branch3.1.bn.weight\", \"inception5a.branch3.1.bn.bias\", \"inception5a.branch3.1.bn.running_mean\", \"inception5a.branch3.1.bn.running_var\", \"inception5a.branch4.1.conv.weight\", \"inception5a.branch4.1.bn.weight\", \"inception5a.branch4.1.bn.bias\", \"inception5a.branch4.1.bn.running_mean\", \"inception5a.branch4.1.bn.running_var\", \"inception5b.branch1.conv.weight\", \"inception5b.branch1.bn.weight\", \"inception5b.branch1.bn.bias\", \"inception5b.branch1.bn.running_mean\", \"inception5b.branch1.bn.running_var\", \"inception5b.branch2.0.conv.weight\", \"inception5b.branch2.0.bn.weight\", \"inception5b.branch2.0.bn.bias\", \"inception5b.branch2.0.bn.running_mean\", \"inception5b.branch2.0.bn.running_var\", \"inception5b.branch2.1.conv.weight\", \"inception5b.branch2.1.bn.weight\", \"inception5b.branch2.1.bn.bias\", \"inception5b.branch2.1.bn.running_mean\", \"inception5b.branch2.1.bn.running_var\", \"inception5b.branch3.0.conv.weight\", \"inception5b.branch3.0.bn.weight\", \"inception5b.branch3.0.bn.bias\", \"inception5b.branch3.0.bn.running_mean\", \"inception5b.branch3.0.bn.running_var\", \"inception5b.branch3.1.conv.weight\", \"inception5b.branch3.1.bn.weight\", \"inception5b.branch3.1.bn.bias\", \"inception5b.branch3.1.bn.running_mean\", \"inception5b.branch3.1.bn.running_var\", \"inception5b.branch4.1.conv.weight\", \"inception5b.branch4.1.bn.weight\", \"inception5b.branch4.1.bn.bias\", \"inception5b.branch4.1.bn.running_mean\", \"inception5b.branch4.1.bn.running_var\", \"fc.weight\", \"fc.bias\". \n\tUnexpected key(s) in state_dict: \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"bn1.num_batches_tracked\", \"bn2.weight\", \"bn2.bias\", \"bn2.running_mean\", \"bn2.running_var\", \"bn2.num_batches_tracked\", \"fc1.weight\", \"fc1.bias\", \"fc2.weight\", \"fc2.bias\", \"conv1.weight\", \"conv2.weight\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-9fb5e044317e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mvis_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvis_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mvis_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_vis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvis_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvis_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvis_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'outputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-9fb5e044317e>\u001b[0m in \u001b[0;36mforward_vis\u001b[0;34m(vis_loader, groups)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_weight/2_layer_model_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_weight/2_layer_model_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# Set model to evaluate mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 839\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    840\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for GoogLeNet:\n\tMissing key(s) in state_dict: \"conv1.conv.weight\", \"conv1.bn.weight\", \"conv1.bn.bias\", \"conv1.bn.running_mean\", \"conv1.bn.running_var\", \"conv2.conv.weight\", \"conv2.bn.weight\", \"conv2.bn.bias\", \"conv2.bn.running_mean\", \"conv2.bn.running_var\", \"conv3.conv.weight\", \"conv3.bn.weight\", \"conv3.bn.bias\", \"conv3.bn.running_mean\", \"conv3.bn.running_var\", \"inception3a.branch1.conv.weight\", \"inception3a.branch1.bn.weight\", \"inception3a.branch1.bn.bias\", \"inception3a.branch1.bn.running_mean\", \"inception3a.branch1.bn.running_var\", \"inception3a.branch2.0.conv.weight\", \"inception3a.branch2.0.bn.weight\", \"inception3a.branch2.0.bn.bias\", \"inception3a.branch2.0.bn.running_mean\", \"inception3a.branch2.0.bn.running_var\", \"inception3a.branch2.1.conv.weight\", \"inception3a.branch2.1.bn.weight\", \"inception3a.branch2.1.bn.bias\", \"inception3a.branch2.1.bn.running_mean\", \"inception3a.branch2.1.bn.running_var\", \"inception3a.branch3.0.conv.weight\", \"inception3a.branch3.0.bn.weight\", \"inception3a.branch3.0.bn.bias\", \"inception3a.branch3.0.bn.running_mean\", \"inception3a.branch3.0.bn.running_var\", \"inception3a.branch3.1.conv.weight\", \"inception3a.branch3.1.bn.weight\", \"inception3a.branch3.1.bn.bias\", \"inception3a.branch3.1.bn.running_mean\", \"inception3a.branch3.1.bn.running_var\", \"inception3a.branch4.1.conv.weight\", \"inception3a.branch4.1.bn.weight\", \"inception3a.branch4.1.bn.bias\", \"inception3a.branch4.1.bn.running_mean\", \"inception3a.branch4.1.bn.running_var\", \"inception3b.branch1.conv.weight\", \"inception3b.branch1.bn.weight\", \"inception3b.branch1.bn.bias\", \"inception3b.branch1.bn.running_mean\", \"inception3b.branch1.bn.running_var\", \"inception3b.branch2.0.conv.weight\", \"inception3b.branch2.0.bn.weight\", \"inception3b.branch2.0.bn.bias\", \"inception3b.branch2.0.bn.running_mean\", \"inception3b.branch2.0.bn.running_var\", \"inception3b.branch2.1.conv.weight\", \"inception3b.branch2.1.bn.weight\", \"inception3b.branch2.1.bn.bias\", \"inception3b.branch2.1.bn.running_mean\", \"inception3b.branch2.1.bn.running_var\", \"inception3b.branch3.0.conv.weight\", \"inception3b.branch3.0.bn.weight\", \"inception3b.branch3.0.bn.bias\", \"inception3b.branch3.0.bn.running_mean\", \"inception3b.branch3.0.bn.running_var\", \"inception3b.branch3.1.conv.weight\", \"inception3b.branch3.1.bn.weight\", \"inception3b.branch3.1.bn.bias\", \"inception3b.branch3.1.bn.running_mean\", \"inception3b.branch3.1.bn.running_var\", \"inception3b.branch4.1.conv.weight\", \"inception3b.branch4.1.bn.weight\", \"inception3b.branch4.1.bn.bias\", \"inception3b.branch4.1.bn.running_mean\", \"inception3b.branch4.1.bn.running_var\", \"inception4a.branch1.conv.weight\", \"inception4a.branch1.bn.weight\", \"inception4a.branch1.bn.bias\", \"inception4a.branch1.bn.running_mean\", \"inception4a.branch1.bn.running_var\", \"inception4a.branch2.0.conv.weight\", \"inception4a.branch2.0.bn.weight\", \"inception4a.branch2.0.bn.bias\", \"inception4a.branch2.0.bn.running_mean\", \"inception4a.branch2.0.bn.running_var\", \"inception4a.branch2.1.conv.weight\", \"inception4a.branch2.1.bn.weight\", \"inception4a.branch2.1.bn.bias\", \"inception4a.branch2.1.bn.running_mean\", \"inception4a.branch2.1.bn.running_var\", \"inception4a.branch3.0.conv.weight\", \"inception4a.branch3.0.bn.weight\", \"inception4a.branch3.0.bn.bias\", \"inception4a.branch3.0.bn.running_mean\", \"inception4a.branch3.0.bn.running_var\", \"inception4a.branch3.1.conv.weight\", \"inception4a.branch3.1.bn.weight\", \"inception4a.branch3.1.bn.bias\", \"inception4a.branch3.1.bn.running_mean\", \"inception4a.branch3.1.bn.running_var\", \"inception4a.branch4.1.conv.weight\", \"inception4a.branch4.1.bn.weight\", \"inception4a.branch4.1.bn.bias\", \"inception4a.branch4.1.bn.running_mean\", \"inception4a.branch4.1.bn.running_var\", \"inception4b.branch1.conv.weight\", \"inception4b.branch1.bn.weight\", \"inception4b.branch1.bn.bias\", \"inception4b.branch1.bn.running_mean\", \"inception4b.branch1.bn.running_var\", \"inception4b.branch2.0.conv.weight\", \"inception4b.branch2.0.bn.weight\", \"inception4b.branch2.0.bn.bias\", \"inception4b.branch2.0.bn.running_mean\", \"inception4b.branch2.0.bn.running_var\", \"inception4b.branch2.1.conv.weight\", \"inception4b.branch2.1.bn.weight\", \"inception4b.branch2.1.bn.bias\", \"inception4b.branch2.1.bn.running_mean\", \"inception4b.branch2.1.bn.running_var\", \"inception4b.branch3.0.conv.weight\", \"inception4b.branch3.0.bn.weight\", \"inception4b.branch3.0.bn.bias\", \"inception4b.branch3.0.bn.running_mean\", \"inception4b.branch3.0.bn.running_var\", \"inception4b.branch3.1.conv.weight\", \"inception4b.branch3.1.bn.weight\", \"inception4b.branch3.1.bn.bias\", \"inception4b.branch3.1.bn.running_mean\", \"inception4b.branch3.1.bn.running_var\", \"inception4b.branch4.1.conv.weight\", \"inception4b.branch4.1.bn.weight\", \"inception4b.branch4.1.bn.bias\", \"inception4b.branch4.1.bn.running_mean\", \"inception4b.branch4.1.bn.running_var\", \"inception4c.branch1.conv.weight\", \"inception4c.branch1.bn.weight\", \"inception4c.branch1.bn.bias\", \"inception4c.branch1.bn.running_mean\", \"inception4c.branch1.bn.running_var\", \"inception4c.branch2.0.conv.weight\", \"inception4c.branch2.0.bn.weight\", \"inception4c.branch2.0.bn.bias\", \"inception4c.branch2.0.bn.running_mean\", \"inception4c.branch2.0.bn.running_var\", \"inception4c.branch2.1.conv.weight\", \"inception4c.branch2.1.bn.weight\", \"inception4c.branch2.1.bn.bias\", \"inception4c.branch2.1.bn.running_mean\", \"inception4c.branch2.1.bn.running_var\", \"inception4c.branch3.0.conv.weight\", \"inception4c.branch3.0.bn.weight\", \"inception4c.branch3.0.bn.bias\", \"inception4c.branch3.0.bn.running_mean\", \"inception4c.branch3.0.bn.running_var\", \"inception4c.branch3.1.conv.weight\", \"inception4c.branch3.1.bn.weight\", \"inception4c.branch3.1.bn.bias\", \"inception4c.branch3.1.bn.running_mean\", \"inception4c.branch3.1.bn.running_var\", \"inception4c.branch4.1.conv.weight\", \"inception4c.branch4.1.bn.weight\", \"inception4c.branch4.1.bn.bias\", \"inception4c.branch4.1.bn.running_mean\", \"inception4c.branch4.1.bn.running_var\", \"inception4d.branch1.conv.weight\", \"inception4d.branch1.bn.weight\", \"inception4d.branch1.bn.bias\", \"inception4d.branch1.bn.running_mean\", \"inception4d.branch1.bn.running_var\", \"inception4d.branch2.0.conv.weight\", \"inception4d.branch2.0.bn.weight\", \"inception4d.branch2.0.bn.bias\", \"inception4d.branch2.0.bn.running_mean\", \"inception4d.branch2.0.bn.running_var\", \"inception4d.branch2.1.conv.weight\", \"inception4d.branch2.1.bn.weight\", \"inception4d.branch2.1.bn.bias\", \"inception4d.branch2.1.bn.running_mean\", \"inception4d.branch2.1.bn.running_var\", \"inception4d.branch3.0.conv.weight\", \"inception4d.branch3.0.bn.weight\", \"inception4d.branch3.0.bn.bias\", \"inception4d.branch3.0.bn.running_mean\", \"inception4d.branch3.0.bn.running_var\", \"inception4d.branch3.1.conv.weight\", \"inception4d.branch3.1.bn.weight\", \"inception4d.branch3.1.bn.bias\", \"inception4d.branch3.1.bn.running_mean\", \"inception4d.branch3.1.bn.running_var\", \"inception4d.branch4.1.conv.weight\", \"inception4d.branch4.1.bn.weight\", \"inception4d.branch4.1.bn.bias\", \"inception4d.branch4.1.bn.running_mean\", \"inception4d.branch4.1.bn.running_var\", \"inception4e.branch1.conv.weight\", \"inception4e.branch1.bn.weight\", \"inception4e.branch1.bn.bias\", \"inception4e.branch1.bn.running_mean\", \"inception4e.branch1.bn.running_var\", \"inception4e.branch2.0.conv.weight\", \"inception4e.branch2.0.bn.weight\", \"inception4e.branch2.0.bn.bias\", \"inception4e.branch2.0.bn.running_mean\", \"inception4e.branch2.0.bn.running_var\", \"inception4e.branch2.1.conv.weight\", \"inception4e.branch2.1.bn.weight\", \"inception4e.branch2.1.bn.bias\", \"inception4e.branch2.1.bn.running_mean\", \"inception4e.branch2.1.bn.running_var\", \"inception4e.branch3.0.conv.weight\", \"inception4e.branch3.0.bn.weight\", \"inception4e.branch3.0.bn.bias\", \"inception4e.branch3.0.bn.running_mean\", \"inception4e.branch3.0.bn.running_var\", \"inception4e.branch3.1.conv.weight\", \"inception4e.branch3.1.bn.weight\", \"inception4e.branch3.1.bn.bias\", \"inception4e.branch3.1.bn.running_mean\", \"inception4e.branch3.1.bn.running_var\", \"inception4e.branch4.1.conv.weight\", \"inception4e.branch4.1.bn.weight\", \"inception4e.branch4.1.bn.bias\", \"inception4e.branch4.1.bn.running_mean\", \"inception4e.branch4.1.bn.running_var\", \"inception5a.branch1.conv.weight\", \"inception5a.branch1.bn.weight\", \"inception5a.branch1.bn.bias\", \"inception5a.branch1.bn.running_mean\", \"inception5a.branch1.bn.running_var\", \"inception5a.branch2.0.conv.weight\", \"inception5a.branch2.0.bn.weight\", \"inception5a.branch2.0.bn.bias\", \"inception5a.branch2.0.bn.running_mean\", \"inception5a.branch2.0.bn.running_var\", \"inception5a.branch2.1.conv.weight\", \"inception5a.branch2.1.bn.weight\", \"inception5a.branch2.1.bn.bias\", \"inception5a.branch2.1.bn.running_mean\", \"inception5a.branch2.1.bn.running_var\", \"inception5a.branch3.0.conv.weight\", \"inception5a.branch3.0.bn.weight\", \"inception5a.branch3.0.bn.bias\", \"inception5a.branch3.0.bn.running_mean\", \"inception5a.branch3.0.bn.running_var\", \"inception5a.branch3.1.conv.weight\", \"inception5a.branch3.1.bn.weight\", \"inception5a.branch3.1.bn.bias\", \"inception5a.branch3.1.bn.running_mean\", \"inception5a.branch3.1.bn.running_var\", \"inception5a.branch4.1.conv.weight\", \"inception5a.branch4.1.bn.weight\", \"inception5a.branch4.1.bn.bias\", \"inception5a.branch4.1.bn.running_mean\", \"inception5a.branch4.1.bn.running_var\", \"inception5b.branch1.conv.weight\", \"inception5b.branch1.bn.weight\", \"inception5b.branch1.bn.bias\", \"inception5b.branch1.bn.running_mean\", \"inception5b.branch1.bn.running_var\", \"inception5b.branch2.0.conv.weight\", \"inception5b.branch2.0.bn.weight\", \"inception5b.branch2.0.bn.bias\", \"inception5b.branch2.0.bn.running_mean\", \"inception5b.branch2.0.bn.running_var\", \"inception5b.branch2.1.conv.weight\", \"inception5b.branch2.1.bn.weight\", \"inception5b.branch2.1.bn.bias\", \"inception5b.branch2.1.bn.running_mean\", \"inception5b.branch2.1.bn.running_var\", \"inception5b.branch3.0.conv.weight\", \"inception5b.branch3.0.bn.weight\", \"inception5b.branch3.0.bn.bias\", \"inception5b.branch3.0.bn.running_mean\", \"inception5b.branch3.0.bn.running_var\", \"inception5b.branch3.1.conv.weight\", \"inception5b.branch3.1.bn.weight\", \"inception5b.branch3.1.bn.bias\", \"inception5b.branch3.1.bn.running_mean\", \"inception5b.branch3.1.bn.running_var\", \"inception5b.branch4.1.conv.weight\", \"inception5b.branch4.1.bn.weight\", \"inception5b.branch4.1.bn.bias\", \"inception5b.branch4.1.bn.running_mean\", \"inception5b.branch4.1.bn.running_var\", \"fc.weight\", \"fc.bias\". \n\tUnexpected key(s) in state_dict: \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"bn1.num_batches_tracked\", \"bn2.weight\", \"bn2.bias\", \"bn2.running_mean\", \"bn2.running_var\", \"bn2.num_batches_tracked\", \"fc1.weight\", \"fc1.bias\", \"fc2.weight\", \"fc2.bias\", \"conv1.weight\", \"conv2.weight\". "
     ]
    }
   ],
   "source": [
    "def forward_vis(vis_loader, groups):\n",
    "    since = time.time()\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    model = models.googlenet(aux_logits=False)\n",
    "    set_parameter_requires_grad(model, feature_extract)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    # load best model weights\n",
    "    state_dict = torch.load('model_weight/2_layer_model_'+str(num_epochs))\n",
    "    print(state_dict.keys())\n",
    "    model.load_state_dict(torch.load('model_weight/2_layer_model_'+str(num_epochs)))\n",
    "    model.to(device)\n",
    "    model.eval()   # Set model to evaluate mode\n",
    "    # Iterate over data.\n",
    "    cnt=0\n",
    "    vis_dict = {'inputs':np.empty([groups,vis_batch,3,224,224]),'outputs':np.empty([groups,vis_batch,num_classes]),'labels':np.empty([groups,vis_batch]),'preds':np.empty([groups,vis_batch])}\n",
    "    for inputs, labels in vis_loader:\n",
    "            if(cnt==groups):\n",
    "                break;\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            vis_dict['inputs'][cnt,:,:,:,:]=inputs.cpu().numpy()\n",
    "            vis_dict['labels'][cnt,:]=labels.cpu().numpy()\n",
    "            # forward\n",
    "            # track history if only in train\n",
    "            with torch.set_grad_enabled(False):\n",
    "            # Get model outputs and calculate loss\n",
    "            # Special case for inception because in training it has an auxiliary output. In train\n",
    "            #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "            #   but in testing we only consider the final output.\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                vis_dict['outputs'][cnt,:,:]=outputs.cpu().numpy()\n",
    "                vis_dict['preds'][cnt,:]=preds.cpu().numpy()\n",
    "            cnt+=1\n",
    "            \n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print()\n",
    "    print('Inference complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    return vis_dict\n",
    "\n",
    "vis_loader = torch.utils.data.DataLoader(image_datasets['val'], batch_size=vis_batch, shuffle=True, num_workers=8)\n",
    "vis_dict = forward_vis(vis_loader, groups)\n",
    "print(vis_dict['inputs'].shape)\n",
    "print(vis_dict['outputs'].shape)\n",
    "print(vis_dict['labels'].shape)\n",
    "print(vis_dict['preds'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(groups) :\n",
    "    for j in range(vis_batch) :\n",
    "        plt.figure(figsize=(15,15))\n",
    "        plt.subplot(groups,vis_batch,4*i+j+1)\n",
    "        image = np.moveaxis(np.squeeze(vis_dict['inputs'][i,j]), 0, -1)\n",
    "        image = (image-np.amin(image))/(np.amax(image)-np.amin(image))\n",
    "        plt.imshow(image)\n",
    "        plt.tick_params(\n",
    "        axis='both',          # changes apply to the x-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        bottom=False,      # ticks along the bottom edge are off\n",
    "        left=False,         # ticks along the left edge are off\n",
    "        labelbottom=False,\n",
    "        labelleft=False) # labels along the bottom edge are off\n",
    "        plt.title('preprocessed '+str(i)+' '+str(j))\n",
    "        plt.xlabel('label : '+str(vis_dict['labels'][i,j])+', pred : '+str(vis_dict['preds'][i,j])+', output : '+str(vis_dict['outputs'][i,j,:]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
