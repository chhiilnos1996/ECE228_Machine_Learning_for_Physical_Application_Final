{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whale Detection Challenge : NN_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method overview : FFT to convert the sound tracks into spectrograms, and apply distinct preprocessing methods such as clipping, noise removal, PCEN and filters. After preprocessing we feed the spectrograms into state of the art light CNN models such as Resnet 18, VGG 16 or GoogleNet to identify right whale call patterns and perform classification. We may also try the removal of pooling layers in the networks and see if it causes better outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.3.1\n",
      "Torchvision Version:  0.4.2\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "batch_size = 32\n",
    "num_epochs = 200\n",
    "feature_extract = True\n",
    "groups = 3\n",
    "vis_batch = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"data/\"\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((64,64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((64,64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x+\"_prep_10/\"), data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=8) for x in ['train', 'val']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The small CNN model\n",
    "class small_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(small_model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, kernel_size=7, stride=1, padding=(3, 3), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.conv2 = nn.Conv2d(8, 8, kernel_size=7, stride=1, padding=(3, 3), bias=False)\n",
    "        \n",
    "        self.dropout = nn.Dropout2d(p=0.3)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(8, 16, kernel_size=5, stride=1, padding=(2, 2), bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.conv4 = nn.Conv2d(16, 16, kernel_size=5, stride=1, padding=(2, 2), bias=False)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=(1, 1), bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.conv6 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=(1, 1), bias=False)\n",
    "        \n",
    "        self.flat = nn.Flatten()\n",
    "        \n",
    "        self.fc1 = nn.Linear(2048, 2048)\n",
    "        self.bn4 = nn.BatchNorm1d(2048, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        \n",
    "        self.fc2 = nn.Linear(2048, 512)\n",
    "        self.bn5 = nn.BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        \n",
    "        self.fc3 = nn.Linear(512, 1024)\n",
    "        self.bn6 = nn.BatchNorm1d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        \n",
    "        self.fc4 = nn.Linear(1024, 2)\n",
    "        self.bn7 = nn.BatchNorm1d(2, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn1(self.conv2(x)))\n",
    "        x = F.relu(self.bn1(self.conv2(x)))\n",
    "        x = self.dropout(self.pool(x))\n",
    "        \n",
    "        x = F.relu(self.bn2(self.conv3(x)))\n",
    "        x = F.relu(self.bn2(self.conv4(x)))\n",
    "        x = F.relu(self.bn2(self.conv4(x)))\n",
    "        x = self.dropout(self.pool(x))\n",
    "    \n",
    "        x = F.relu(self.bn3(self.conv5(x)))\n",
    "        x = F.relu(self.bn3(self.conv6(x)))\n",
    "        x = F.relu(self.bn3(self.conv6(x)))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.flat(x)\n",
    "               \n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x)))\n",
    "        x = F.relu(self.bn6(self.fc3(x)))\n",
    "        x = F.relu(self.bn7(self.fc4(x)))\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small_model(\n",
      "  (conv1): Conv2d(3, 8, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(8, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(8, 8, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "  (dropout): Dropout2d(p=0.3, inplace=False)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (conv3): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "  (bn2): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): Conv2d(16, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "  (conv5): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (flat): Flatten()\n",
      "  (fc1): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "  (bn4): BatchNorm1d(2048, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "  (bn5): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=512, out_features=1024, bias=True)\n",
      "  (bn6): BatchNorm1d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc4): Linear(in_features=1024, out_features=2, bias=True)\n",
      "  (bn7): BatchNorm1d(2, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "def initialize_model(num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = small_model()\n",
    "#     num_ftrs = model_ft.fc3.out_features\n",
    "#     model_ft.fc4 = nn.Linear(num_ftrs, num_classes)\n",
    "    input_size = (64, 64)  \n",
    "    return model_ft, input_size\n",
    "\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training fuction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "    history = {'train_loss':[],'train_acc':[],'val_loss':[],'val_acc':[]}\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0\n",
    "            running_corrects = 0\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'train':\n",
    "                history['train_loss'].append(epoch_loss)\n",
    "                history['train_acc'].append(epoch_acc)\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                history['val_loss'].append(epoch_loss)\n",
    "                history['val_acc'].append(epoch_acc)\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, history, best_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t conv1.weight\n",
      "\t bn1.weight\n",
      "\t bn1.bias\n",
      "\t conv2.weight\n",
      "\t conv3.weight\n",
      "\t bn2.weight\n",
      "\t bn2.bias\n",
      "\t conv4.weight\n",
      "\t conv5.weight\n",
      "\t bn3.weight\n",
      "\t bn3.bias\n",
      "\t conv6.weight\n",
      "\t fc1.weight\n",
      "\t fc1.bias\n",
      "\t bn4.weight\n",
      "\t bn4.bias\n",
      "\t fc2.weight\n",
      "\t fc2.bias\n",
      "\t bn5.weight\n",
      "\t bn5.bias\n",
      "\t fc3.weight\n",
      "\t fc3.bias\n",
      "\t bn6.weight\n",
      "\t bn6.bias\n",
      "\t fc4.weight\n",
      "\t fc4.bias\n",
      "\t bn7.weight\n",
      "\t bn7.bias\n"
     ]
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/199\n",
      "----------\n",
      "train Loss: 0.6662 Acc: 0.7053\n",
      "val Loss: 0.5938 Acc: 0.7983\n",
      "\n",
      "Epoch 1/199\n",
      "----------\n",
      "train Loss: 0.4932 Acc: 0.8557\n",
      "val Loss: 0.4612 Acc: 0.8477\n",
      "\n",
      "Epoch 2/199\n",
      "----------\n",
      "train Loss: 0.4394 Acc: 0.8630\n",
      "val Loss: 0.4151 Acc: 0.8853\n",
      "\n",
      "Epoch 3/199\n",
      "----------\n",
      "train Loss: 0.3978 Acc: 0.8690\n",
      "val Loss: 0.3954 Acc: 0.8673\n",
      "\n",
      "Epoch 4/199\n",
      "----------\n",
      "train Loss: 0.3685 Acc: 0.8770\n",
      "val Loss: 0.3999 Acc: 0.8443\n",
      "\n",
      "Epoch 5/199\n",
      "----------\n",
      "train Loss: 0.3475 Acc: 0.8790\n",
      "val Loss: 0.4582 Acc: 0.7890\n",
      "\n",
      "Epoch 6/199\n",
      "----------\n",
      "train Loss: 0.3386 Acc: 0.8797\n",
      "val Loss: 0.3616 Acc: 0.8310\n",
      "\n",
      "Epoch 7/199\n",
      "----------\n",
      "train Loss: 0.3266 Acc: 0.8820\n",
      "val Loss: 0.3483 Acc: 0.8580\n",
      "\n",
      "Epoch 8/199\n",
      "----------\n",
      "train Loss: 0.3098 Acc: 0.8940\n",
      "val Loss: 0.3427 Acc: 0.8713\n",
      "\n",
      "Epoch 9/199\n",
      "----------\n",
      "train Loss: 0.2949 Acc: 0.8957\n",
      "val Loss: 0.3444 Acc: 0.8330\n",
      "\n",
      "Epoch 10/199\n",
      "----------\n",
      "train Loss: 0.2914 Acc: 0.8990\n",
      "val Loss: 0.3282 Acc: 0.8607\n",
      "\n",
      "Epoch 11/199\n",
      "----------\n",
      "train Loss: 0.2908 Acc: 0.8930\n",
      "val Loss: 0.3139 Acc: 0.8843\n",
      "\n",
      "Epoch 12/199\n",
      "----------\n",
      "train Loss: 0.2771 Acc: 0.9007\n",
      "val Loss: 0.3215 Acc: 0.8783\n",
      "\n",
      "Epoch 13/199\n",
      "----------\n",
      "train Loss: 0.2691 Acc: 0.9030\n",
      "val Loss: 0.3044 Acc: 0.8870\n",
      "\n",
      "Epoch 14/199\n",
      "----------\n",
      "train Loss: 0.2646 Acc: 0.8980\n",
      "val Loss: 0.3099 Acc: 0.8887\n",
      "\n",
      "Epoch 15/199\n",
      "----------\n",
      "train Loss: 0.2542 Acc: 0.9123\n",
      "val Loss: 0.3112 Acc: 0.8750\n",
      "\n",
      "Epoch 16/199\n",
      "----------\n",
      "train Loss: 0.2460 Acc: 0.9130\n",
      "val Loss: 0.2814 Acc: 0.8893\n",
      "\n",
      "Epoch 17/199\n",
      "----------\n",
      "train Loss: 0.2477 Acc: 0.9110\n",
      "val Loss: 0.3525 Acc: 0.8387\n",
      "\n",
      "Epoch 18/199\n",
      "----------\n",
      "train Loss: 0.2337 Acc: 0.9140\n",
      "val Loss: 0.2872 Acc: 0.8857\n",
      "\n",
      "Epoch 19/199\n",
      "----------\n",
      "train Loss: 0.2374 Acc: 0.9170\n",
      "val Loss: 0.3348 Acc: 0.8510\n",
      "\n",
      "Epoch 20/199\n",
      "----------\n",
      "train Loss: 0.2297 Acc: 0.9187\n",
      "val Loss: 0.2992 Acc: 0.8800\n",
      "\n",
      "Epoch 21/199\n",
      "----------\n",
      "train Loss: 0.2196 Acc: 0.9270\n",
      "val Loss: 0.2981 Acc: 0.8747\n",
      "\n",
      "Epoch 22/199\n",
      "----------\n",
      "train Loss: 0.2132 Acc: 0.9270\n",
      "val Loss: 0.3039 Acc: 0.8707\n",
      "\n",
      "Epoch 23/199\n",
      "----------\n",
      "train Loss: 0.2046 Acc: 0.9323\n",
      "val Loss: 0.4032 Acc: 0.7923\n",
      "\n",
      "Epoch 24/199\n",
      "----------\n",
      "train Loss: 0.2036 Acc: 0.9327\n",
      "val Loss: 0.2857 Acc: 0.8847\n",
      "\n",
      "Epoch 25/199\n",
      "----------\n",
      "train Loss: 0.1940 Acc: 0.9363\n",
      "val Loss: 0.2899 Acc: 0.8820\n",
      "\n",
      "Epoch 26/199\n",
      "----------\n",
      "train Loss: 0.1842 Acc: 0.9433\n",
      "val Loss: 0.3439 Acc: 0.8470\n",
      "\n",
      "Epoch 27/199\n",
      "----------\n",
      "train Loss: 0.1756 Acc: 0.9483\n",
      "val Loss: 0.2814 Acc: 0.8823\n",
      "\n",
      "Epoch 28/199\n",
      "----------\n",
      "train Loss: 0.1734 Acc: 0.9477\n",
      "val Loss: 0.2899 Acc: 0.8830\n",
      "\n",
      "Epoch 29/199\n",
      "----------\n",
      "train Loss: 0.1628 Acc: 0.9543\n",
      "val Loss: 0.3862 Acc: 0.8270\n",
      "\n",
      "Epoch 30/199\n",
      "----------\n",
      "train Loss: 0.1551 Acc: 0.9637\n",
      "val Loss: 0.3120 Acc: 0.8697\n",
      "\n",
      "Epoch 31/199\n",
      "----------\n",
      "train Loss: 0.1452 Acc: 0.9667\n",
      "val Loss: 0.3209 Acc: 0.8633\n",
      "\n",
      "Epoch 32/199\n",
      "----------\n",
      "train Loss: 0.1445 Acc: 0.9643\n",
      "val Loss: 0.3575 Acc: 0.8507\n",
      "\n",
      "Epoch 33/199\n",
      "----------\n",
      "train Loss: 0.1323 Acc: 0.9733\n",
      "val Loss: 0.2944 Acc: 0.8757\n",
      "\n",
      "Epoch 34/199\n",
      "----------\n",
      "train Loss: 0.1227 Acc: 0.9767\n",
      "val Loss: 0.3033 Acc: 0.8753\n",
      "\n",
      "Epoch 35/199\n",
      "----------\n",
      "train Loss: 0.1244 Acc: 0.9750\n",
      "val Loss: 0.3346 Acc: 0.8623\n",
      "\n",
      "Epoch 36/199\n",
      "----------\n",
      "train Loss: 0.1059 Acc: 0.9860\n",
      "val Loss: 0.3131 Acc: 0.8703\n",
      "\n",
      "Epoch 37/199\n",
      "----------\n",
      "train Loss: 0.1051 Acc: 0.9833\n",
      "val Loss: 0.4741 Acc: 0.7887\n",
      "\n",
      "Epoch 38/199\n",
      "----------\n",
      "train Loss: 0.1013 Acc: 0.9873\n",
      "val Loss: 0.3344 Acc: 0.8570\n",
      "\n",
      "Epoch 39/199\n",
      "----------\n",
      "train Loss: 0.0941 Acc: 0.9870\n",
      "val Loss: 0.3279 Acc: 0.8643\n",
      "\n",
      "Epoch 40/199\n",
      "----------\n",
      "train Loss: 0.0959 Acc: 0.9843\n",
      "val Loss: 0.4074 Acc: 0.8173\n",
      "\n",
      "Epoch 41/199\n",
      "----------\n",
      "train Loss: 0.0928 Acc: 0.9877\n",
      "val Loss: 0.3101 Acc: 0.8687\n",
      "\n",
      "Epoch 42/199\n",
      "----------\n",
      "train Loss: 0.0899 Acc: 0.9880\n",
      "val Loss: 0.2811 Acc: 0.8910\n",
      "\n",
      "Epoch 43/199\n",
      "----------\n",
      "train Loss: 0.0796 Acc: 0.9940\n",
      "val Loss: 0.3392 Acc: 0.8527\n",
      "\n",
      "Epoch 44/199\n",
      "----------\n",
      "train Loss: 0.0809 Acc: 0.9920\n",
      "val Loss: 0.2780 Acc: 0.8863\n",
      "\n",
      "Epoch 45/199\n",
      "----------\n",
      "train Loss: 0.0763 Acc: 0.9943\n",
      "val Loss: 0.3098 Acc: 0.8693\n",
      "\n",
      "Epoch 46/199\n",
      "----------\n",
      "train Loss: 0.0712 Acc: 0.9967\n",
      "val Loss: 0.3536 Acc: 0.8457\n",
      "\n",
      "Epoch 47/199\n",
      "----------\n",
      "train Loss: 0.0695 Acc: 0.9953\n",
      "val Loss: 0.3361 Acc: 0.8550\n",
      "\n",
      "Epoch 48/199\n",
      "----------\n",
      "train Loss: 0.0700 Acc: 0.9967\n",
      "val Loss: 0.3441 Acc: 0.8540\n",
      "\n",
      "Epoch 49/199\n",
      "----------\n",
      "train Loss: 0.0700 Acc: 0.9933\n",
      "val Loss: 0.3330 Acc: 0.8577\n",
      "\n",
      "Epoch 50/199\n",
      "----------\n",
      "train Loss: 0.0670 Acc: 0.9953\n",
      "val Loss: 0.3111 Acc: 0.8640\n",
      "\n",
      "Epoch 51/199\n",
      "----------\n",
      "train Loss: 0.0663 Acc: 0.9967\n",
      "val Loss: 0.3086 Acc: 0.8647\n",
      "\n",
      "Epoch 52/199\n",
      "----------\n",
      "train Loss: 0.0623 Acc: 0.9973\n",
      "val Loss: 0.3369 Acc: 0.8483\n",
      "\n",
      "Epoch 53/199\n",
      "----------\n",
      "train Loss: 0.0590 Acc: 0.9990\n",
      "val Loss: 0.2996 Acc: 0.8697\n",
      "\n",
      "Epoch 54/199\n",
      "----------\n",
      "train Loss: 0.0651 Acc: 0.9947\n",
      "val Loss: 0.3084 Acc: 0.8630\n",
      "\n",
      "Epoch 55/199\n",
      "----------\n",
      "train Loss: 0.0580 Acc: 0.9977\n",
      "val Loss: 0.2876 Acc: 0.8797\n",
      "\n",
      "Epoch 56/199\n",
      "----------\n",
      "train Loss: 0.0567 Acc: 0.9970\n",
      "val Loss: 0.3337 Acc: 0.8533\n",
      "\n",
      "Epoch 57/199\n",
      "----------\n",
      "train Loss: 0.0584 Acc: 0.9983\n",
      "val Loss: 0.3965 Acc: 0.8180\n",
      "\n",
      "Epoch 58/199\n",
      "----------\n",
      "train Loss: 0.0611 Acc: 0.9973\n",
      "val Loss: 0.2868 Acc: 0.8737\n",
      "\n",
      "Epoch 59/199\n",
      "----------\n",
      "train Loss: 0.0674 Acc: 0.9927\n",
      "val Loss: 0.3048 Acc: 0.8707\n",
      "\n",
      "Epoch 60/199\n",
      "----------\n",
      "train Loss: 0.0650 Acc: 0.9940\n",
      "val Loss: 0.3136 Acc: 0.8633\n",
      "\n",
      "Epoch 61/199\n",
      "----------\n",
      "train Loss: 0.0613 Acc: 0.9963\n",
      "val Loss: 0.3717 Acc: 0.8247\n",
      "\n",
      "Epoch 62/199\n",
      "----------\n",
      "train Loss: 0.0597 Acc: 0.9960\n",
      "val Loss: 0.2929 Acc: 0.8743\n",
      "\n",
      "Epoch 63/199\n",
      "----------\n",
      "train Loss: 0.0537 Acc: 0.9983\n",
      "val Loss: 0.3041 Acc: 0.8687\n",
      "\n",
      "Epoch 64/199\n",
      "----------\n",
      "train Loss: 0.0551 Acc: 0.9977\n",
      "val Loss: 0.3131 Acc: 0.8630\n",
      "\n",
      "Epoch 65/199\n",
      "----------\n",
      "train Loss: 0.0550 Acc: 0.9983\n",
      "val Loss: 0.3840 Acc: 0.8253\n",
      "\n",
      "Epoch 66/199\n",
      "----------\n",
      "train Loss: 0.0551 Acc: 0.9973\n",
      "val Loss: 0.3863 Acc: 0.8203\n",
      "\n",
      "Epoch 67/199\n",
      "----------\n",
      "train Loss: 0.0496 Acc: 0.9993\n",
      "val Loss: 0.3988 Acc: 0.8147\n",
      "\n",
      "Epoch 68/199\n",
      "----------\n",
      "train Loss: 0.0498 Acc: 0.9990\n",
      "val Loss: 0.3392 Acc: 0.8410\n",
      "\n",
      "Epoch 69/199\n",
      "----------\n",
      "train Loss: 0.0490 Acc: 1.0000\n",
      "val Loss: 0.3766 Acc: 0.8293\n",
      "\n",
      "Epoch 70/199\n",
      "----------\n",
      "train Loss: 0.0509 Acc: 0.9980\n",
      "val Loss: 0.3440 Acc: 0.8383\n",
      "\n",
      "Epoch 71/199\n",
      "----------\n",
      "train Loss: 0.0493 Acc: 0.9990\n",
      "val Loss: 0.3959 Acc: 0.8170\n",
      "\n",
      "Epoch 72/199\n",
      "----------\n",
      "train Loss: 0.0536 Acc: 0.9973\n",
      "val Loss: 0.3879 Acc: 0.8260\n",
      "\n",
      "Epoch 73/199\n",
      "----------\n",
      "train Loss: 0.0492 Acc: 0.9993\n",
      "val Loss: 0.3970 Acc: 0.8127\n",
      "\n",
      "Epoch 74/199\n",
      "----------\n",
      "train Loss: 0.0462 Acc: 1.0000\n",
      "val Loss: 0.3201 Acc: 0.8613\n",
      "\n",
      "Epoch 75/199\n",
      "----------\n",
      "train Loss: 0.0530 Acc: 0.9960\n",
      "val Loss: 0.3781 Acc: 0.8240\n",
      "\n",
      "Epoch 76/199\n",
      "----------\n",
      "train Loss: 0.0485 Acc: 0.9990\n",
      "val Loss: 0.4078 Acc: 0.8210\n",
      "\n",
      "Epoch 77/199\n",
      "----------\n",
      "train Loss: 0.0457 Acc: 0.9993\n",
      "val Loss: 0.4058 Acc: 0.8157\n",
      "\n",
      "Epoch 78/199\n",
      "----------\n",
      "train Loss: 0.0455 Acc: 0.9997\n",
      "val Loss: 0.3718 Acc: 0.8270\n",
      "\n",
      "Epoch 79/199\n",
      "----------\n",
      "train Loss: 0.0492 Acc: 0.9980\n",
      "val Loss: 0.3910 Acc: 0.8213\n",
      "\n",
      "Epoch 80/199\n",
      "----------\n",
      "train Loss: 0.0529 Acc: 0.9977\n",
      "val Loss: 0.3323 Acc: 0.8507\n",
      "\n",
      "Epoch 81/199\n",
      "----------\n",
      "train Loss: 0.0543 Acc: 0.9960\n",
      "val Loss: 0.4788 Acc: 0.7813\n",
      "\n",
      "Epoch 82/199\n",
      "----------\n",
      "train Loss: 0.0519 Acc: 0.9967\n",
      "val Loss: 0.3149 Acc: 0.8630\n",
      "\n",
      "Epoch 83/199\n",
      "----------\n",
      "train Loss: 0.0575 Acc: 0.9970\n",
      "val Loss: 0.6406 Acc: 0.7690\n",
      "\n",
      "Epoch 84/199\n",
      "----------\n",
      "train Loss: 0.0515 Acc: 0.9977\n",
      "val Loss: 0.4126 Acc: 0.8190\n",
      "\n",
      "Epoch 85/199\n",
      "----------\n",
      "train Loss: 0.0550 Acc: 0.9950\n",
      "val Loss: 0.3146 Acc: 0.8617\n",
      "\n",
      "Epoch 86/199\n",
      "----------\n",
      "train Loss: 0.0499 Acc: 0.9983\n",
      "val Loss: 0.3651 Acc: 0.8360\n",
      "\n",
      "Epoch 87/199\n",
      "----------\n",
      "train Loss: 0.0495 Acc: 0.9977\n",
      "val Loss: 0.4088 Acc: 0.8177\n",
      "\n",
      "Epoch 88/199\n",
      "----------\n",
      "train Loss: 0.0550 Acc: 0.9950\n",
      "val Loss: 0.4335 Acc: 0.8153\n",
      "\n",
      "Epoch 89/199\n",
      "----------\n",
      "train Loss: 0.0487 Acc: 0.9980\n",
      "val Loss: 0.3684 Acc: 0.8403\n",
      "\n",
      "Epoch 90/199\n",
      "----------\n",
      "train Loss: 0.0490 Acc: 0.9977\n",
      "val Loss: 0.4674 Acc: 0.7997\n",
      "\n",
      "Epoch 91/199\n",
      "----------\n",
      "train Loss: 0.0475 Acc: 0.9993\n",
      "val Loss: 0.3244 Acc: 0.8573\n",
      "\n",
      "Epoch 92/199\n",
      "----------\n",
      "train Loss: 0.0442 Acc: 0.9997\n",
      "val Loss: 0.4316 Acc: 0.8043\n",
      "\n",
      "Epoch 93/199\n",
      "----------\n",
      "train Loss: 0.0426 Acc: 0.9997\n",
      "val Loss: 0.3464 Acc: 0.8470\n",
      "\n",
      "Epoch 94/199\n",
      "----------\n",
      "train Loss: 0.0431 Acc: 0.9997\n",
      "val Loss: 0.3902 Acc: 0.8297\n",
      "\n",
      "Epoch 95/199\n",
      "----------\n",
      "train Loss: 0.0451 Acc: 0.9987\n",
      "val Loss: 0.3330 Acc: 0.8473\n",
      "\n",
      "Epoch 96/199\n",
      "----------\n",
      "train Loss: 0.0429 Acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3360 Acc: 0.8440\n",
      "\n",
      "Epoch 97/199\n",
      "----------\n",
      "train Loss: 0.0411 Acc: 1.0000\n",
      "val Loss: 0.3793 Acc: 0.8280\n",
      "\n",
      "Epoch 98/199\n",
      "----------\n",
      "train Loss: 0.0437 Acc: 0.9997\n",
      "val Loss: 0.3921 Acc: 0.8153\n",
      "\n",
      "Epoch 99/199\n",
      "----------\n",
      "train Loss: 0.0410 Acc: 1.0000\n",
      "val Loss: 0.3415 Acc: 0.8427\n",
      "\n",
      "Epoch 100/199\n",
      "----------\n",
      "train Loss: 0.0440 Acc: 0.9990\n",
      "val Loss: 0.3156 Acc: 0.8560\n",
      "\n",
      "Epoch 101/199\n",
      "----------\n",
      "train Loss: 0.0440 Acc: 0.9987\n",
      "val Loss: 0.3172 Acc: 0.8843\n",
      "\n",
      "Epoch 102/199\n",
      "----------\n",
      "train Loss: 0.0425 Acc: 0.9997\n",
      "val Loss: 0.4097 Acc: 0.8177\n",
      "\n",
      "Epoch 103/199\n",
      "----------\n",
      "train Loss: 0.0408 Acc: 0.9997\n",
      "val Loss: 0.3852 Acc: 0.8227\n",
      "\n",
      "Epoch 104/199\n",
      "----------\n",
      "train Loss: 0.0426 Acc: 1.0000\n",
      "val Loss: 0.3537 Acc: 0.8417\n",
      "\n",
      "Epoch 105/199\n",
      "----------\n",
      "train Loss: 0.0390 Acc: 1.0000\n",
      "val Loss: 0.3679 Acc: 0.8320\n",
      "\n",
      "Epoch 106/199\n",
      "----------\n",
      "train Loss: 0.0391 Acc: 1.0000\n",
      "val Loss: 0.4134 Acc: 0.8183\n",
      "\n",
      "Epoch 107/199\n",
      "----------\n",
      "train Loss: 0.0403 Acc: 0.9993\n",
      "val Loss: 0.3828 Acc: 0.8250\n",
      "\n",
      "Epoch 108/199\n",
      "----------\n",
      "train Loss: 0.0403 Acc: 1.0000\n",
      "val Loss: 0.3992 Acc: 0.8200\n",
      "\n",
      "Epoch 109/199\n",
      "----------\n",
      "train Loss: 0.0424 Acc: 0.9997\n",
      "val Loss: 0.3980 Acc: 0.8250\n",
      "\n",
      "Epoch 110/199\n",
      "----------\n",
      "train Loss: 0.0398 Acc: 1.0000\n",
      "val Loss: 0.4127 Acc: 0.8137\n",
      "\n",
      "Epoch 111/199\n",
      "----------\n",
      "train Loss: 0.0404 Acc: 1.0000\n",
      "val Loss: 0.4403 Acc: 0.8027\n",
      "\n",
      "Epoch 112/199\n",
      "----------\n",
      "train Loss: 0.0412 Acc: 0.9993\n",
      "val Loss: 0.3665 Acc: 0.8373\n",
      "\n",
      "Epoch 113/199\n",
      "----------\n",
      "train Loss: 0.0415 Acc: 0.9990\n",
      "val Loss: 0.4606 Acc: 0.7903\n",
      "\n",
      "Epoch 114/199\n",
      "----------\n",
      "train Loss: 0.0421 Acc: 0.9993\n",
      "val Loss: 0.3600 Acc: 0.8390\n",
      "\n",
      "Epoch 115/199\n",
      "----------\n",
      "train Loss: 0.0412 Acc: 0.9993\n",
      "val Loss: 0.3030 Acc: 0.8707\n",
      "\n",
      "Epoch 116/199\n",
      "----------\n",
      "train Loss: 0.0435 Acc: 0.9990\n",
      "val Loss: 0.3034 Acc: 0.8673\n",
      "\n",
      "Epoch 117/199\n",
      "----------\n",
      "train Loss: 0.0426 Acc: 0.9993\n",
      "val Loss: 0.3185 Acc: 0.8593\n",
      "\n",
      "Epoch 118/199\n",
      "----------\n",
      "train Loss: 0.0444 Acc: 0.9980\n",
      "val Loss: 0.3559 Acc: 0.8443\n",
      "\n",
      "Epoch 119/199\n",
      "----------\n",
      "train Loss: 0.0423 Acc: 0.9990\n",
      "val Loss: 0.4285 Acc: 0.8080\n",
      "\n",
      "Epoch 120/199\n",
      "----------\n",
      "train Loss: 0.0408 Acc: 0.9990\n",
      "val Loss: 0.5263 Acc: 0.7813\n",
      "\n",
      "Epoch 121/199\n",
      "----------\n",
      "train Loss: 0.0451 Acc: 0.9993\n",
      "val Loss: 0.4018 Acc: 0.8193\n",
      "\n",
      "Epoch 122/199\n",
      "----------\n",
      "train Loss: 0.0425 Acc: 0.9993\n",
      "val Loss: 0.4509 Acc: 0.8010\n",
      "\n",
      "Epoch 123/199\n",
      "----------\n",
      "train Loss: 0.0457 Acc: 0.9983\n",
      "val Loss: 0.3886 Acc: 0.8277\n",
      "\n",
      "Epoch 124/199\n",
      "----------\n",
      "train Loss: 0.0469 Acc: 0.9980\n",
      "val Loss: 0.3091 Acc: 0.8647\n",
      "\n",
      "Epoch 125/199\n",
      "----------\n",
      "train Loss: 0.0426 Acc: 1.0000\n",
      "val Loss: 0.3636 Acc: 0.8357\n",
      "\n",
      "Epoch 126/199\n",
      "----------\n",
      "train Loss: 0.0396 Acc: 1.0000\n",
      "val Loss: 0.3104 Acc: 0.8640\n",
      "\n",
      "Epoch 127/199\n",
      "----------\n",
      "train Loss: 0.0454 Acc: 0.9983\n",
      "val Loss: 0.3142 Acc: 0.8667\n",
      "\n",
      "Epoch 128/199\n",
      "----------\n",
      "train Loss: 0.0472 Acc: 0.9987\n",
      "val Loss: 0.3263 Acc: 0.8590\n",
      "\n",
      "Epoch 129/199\n",
      "----------\n",
      "train Loss: 0.0954 Acc: 0.9723\n",
      "val Loss: 0.3786 Acc: 0.8657\n",
      "\n",
      "Epoch 130/199\n",
      "----------\n",
      "train Loss: 0.0794 Acc: 0.9830\n",
      "val Loss: 0.3504 Acc: 0.8520\n",
      "\n",
      "Epoch 131/199\n",
      "----------\n",
      "train Loss: 0.0574 Acc: 0.9927\n",
      "val Loss: 0.3093 Acc: 0.8673\n",
      "\n",
      "Epoch 132/199\n",
      "----------\n",
      "train Loss: 0.0557 Acc: 0.9937\n",
      "val Loss: 0.3470 Acc: 0.8567\n",
      "\n",
      "Epoch 133/199\n",
      "----------\n",
      "train Loss: 0.0478 Acc: 0.9970\n",
      "val Loss: 0.2810 Acc: 0.8810\n",
      "\n",
      "Epoch 134/199\n",
      "----------\n",
      "train Loss: 0.0441 Acc: 0.9983\n",
      "val Loss: 0.3254 Acc: 0.8733\n",
      "\n",
      "Epoch 135/199\n",
      "----------\n",
      "train Loss: 0.0439 Acc: 0.9987\n",
      "val Loss: 0.2715 Acc: 0.8903\n",
      "\n",
      "Epoch 136/199\n",
      "----------\n",
      "train Loss: 0.0421 Acc: 0.9997\n",
      "val Loss: 0.2767 Acc: 0.8890\n",
      "\n",
      "Epoch 137/199\n",
      "----------\n",
      "train Loss: 0.0423 Acc: 0.9983\n",
      "val Loss: 0.2769 Acc: 0.8883\n",
      "\n",
      "Epoch 138/199\n",
      "----------\n",
      "train Loss: 0.0506 Acc: 0.9967\n",
      "val Loss: 0.2763 Acc: 0.8827\n",
      "\n",
      "Epoch 139/199\n",
      "----------\n",
      "train Loss: 0.0529 Acc: 0.9950\n",
      "val Loss: 0.2807 Acc: 0.8837\n",
      "\n",
      "Epoch 140/199\n",
      "----------\n",
      "train Loss: 0.0477 Acc: 0.9970\n",
      "val Loss: 0.3268 Acc: 0.8707\n",
      "\n",
      "Epoch 141/199\n",
      "----------\n",
      "train Loss: 0.0440 Acc: 0.9987\n",
      "val Loss: 0.3297 Acc: 0.8633\n",
      "\n",
      "Epoch 142/199\n",
      "----------\n",
      "train Loss: 0.0430 Acc: 0.9997\n",
      "val Loss: 0.3311 Acc: 0.8610\n",
      "\n",
      "Epoch 143/199\n",
      "----------\n",
      "train Loss: 0.0406 Acc: 0.9997\n",
      "val Loss: 0.3499 Acc: 0.8613\n",
      "\n",
      "Epoch 144/199\n",
      "----------\n",
      "train Loss: 0.0414 Acc: 0.9997\n",
      "val Loss: 0.2801 Acc: 0.8807\n",
      "\n",
      "Epoch 145/199\n",
      "----------\n",
      "train Loss: 0.0454 Acc: 0.9973\n",
      "val Loss: 0.4558 Acc: 0.8160\n",
      "\n",
      "Epoch 146/199\n",
      "----------\n",
      "train Loss: 0.0441 Acc: 0.9980\n",
      "val Loss: 0.3356 Acc: 0.8587\n",
      "\n",
      "Epoch 147/199\n",
      "----------\n",
      "train Loss: 0.0508 Acc: 0.9960\n",
      "val Loss: 0.3206 Acc: 0.8670\n",
      "\n",
      "Epoch 148/199\n",
      "----------\n",
      "train Loss: 0.0530 Acc: 0.9943\n",
      "val Loss: 0.3874 Acc: 0.8367\n",
      "\n",
      "Epoch 149/199\n",
      "----------\n",
      "train Loss: 0.0453 Acc: 0.9987\n",
      "val Loss: 0.3212 Acc: 0.8693\n",
      "\n",
      "Epoch 150/199\n",
      "----------\n",
      "train Loss: 0.0439 Acc: 0.9980\n",
      "val Loss: 0.2777 Acc: 0.8877\n",
      "\n",
      "Epoch 151/199\n",
      "----------\n",
      "train Loss: 0.0407 Acc: 0.9990\n",
      "val Loss: 0.2870 Acc: 0.8803\n",
      "\n",
      "Epoch 152/199\n",
      "----------\n",
      "train Loss: 0.0408 Acc: 0.9997\n",
      "val Loss: 0.2851 Acc: 0.8850\n",
      "\n",
      "Epoch 153/199\n",
      "----------\n",
      "train Loss: 0.0408 Acc: 1.0000\n",
      "val Loss: 0.3192 Acc: 0.8673\n",
      "\n",
      "Epoch 154/199\n",
      "----------\n",
      "train Loss: 0.0418 Acc: 0.9993\n",
      "val Loss: 0.2968 Acc: 0.8733\n",
      "\n",
      "Epoch 155/199\n",
      "----------\n",
      "train Loss: 0.0402 Acc: 0.9993\n",
      "val Loss: 0.2704 Acc: 0.8910\n",
      "\n",
      "Epoch 156/199\n",
      "----------\n",
      "train Loss: 0.0422 Acc: 0.9987\n",
      "val Loss: 0.3093 Acc: 0.8743\n",
      "\n",
      "Epoch 157/199\n",
      "----------\n",
      "train Loss: 0.0412 Acc: 0.9993\n",
      "val Loss: 0.2771 Acc: 0.8870\n",
      "\n",
      "Epoch 158/199\n",
      "----------\n",
      "train Loss: 0.0409 Acc: 1.0000\n",
      "val Loss: 0.3060 Acc: 0.8760\n",
      "\n",
      "Epoch 159/199\n",
      "----------\n",
      "train Loss: 0.0423 Acc: 0.9993\n",
      "val Loss: 0.2778 Acc: 0.8870\n",
      "\n",
      "Epoch 160/199\n",
      "----------\n",
      "train Loss: 0.0420 Acc: 1.0000\n",
      "val Loss: 0.2923 Acc: 0.8797\n",
      "\n",
      "Epoch 161/199\n",
      "----------\n",
      "train Loss: 0.0406 Acc: 1.0000\n",
      "val Loss: 0.2771 Acc: 0.8883\n",
      "\n",
      "Epoch 162/199\n",
      "----------\n",
      "train Loss: 0.0393 Acc: 1.0000\n",
      "val Loss: 0.2933 Acc: 0.8760\n",
      "\n",
      "Epoch 163/199\n",
      "----------\n",
      "train Loss: 0.0468 Acc: 0.9970\n",
      "val Loss: 0.3083 Acc: 0.8793\n",
      "\n",
      "Epoch 164/199\n",
      "----------\n",
      "train Loss: 0.0445 Acc: 0.9987\n",
      "val Loss: 0.2730 Acc: 0.8870\n",
      "\n",
      "Epoch 165/199\n",
      "----------\n",
      "train Loss: 0.0407 Acc: 1.0000\n",
      "val Loss: 0.2688 Acc: 0.8943\n",
      "\n",
      "Epoch 166/199\n",
      "----------\n",
      "train Loss: 0.0410 Acc: 1.0000\n",
      "val Loss: 0.3162 Acc: 0.8713\n",
      "\n",
      "Epoch 167/199\n",
      "----------\n",
      "train Loss: 0.0398 Acc: 1.0000\n",
      "val Loss: 0.2888 Acc: 0.8820\n",
      "\n",
      "Epoch 168/199\n",
      "----------\n",
      "train Loss: 0.0398 Acc: 0.9997\n",
      "val Loss: 0.2792 Acc: 0.8890\n",
      "\n",
      "Epoch 169/199\n",
      "----------\n",
      "train Loss: 0.0415 Acc: 1.0000\n",
      "val Loss: 0.2993 Acc: 0.8757\n",
      "\n",
      "Epoch 170/199\n",
      "----------\n",
      "train Loss: 0.0394 Acc: 0.9997\n",
      "val Loss: 0.3125 Acc: 0.8730\n",
      "\n",
      "Epoch 171/199\n",
      "----------\n",
      "train Loss: 0.0447 Acc: 0.9970\n",
      "val Loss: 0.3411 Acc: 0.8473\n",
      "\n",
      "Epoch 172/199\n",
      "----------\n",
      "train Loss: 0.0643 Acc: 0.9867\n",
      "val Loss: 0.2856 Acc: 0.8910\n",
      "\n",
      "Epoch 173/199\n",
      "----------\n",
      "train Loss: 0.0652 Acc: 0.9857\n",
      "val Loss: 0.3150 Acc: 0.8693\n",
      "\n",
      "Epoch 174/199\n",
      "----------\n",
      "train Loss: 0.0629 Acc: 0.9907\n",
      "val Loss: 0.2812 Acc: 0.8970\n",
      "\n",
      "Epoch 175/199\n",
      "----------\n",
      "train Loss: 0.0523 Acc: 0.9957\n",
      "val Loss: 0.2772 Acc: 0.8870\n",
      "\n",
      "Epoch 176/199\n",
      "----------\n",
      "train Loss: 0.0462 Acc: 0.9977\n",
      "val Loss: 0.2627 Acc: 0.8953\n",
      "\n",
      "Epoch 177/199\n",
      "----------\n",
      "train Loss: 0.0439 Acc: 0.9987\n",
      "val Loss: 0.2738 Acc: 0.8903\n",
      "\n",
      "Epoch 178/199\n",
      "----------\n",
      "train Loss: 0.0434 Acc: 0.9993\n",
      "val Loss: 0.2884 Acc: 0.8810\n",
      "\n",
      "Epoch 179/199\n",
      "----------\n",
      "train Loss: 0.0422 Acc: 0.9997\n",
      "val Loss: 0.2696 Acc: 0.8893\n",
      "\n",
      "Epoch 180/199\n",
      "----------\n",
      "train Loss: 0.0414 Acc: 0.9990\n",
      "val Loss: 0.3359 Acc: 0.8640\n",
      "\n",
      "Epoch 181/199\n",
      "----------\n",
      "train Loss: 0.0424 Acc: 0.9980\n",
      "val Loss: 0.2858 Acc: 0.8840\n",
      "\n",
      "Epoch 182/199\n",
      "----------\n",
      "train Loss: 0.0476 Acc: 0.9967\n",
      "val Loss: 0.3465 Acc: 0.8497\n",
      "\n",
      "Epoch 183/199\n",
      "----------\n",
      "train Loss: 0.0481 Acc: 0.9967\n",
      "val Loss: 0.2828 Acc: 0.8900\n",
      "\n",
      "Epoch 184/199\n",
      "----------\n",
      "train Loss: 0.0435 Acc: 0.9987\n",
      "val Loss: 0.2771 Acc: 0.8980\n",
      "\n",
      "Epoch 185/199\n",
      "----------\n",
      "train Loss: 0.0430 Acc: 0.9993\n",
      "val Loss: 0.2673 Acc: 0.8993\n",
      "\n",
      "Epoch 186/199\n",
      "----------\n",
      "train Loss: 0.0419 Acc: 0.9990\n",
      "val Loss: 0.2724 Acc: 0.8893\n",
      "\n",
      "Epoch 187/199\n",
      "----------\n",
      "train Loss: 0.0409 Acc: 1.0000\n",
      "val Loss: 0.2679 Acc: 0.8940\n",
      "\n",
      "Epoch 188/199\n",
      "----------\n",
      "train Loss: 0.0462 Acc: 0.9980\n",
      "val Loss: 0.2865 Acc: 0.8870\n",
      "\n",
      "Epoch 189/199\n",
      "----------\n",
      "train Loss: 0.0472 Acc: 0.9973\n",
      "val Loss: 0.2931 Acc: 0.8830\n",
      "\n",
      "Epoch 190/199\n",
      "----------\n",
      "train Loss: 0.0566 Acc: 0.9933\n",
      "val Loss: 0.2677 Acc: 0.8887\n",
      "\n",
      "Epoch 191/199\n",
      "----------\n",
      "train Loss: 0.0600 Acc: 0.9927\n",
      "val Loss: 0.5386 Acc: 0.8027\n",
      "\n",
      "Epoch 192/199\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0482 Acc: 0.9960\n",
      "val Loss: 0.2670 Acc: 0.8970\n",
      "\n",
      "Epoch 193/199\n",
      "----------\n",
      "train Loss: 0.0522 Acc: 0.9940\n",
      "val Loss: 0.2924 Acc: 0.8833\n",
      "\n",
      "Epoch 194/199\n",
      "----------\n",
      "train Loss: 0.0503 Acc: 0.9953\n",
      "val Loss: 0.2828 Acc: 0.8897\n",
      "\n",
      "Epoch 195/199\n",
      "----------\n",
      "train Loss: 0.0436 Acc: 0.9983\n",
      "val Loss: 0.2662 Acc: 0.8917\n",
      "\n",
      "Epoch 196/199\n",
      "----------\n",
      "train Loss: 0.0475 Acc: 0.9980\n",
      "val Loss: 0.3130 Acc: 0.8710\n",
      "\n",
      "Epoch 197/199\n",
      "----------\n",
      "train Loss: 0.0431 Acc: 0.9993\n",
      "val Loss: 0.2795 Acc: 0.8880\n",
      "\n",
      "Epoch 198/199\n",
      "----------\n",
      "train Loss: 0.0403 Acc: 0.9997\n",
      "val Loss: 0.2852 Acc: 0.8810\n",
      "\n",
      "Epoch 199/199\n",
      "----------\n",
      "train Loss: 0.0438 Acc: 0.9987\n",
      "val Loss: 0.5127 Acc: 0.8320\n",
      "\n",
      "Training complete in 14m 11s\n",
      "Best val Acc: 0.899333\n",
      "odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'conv2.weight', 'conv3.weight', 'bn2.weight', 'bn2.bias', 'bn2.running_mean', 'bn2.running_var', 'bn2.num_batches_tracked', 'conv4.weight', 'conv5.weight', 'bn3.weight', 'bn3.bias', 'bn3.running_mean', 'bn3.running_var', 'bn3.num_batches_tracked', 'conv6.weight', 'fc1.weight', 'fc1.bias', 'bn4.weight', 'bn4.bias', 'bn4.running_mean', 'bn4.running_var', 'bn4.num_batches_tracked', 'fc2.weight', 'fc2.bias', 'bn5.weight', 'bn5.bias', 'bn5.running_mean', 'bn5.running_var', 'bn5.num_batches_tracked', 'fc3.weight', 'fc3.bias', 'bn6.weight', 'bn6.bias', 'bn6.running_mean', 'bn6.running_var', 'bn6.num_batches_tracked', 'fc4.weight', 'fc4.bias', 'bn7.weight', 'bn7.bias', 'bn7.running_mean', 'bn7.running_var', 'bn7.num_batches_tracked'])\n"
     ]
    }
   ],
   "source": [
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist, best_acc = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs)\n",
    "torch.save(model_ft.state_dict(), 'model_weight/NN_model_'+str(num_epochs))\n",
    "print(model_ft.state_dict().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train_loss', 'train_acc', 'val_loss', 'val_acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAACgCAYAAAAB6WsAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO2dd3gc1fWw37PqvcuS3HsFbLDBGAMGTDM1gVBCC6GEAAmQkEAqpH0h7ZceCElIIPTQQ2+xTS8G425s4yZbzbJ61+79/jgz2tVqV1rJWkm27vs8++zutD0zO3PPPeWeK8YYLBaLxTJ88Qy2ABaLxWIZXKwisFgslmGOVQQWi8UyzLGKwGKxWIY5VhFYLBbLMMcqAovFYhnmWEVgsVi6ICLbRGRxBNuNExEjIrEDIZclOlhFYLFECacxLRORlIBlV4rI0oDvRkRWi4gnYNlPReRfAyutZThjFYHlgEKUoXRfxwI39LBNEXDBAMhisYRkKD0wlgMEEblVRLaISJ2IrBORzwWtv0pE1gesP9RZPlpEnhCRChGpFJE/OctvF5H7A/bv5I4QkaUi8jMReQtoBCaIyOUBv/GZiHwlSIazRGSliNQ6sp4iIl8QkRVB231TRJ7ah8vxK+BmEcnsZptfAj/qjXsl4BpcLiI7RaRKRK4RkXkiskpEqt3r52zvEZHvi8h2ESkXkftEJCNg/SXOukoR+V7Qb3kC/tNKEXlURLJ7cQ0sQxyrCCzRYAtwNJAB/Ai4X0QKAUTkC8DtwKVAOnAmUCkiMcCzwHZgHDASeLgXv3kJcDWQ5hyjHDjd+Y3Lgd8GKJzDgfuAbwGZwDHANuAZYLyITA847sXAv0P9oNM4PtuDXB8CS4Gbu9nmCaAW+FIPxwrFEcBk4Hzgd8D3gMXATOA8ETnW2e5Lzus4YAKQCriKdgZwJ3oNi4AcYFTAb3wdOBs41llfBfy5D7JahirGGPuyr6i+gJXAWc7nl4AbQmxzJFABxIZYdztwf8D3cYBxt0Ub2h/3IMNT7u8CfwV+G2a7O4GfOZ9noo1eQh/PexvaKM8CaoA84EpgacA2BpgELAF2AAnAT4F/9XBs9xqMDFhWCZwf8P1x4Ebn82vAtQHrpgJtqOvqh8DDAetSgFZgsfN9PXBCwPrCgH07/Rf2tX++rEVg6XdE5FLH7VItItVoQ5jrrB6NWgzBjAa2G2Pa+/izO4NkOFVE3hWRvY4MSyKQAeBe4IsiImgP+VFjTEsfZQLAGLMGtXZu7Wab51FFcHUvD18W8LkpxPdU53MRaim5bEcb8hHOuo7rZ4xpQJWKy1jgyYD/cz3gdfa1HABYRWDpV0RkLPA34HogxxiTCawBxNlkJzAxxK47gTFh/OQNQHLA94IQ23SU0RWRBLQ3/GtghCPD8xHIgDHmXbQ3fDTwRcK4hfrAbcBVqMsrHN9HXTvJ3WzTV3ajDbrLGKAdVRwlqHIEQESSUfeQy07gVGNMZsAr0RizKwpyWgYBqwgs/U0K2ihXAIjI5ahF4PJ3NHh6mJPhM8lRHu+jDdIdIpIiIokicpSzz0rgGBEZ4wQ4v9ODDPGoi6UCaBeRU4GTAtb/A7hcRE5wAqEjRWRawPr7UP95uzHmzT5cgy4YYzYDj6D+9nDbLAVWA5f1x28G8RBwk4iMF5FU4P8BjzgW2GPA6SKyUETigR/TuW24C/iZ8z8hInkiclYUZLQMElYRWPoVY8w64DfAO2hv8yDgrYD1/wF+BjwI1KG++2xjjBc4A/WX7wCK0QAoxphX0EZ0FbACdbN0J0Md2uA+ivr4v4gGgt317+MEkFHf/TI695b/jSqvbq0BEfmuiLzQ3TZB/BhVlN3xfSAaGTn3oOezHNgKNANfAzDGrAWuQ/+TEvSaFQfs+3v0+r0sInXAu2iQ2nKAIMbYiWkslkBEJAnNOjrUGLNpsOWxWKKNtQgslq58FfjAKgHLcMHWB7FYAhCRbWhQ+exBFgURuQhNdQ1muzFm5kDLYzlwsa4hi8ViGeZY15DFYrEMc6wisFgslmHOfhcjyM3NNePGjRtsMSwWi2W/YsWKFXuMMXmh1kVNEYjIPWjRr3JjzKwQ6wXNT16CVoz8kjHmo56OO27cOD788MP+FtdisVgOaERke7h10XQN/Qs4pZv1p6JVEyej9VXujKIsFovFYglD1CwCY8xyERnXzSZnAfcZTVt6V0QyRaTQGFMSLZksQ5PmNi9tXh+xHg/rS2vJTUlgTE7ncjvtXh/bKhvZ29DKnDGZxMV4MMbQ0OqlpqmN+uZ2xuYkkxgX0y8y1TS1UdvURku7j5Z2L8ZAakIsY7KT2VXdxKbyui77FGYkMTk/ldgYD02tXrZVNuAzBo8IHhFEwCMgIgh0Wq7rOn9PTYglKS5GZWjz4TWGtMRY2r2Gdp+PtMQ4QCsIe32GNq+hzeejrd1HamIsCbF6Ldq8Pj7cVkVTWzt5qYnMGpmOGuSR09TqpbS2mbHZyXg8ofdt8/rYtqeBlnYfADEe6bgePeH1GYqrGimrbaG5zUtRZiLpSXHEejxkJet5VtS3sHNvI21eQ2FGIpUNrVQ3tna6/tML0wG9Xz4prqa2uZ0YEWI8QS8R0hJjmZCXGlKeUFQ3tlLZ0IoAY7KTw56X12eobWojJSGWstpmSmqaO+7Z3lLX3EZFXQsiwpjsZGLCXPt9ZTBjBCPpXDGy2FnWRRGIyNU4VRnHjBkzIMINJzaU1pKWGMeItAQ2lNYxOjuZjCR9+KoaWvl4ZxXb9jTyxqYKNpbW8e1TpnHY2Cween8H6Ulx1Da1sXJnNUWZSZw4YwQnz/TXhCutaabN6+OzPQ3c/+52fD5DRlIcJTXNZKXEkRwfywurS2ho9XaS6aCRGZTWNpMcH8O8cdks3VjBnnotAjp3bBYnzyzgz0s3U93Y1rFPakIs8yfkkJcWz5zRWcyfkMPexlZKqpsoqWmmrLaZGUXpHD05j1+/vJHiqiYm5KZw8fyxNLV6+edbWxERtlU2sGJ7VchrlRDr6WjoQhHjETKS4qhubMUX5czsaQVpAGwur6c96MdiPcKk/FTy0hLYWFpHeZ2/gGpBeiLJ8TFMyk/l7kvnhjz2W5v38MKaElYV11DV2MquqiZ8BvLSEjhhWj7HT8vnmCl5eH2Gl9aW8uTHu3hv615ag67N6OwkFk8fwd6GVmYVZXDW7CLy0xO59+1t3P/udnJTE6hpamNLRX3Y65oY50EQmtq8IdcHcsYhRQiwdGM5tc09F7I9enIut50xg0n5aV3WrS6u4cmPd7GupIbN5fXsqfcrnfgYDxPyUphWkMaCibmMyEhke2UDj60oZkNJHa3ezueSm5rAoql5TMpP5eL5Y0lN8De9xpgOxbxiexV/fH0Tre0+6prbWbO7BjfDPzk+huuOm8R1x03q8bx6S1THETgWwbNhYgTPAT93i3qJyGvAt40xK4K3DWTu3LkmOEbQ1tZGcXExzc3N/SX6kCUxMZFRo0YRFxfXp/237Wngox1VnDhjBO99tpe7lm3hQ6fRcxu53NR4vrRgHEs3VrBiR1XHjTgyM4nM5DjW7q4lPtZDu9eHz2jjN70wjZLqZiobWrlp8RSmFabxnw+LeXW9vypyfloC2Snx1Da1UZiZxJ76FirqWlhyUCFTR6TR0u5lUn4am8vrWLqxgjE5yVTWt/LBtr0smJjLqbMKaGrz8rPn1tPU5mXhpFyOnpxLRlIciXExvLOlko92VFHZ0MrehtYu5x7rEdp9hlinVzW1II0tFfW0tvswQHpiHKkJsWQkxXHSzBEUZSaREOshITYGj0BVYysbSusYk53MwaMyO44D4DOGHXsb2VRWT3VTK9nJ8UwpSOuwXHwGjNHtfMZgDBgMPp8uM9Cxnc8YfD61dppavSTE+WWoa24nNkbweg3vb9tLjEeYVpBOSnwMcbEeYj1CXIyH8rpmNpTUsbexldzUBM45dBSFGYlsKq/nfxvL2V7ZwJpdtXz8gxPJSokH1DJbV1LLvW9v4+mVu0mOj+HQMVnkpsYzJjuZgowk3tqyh+UbK6hraSclPgYDNLZ6GZ2dxMkzCpg1MoPkeLVE6prbeeC97azZVUtuajy7a5rxCEwvTGft7loOGZ1JjEBaYhyT81OZPCKVoswk4mM8lNQ0U9fSTlu7j93VTRhgbE4yo7OTifUIJTXN5KTEk5OagKBVDl9dV8bdyz8jLTGW46blc8K0fAoyEvEZQ7vX4DV6vdt9PnzG8GlZPXct20J2Sjyv3HRsR2+7td3HjY98zPOrS0mI9TCjKF3ly08jLy2Bdp9hU3kdm8rqWVVc3UlBzCxKZ+HkXPLTEmlsaScrJZ6s5HieXrmLVcU1lNY2Mzk/lZ+ePQuPR/jh02vZXd3EKTML2FnVyNtbKslPS2B0djJxMcL8CTmMzUmmzWtYt7uW+ROyOWVWYZ+efRFZYYwJqfkHUxH8FZ2g4yHn+0ZgUU+uoVCKYOvWraSlpZGTk9Nrk3d/whhDZWUldXV1jB8/vtf7l9c1c/af3up4IH1GG/crFo7HZwzFVU3MKEznvne3sWZXLRPyUjjzkCKOnJDDxPxUclLiafMafvLsOupb2vnWyVNJS4zFI0JKQixtXh/ffmwVT36s1Ykzk+O4dP5YRmUnkxwfw4kzRnS4KwLPqbf/2ebyeoqrGjl2Sl7IfY0xrNlVy5rdNeSnJVCQkUhRRhIZSXE8t7qENzZVcNmCccwsyqCyvoW/v7mVGBGuPnYC6Yl9U7D7G29u2sPF/3iP+684goWTc6lvaeeU3y2nuKqJWI/wteMnc82iCV3+L9CG8r2tlbywphSPwFmzRzJ3bFbY/9H9j7dU1PPUx7t4ZV0Zx03L5+aTpva7q6Op1Ut8rCfi4z6/uoRrH/iIP144hzMOKaK13ce1D3zEq+vLuGnxFC5fOK7be8IYw5aKemqa2slIig1pWQTy9pY9XP/gxx0dlRHpCRw2NotX15czPieFk2cV8JVjJpCS0P/OmqGqCE5Da9YvQSsZ/sEYc3hPxwylCNavX8+0adMOaCXgYoxhw4YNTJ8+PeT65jYvz65SXTqjMJ0ZRem8vXkPr6wv463Ne9i5t4mff/4g1uyqYdbIDE47uLCL77LN62NXVRNjc5J7fU19PsPL60rJSo5nzpgs4mPtUJWhSFVDK3N+8grfXTKNq4+ZyB9e28T/vfIpvzz3YBZNzSM/LXGwRRwQfD7DSb9bTowID189n2899gmvri/nJ2fN5JIjx0XlNyvrW1ixvYq9Da2cOquQjOS4PnWIekt3iiCa6aMPAYuAXBEpRifmiAMwxtyFThSyBNiMpo9evo+/ty+77zeEOs+PdlTxpXve54xDilizq4ZPims61h0yKoNPimtIioshPz2BP144h8UzRnD2nPDzo8TFeBiX21O15NB4PNJn09UycGSlxFOUkcja3bVUN7byt+WfcdKMEZw3d3TPOx9AeDzC146fxA0Pr2TOT14BiKoSAMhJTeCkmZ3nVhrs9iuaWUMX9rDeoDXQ93uqq6t58MEHufbaa3u135IlS3jwwQfJzMzcp9//0+ubafMaHvlgJwmxHv5y0aHMLErnyY938fhHxXzl2AnctHhKv2XUWA4MZhRlsHZ3Lf94cyv1re1846Qpgy3SoHDW7JHkpSawYnsVUwvSujTSw4H9bmTxUKS6upq//OUvXRSB1+slJiZ84/v888/3+TeNMVTUt1DT2MbrG8q5cfFkzj1sFB4RijKTALhx8RRuXDw8H25Lz8wsSuf1DWX86+1tnDKzgGkF6YMt0qCxYFIuCybl9rzhAYpVBP3ArbfeypYtW5g9ezZxcXGkpqZSWFjIypUrWbduHWeffTY7d+6kubmZG264gauv1vnJ3VHS9fX1nHrqqSxcuJC3336bkSNH8vTTT5OUlBTy97w+w6X3vM8bm/aQGOchMc7DpUeOI9vJ/rBYImFGUTo+o9k9X10UcgpnyzDhgFMEP/rvWtbtru3XY84oSue2M8KXf7/jjjtYs2YNK1euZOnSpZx22mmsWbOmI7PnnnvuITs7m6amJubNm8c555xDTk5Op2Ns2rSJhx56iL/97W+cd955PP7441x88cVdfsvnM1TUabDpmmMnsrG0lgUTc60SsPSamUVqASyclMvBo/bNPWnZvzngFMFQ4PDDD++U3vmHP/yBJ598EoCdO3eyadOmLopg/PjxzJ49G4DDDjuMbdu2dVrvMwYB9tS30O4z/OOyeRw5sfMxLJbeMDIziZtPmtJpAKBleHLAKYLueu4DRUqKP+Nm6dKlvPrqq7zzzjskJyezaNGikAPfEhISOj7HxMTQ1NQEqALYU99CeW1Lx4CopDiPVQKWfUZEuP74yYMthmUIYJO8+4G0tDTq6rrWngGoqakhKyuL5ORkNmzYwLvvvturY5fVNlNa00xqQmxHvr9b/sFisVj6gwPOIhgMcnJyOOqoo5g1axZJSUmMGDGiY90pp5zCXXfdxcEHH8zUqVOZP39+xMdtbfdRWd9KVnI8o7O1CJvPGDbWWv1tsVj6j/1uzuJwI4vDjbTdnymuaqSqsY2pI1KJDxjqf6Cer8ViiR7djSy2XcshSl1zG3sbWslJie+kBCwWi6W/sa6hIYQxhr0NWr64oq6FxLgYCtKHR80Xi8UyeFhFMEQwTvXPKmeijRgRxmSnhJ0ExGKxWPoLqwiGCCU1zVQ1tjIiPZGclHjEmVXJYrFYoo1VBEOA2qY29tS3kJuawAjrCrJYLAOMDRYPMg0t7RRXNWk8IMMqAYvFMvBYi2AQSE1NZcPOclrbfTS0tBMX69FJwYfJnAoWi2VoYRXBAOLORWsMVDW2kRQXQ3ZqAgXpCcR4rHFmsVgGB6sI+oFbbrmFsWPHdsxHcPvttyMiLF++nKqqKtra2vjBbT9i5oIT8Pp0ovIx2cm2VITFYhkSHHiK4IVboXR1/x6z4CA49Y6wqy+44AJuvPHGDkXw6KOP8uKLL3LTTTeRnp5ORUUFcw8/ghfe+piCjEQ8YusFWSyWocOBpwgGgTlz5lBeXs7u3bupqKggKyuLwsJCbrrpJpYtX44xUFZSQkxzDflFYwZbXIvFYulERIpARB4H7gFeMMb4oivSPtJNzz2anHvuuTz22GOUlpZywQUX8O9/38+O3aXc+8zrxMbGsmTBIcSLd1Bks1gslu6INEJ5J/BFYJOI3CEi06Io035Hm9fHcUvO5t77H+ThR//DCUvOYPOuclIysslLT2bX2g/ZtXMHYrOCLBbLECQiRWCMedUYcxFwKLANeEVE3haRy0UkrLNbRE4RkY0isllEbg2xPktEnhSRVSLyvojM6uuJDCZ76lrIGz2R+ro6cvMLaE/I5Kxzzuez9av43EnH8Ph/HmbaNKs7LRbL0CTiGIGI5AAXA5cAHwMPAAuBy4BFIbaPAf4MnAgUAx+IyDPGmHUBm30XWGmM+ZxjZfwZOKFvpzI4GGOobmojLTGOjevX0u710dzmI2VkBu+FmYSmvr5+gKW0WCyW8ERkEYjIE8AbQDJwhjHmTGPMI8aYrwGpYXY7HNhsjPnMGNMKPAycFbTNDOA1AGPMBmCciIxgiOPz6fSRxVWN1DW30+b1kZmshlFsjIfUxFjrBrJYLPsNkVoEfzLGvB5qRbiJDoCRwM6A78XAEUHbfAJ8HnhTRA4HxgKjgLII5RoQfMZQ3dhKakIcHoHN5fW0ejVmXtXYhkeEtESbDmqxDHvqSmHjC1BfBkd/E2L2j3Yh0mDxdBHJdL84vv1re9gnVJc4eDq0O4AsEVkJfA11ObV3OZDI1SLyoYh8WFFREaHI+47PGGqb2thcXk9xVRNb9zSwq7qJNq9hfG4KY3NSwOiYAFsp1GIZYvj6kKVXXwF/OwFK14AxsPUNaG2MfN87F8CzN8LSn8MnD/e8z3t/hedu7r2c/UykiuAqY0y1+8UYUwVc1cM+xcDogO+jgN2BGxhjao0xlxtjZgOXAnnA1uADGWPuNsbMNcbMzcvLC/lj/T3lZrvXx8bSOrZVNuD1GQoyEmlt91HT1EZeWjxpiXFkJMUxpSCVosykfv3t7tjfpha1WAaF+nL47Ux458+922/bG7DrQ3j9J7D6Mbj3dHjgXGiJIK730nehuRa+/DIUzoblv4IP74Hfzw4/yHXTK/DB36DacZ4YA2XrwNulPxxVIlUEHglwejuB4Pge9vkAmCwi40UkHrgAeCZwAxHJdNYBXAksN8bURihTB4mJiVRWVvZrI7m3sZU2r48x2clMLUgjPy2R0dlJZCTFkZ/mVAk1PhK8jcQYp+fRVBN576EPGGOorKwkMbEPVUqbquBXk+DTl/tfMMuBzXM3w78/D2/8H6x/Vu+l/sIYfYWi5BP4WZE2jN2x97POvX9j4NmboK5EG1qX5lrY9GrX3yvfAP9vFFRshLK1uuzTF+H5b0LGGNjxDjx6ie5Xvh5WPdpVhm1vwupH4ehvwJgjYNF3oHq7ylG1DR67wt82VG2DvU5/t6VO31c/ChtfhD8eCnceCSv+6Zd5ADp/kcYIXgIeFZG7UPfONcCL3e1gjGkXkeudfWOAe4wxa0XkGmf9XcB04D4R8QLrgCv6chKjRo2iuLiYXrmN2lsgNiGM7FBW20yMR4irS6AkaP3GcqCtGRr3gPFBXDIkZ0PtLohNgpRc8LYC0r2P0P2DexFYTkxMZNSoURFv38GO96ChAna+B5NPhDd/C9PPhNxJvT+WZfjQUAkf/B0SM2DLa7oscyxc+Sqk5u/bsY2Bu46GsQtgyS9VwcQkQHyyrl/7JLQ1wNon9Pl64mo47TeQnANPXw8Lb9Jn5x8nwuIfwVFf1/3WPA4bnoXkXNj1Efh8ut0TV2kD/6XnYdxRfjlKVkJrnSqNsjV6fi210FQNlzwJxSvghW/Buqfh9Z+q4pl+BsQFeAI+WwbiUZkAppwM006HpEyYfhY8+AV4+lqNG9x7BoyYBV96FlodS+P9v+v5Z42DlHz4bCkcfL5aNXMuhlN+vm/XugciVQS3AF8Bvor6/l8G/t7TTsaY54Hng5bdFfD5HWBypMKGIy4ujvHjx0e+w5b/wSNnwyVPwcTjuqx+aW0pX3lqBX+56FCOmV7oX7HiX7D8N3Dx43D/papIcibq8U76Cbz4bRh1OFz5Cty5EFLz9EYKx6u3w/t/gyOvh2NuVqWx4Tko/kBv4gXXR35OPVH8vr5XbdOA1ms/0hv6rD/1329YlAfOg5GHwaJbBluSfWfzK4DR+zh7POz8AB69VBuz1BEwbiEc++2+HXvPp1C2Wl/J2erGmboEPv9X57df1feNL4InFrYuU3dL9kTY+Jw22sk52hn74O/6HDVUwPM3w8i5cNhl8MzXoHITbF2uSgCBlQ92VgQ1xfq+8121CEYfAYdcqBbFyMOg4BB4/25VJF6dSpaytVC7W3/30qehegekj/QrBxG44AH/byy+XZ/3tU/p9WxwOq0ttdqRrNsNaUVw2TO63cYXYMvruv7dv8CERapcokREisApK3Gn89r/2fOpvm96BSYehzGGj3ZU8f7WKtbsruHFNaWMzEzixBlBmayfvgQ1O+DuY6GtES57FhJS9QZ79Xbdpr5U32t2QLMTVln5kH6e/9XOx6vcDO3NsOwOSC+EGWfBw1/0r593JcT102Q1Ox1FUL1df9c9f58P+lICu60Z3v6DnlNCWv/IeCDQ3uJvwPZn/nESjDlSG7iUfPV5ezww5ST4wr/U5dG4F3a8q/dpcnbn/Vsb4IEvwAm3qaskFFucRMTMsRpcBW0Ave1qbZeuhvRRqijqdmuPe83jer/lTYeKDXo/T10CG5/X5/Cje9UFc3ZAU/XpS7D0Dph4gj5na56EU3+hzy74FcHW5dBcA/OugMmL/fvHxMIJP1T30Kh52lHb/bHKv3WZKozqHZDZTR2xhTdBzmR48//UEqpz2omWephxtiqOw69SK2vsAlj5ALz9R7XEMkarQvvGhr49qxEQ6TiCySLymIisE5HP3FdUJBoIqrbp++ZXKalp4tTfv8E5d77DL17cwHufVfKlBeN4/KsLiIsJuDzGQPGHkD9DH/YZZ8H4o/UByZumiiEmHurK9M9trtEbrK1Z3TAv3gpv/q6zHC11UHQoxKWo77HSuaRTTtX3hjCurt0rNZC1473IztfbDrtW+M+9cpN+ri+F0k8iO0Yw65+B//0M1v+3b/sfqOz5FIwXmvYOtiR9p75cXYhv/U4b2CkndW6App4C31yvlrG3Re/FYLa9Bdvfgh1vh/+dLa9DziS46D8w7yo4/bfQUqPWq6tMT/qJvjdWwok/0eewqQpO+zWc+GOYdQ6c+0+1oB+5WJXB4tshb4oeOzFDlUBbA5z0U5h9sX5eEyBz7S59b67R9xEhChxMP0MV4BcfhaRsVQTb39J1lZt7VgQA00+Hq15XBdvi+P5b6iCtAM7+CxTN0e3GLtD3XR/CpMVw6KWajtpY2f3x94FI1cs/UWugHTgOuA/4d7SEijquItizkd8+/j+2VTbwi3MO4pPbTuLD75/ID06fodNGBgZpaoqhoRzmfhmuew8+d7cuF1EzEuCg8/TBqNjg7GT0c+VmSMiAV2+D137sD2y11EFiOmRPUDfN3i26fMx8fW8oDy3/QxfC41fAPSdpj6wnytaoohoxS5VLySpVWoj2lvrCxhf0vWSVf9mG5+CZr/szIFxW/Qf+PN/f8zqQcYONUXxoo86uj/Q9Llkt1slhXBKFB0PhIfDxfV3XbV2m7+GuQ3uLBlgnHg95U7Vhn3UOSIxaqhtfgLRCmPk5fT5S8uDwq9XdM2ERjD1KYwLn3qNW81Ffh4xRcOEjcKST2e7xqIuorUE7VyNm6LOVPxP+eyM8fZ12kmqKISvAtRxKEYioLMnZes7rnvErjoqNarH0pAhcEtI0NtDWCL42v2XikjVezx1gyimqKEAtjygRqSJIMsa8BogxZrsx5nbg+KhJFW2qtqmfEZAtr3PT4imcP29M5zkC6srgVxPVPwn+HvXIQyF3cmeXzZHXwVX/88cb3AcJYNPL2kNc8kvV7G/8Bp77hq5rqYP4VMiZAJVbVBkgMPpwXV9foTfp+39TFw5AbbLN9WwAACAASURBVInedEfdCPFp8NF9ULUdHvuyBrdCUfyBvh/0BX3f8pqaqaPm9k4RtDbCW7/XHtlmJ3AYmBa38kE1zf80T7MzXHa+CxXr4f5zw8t4oNChCPrZItjxHtx3VuRW4L6w+2N1w5z/b+2RTuqm6sucS/QeCJZr63J9bwyTYbTzfW0IJwY0I4kZ6p//4B8a7D3kQm2Az75Te+Ox8Wo1XPp01wSLo26AG1eptRKI+yy5QVwRDdLOvRw+vl8tlppdeo4JGdrbdxvecBTN1uAyqOLaukzjFJEqgsR0fa91GvaE9M7rRdQqEI9e/7QiXe66k6JApIqgWUQ8aPXR60Xkc8A+pgwMEsZA1TZqxxxPGdmcnryOLy8MEWhe9Yj2ZtxGdNcK7UWH6i3ExKmCcG+g3R/717muk4KD4cw/qj/TfUha6rR3kD1RfZ17PtVeTYaTFdRQro3r8zfD8l92PvbUJTDr85pZ8dS16jstCePm2f2xP7AHasbmToJJJ8Luj3punF3LaP0z8MoP4V9nqAmfMVobAXd9QwWMOEiDik99VTNOQG/gxEy1jB6+SHuDByrlTqpjc03fBjSFY/0zmklyz8kaoOwrlVvgpe/BHidOVLYO2lv1P/zP5ZoZs/sjyJ2qjdDFj0N8SvjjHXy+NlTPfA3amnRZ415/ByHQItj6Brxwi/7WTseSHXtU5+NNXqz31oRFcNx3ddmY+f57t7cc8RW1EgLjFMnZcNz39PO2N/X3Mseo62bSCT1n8RXO1vfsiWrNuM9zxBaBqwgcCzk+RJWeRd+Bc/6hsg4hi+BGtM7Q14HD0OJzl0VLqKjSUAFtjdy7QfiAmRwZt4m44FHBxmiwBvxupF0f6UxlYVJOAb85t9uxCOLToHSVZjzkTPJv4za8LXV6U2RPAF+73lDZEzQ4B+qrrXHcLEt/riZzyUrtKRQcpL2xtkbY/qZu45qqoA/7s04vqHaXNtpZ4/zrcyapRQCdFZeLz6um8y8nws9Hq/LY8Y6uK1utaX7zv6oPkXuN6svVN/v5u9VqeOFburyuRBXl2XeqrE9fF/4a9jebXtHGL5D21uj9XtlaNLHO9K/1U7ERcqdoD/ql7/vz0HvilR+q7xx0pOufD4d3/qSuxQ3Pa8766z/Re3btE/Dy9/VeH3loZMdPTNfMsz0b1d3SUKmDsjDaw3YVQWsDPHkNvHcXNOyBPZs0EJwY1BuefREc8VW1APqjPENSVlcrATTFO32UXgPQjJ+z/wLnRKBkCw/R93EL9Xl1n7uM0eH3CaTDInDG14ZKtsidrB090E4cDK5F4AweO88YU2+MKXZGAp9jjInAOT0EcRqtj+symHH4CcQ2lnf1Xe/+SH374tGeus+rjeXIcGWVHNw/rGKjPgT50/V77hQ1a0Hzit3eYmu93gQ56qaioUJvrLhEVRANjmtoxCxtuJf+XOXInaq51qPmqkLInqD7uzfkhuf0YXfdWnVl2qtIztHANOjx3IfddXsF8vpP1XQeu0DN4HXPaDxi0mINnB18nj+W4fb+GipUiRUcpLGUdU/redaVqgI8+Auw4Ouw+j8qU29p3Au/naUpjJHyxFV6LVy2vwM/H6XutP6mca8qvYKDnO/9GCfY86ke98w/gicGnvtmZAONti5XN53Pq52brHGw5NfaoXjkIt1m1SOw5gn9XL1DM3bcwGUkTDoBFn4DVj0Mv5mqbsq4FJhwrP8aLP+1vwdcsV7PJ9QYlrQCnVwqKSvy3+8rhYdopwb8VngkZI2DY2+BI67xP7viUWUSCa5FUOMEqXvKuouN12D4YFoExhgvcFjgyOL9mdVr1H2ycN48JsxepAuLgxqWVY9CbKI2eFXb1Hff1uDvCYQjIdUx8wykF/lvElchgPpBjVezAMDvGnJxG/WUPO1hV+/U48y7Uhvsrcv9D6mIDo653AncttSqMvjvDfq9vlSDYfWlqqRE/FZBziR92HImaQ/QGM1w8vngrT9omtuhl6mfOH8mfPKQKsexC+D8+7UXmD9DfaSlqzR+0FqvYydAA3O+drVo6kr95u34Y/TdtSJ6Q8UGPV53mSiB+HzaKw+0lEpWakB/Zze+9rYmdZNE2ut2ceMD447W9/7KHGprctx5UyFjpLoNtrzWORYVjr1bob1Jr3fZOlXe867UlMX4VM2wqS/TPPmJx2sGHGg2W29YfBtc+54Gao+8ToO4qSNUEbQ1qzKesEi3Ld+grqncKb37jf4m8HnujSIQUbfViBkBln6Rv7PXEx0WgasIwhVwDiCtcEi4hj4GnhaRS0Tk8+4ralJFkdVrVgJw8SlHa087NlHTQgMp/lB7/wUH+0fjAhREMG+O2+ClF/ob+E6KwKnd51ohCWmaO+z6CV3lkZrvtwgyRqsvNiZBsziKZgccL91xJYk2eCWrdL+pp2kAq2anumlcubLGOr/j3MAjD9M0tXfvhJ+NgN9MgVd+oKMil/xKt5m2RDOPQFPfXOKS9GEuWeXPcHLdWpnO7+xaoYrPdZu5iqgvisB9ECJtoFvrANO5Tox73cPFU0BTedc+AZ/9r3fyuemEExbpe38FjCs3A0bdbgBzLgJPHKzrZrAi6P/ujmXZukx7+vkztSE79x644ROYf63ek95WVQ4n/hhGz4/sXg8mf5ruf+KP1R2TnKO/X7VNj3/IhdoR2rpM/5ucfR5Lum+4ikA8kNpDgDgc7jMeaXwA1FsAAa6h9PDbuqQPDUWQDVSimUJnOK/ToyVUNMlp2U1VbC7xicnqgyya09ki8Hk14FdwkL/R2vC89nxzp/b8A+4NlVak2UCgPWeXROcmcH3/CWn6YGY7AetAi6B8vfbmMkZp0GjGmbquMEARgKbJJaarInB7oa7bp2SlI9cI//Lsif4BQCPnao/w9Z/qgzHuaDj9d9rrd+MhU51xDTHxXXuKI2aqqV/vjHlwyw64CsfNJnF/P2M0IH1TBG6WRU/7vvx92P623xJw67mA/7p3pwga9uh7b9xXPp8G9scfowFE6D/XUMVGfXd70ElZmqG29unu3UOB18nN9R8xU989MXoPxCZoNpknDqadpqNXr3ip+1hYpCTn6LvbicgYrRaHm3E22OVNXEWQVqiDxvpCTh8UQbBFECpYHExaQVRjBJGOLL48ahIMMCN8pexNLKLDAzlqLrx3t7/20N7PNABbMMufW7zldX0IIxnlm+Y0eOlFMPkk9Z1OCChj4SoCN9fe7Q1kT1Rfu6t8UvO1Bwf+INQx31IZQ/lvEzK04XN7oW52kxsIdi2Chd9UP73LyMP0va0RzvpL6J5g4RxVbJljul6DnInae3b9v64iyBitPS03O8S1COIS9drsi0XQ3b4NlToi09uuPWcIUgQBFkG4UdWudVNfptss+4UeK30UvPQdbUDc1EaXHe9oPOm47/qVbH+5hvZs0msZ6EKccTZsulbdQ6MOC72fazlJjCpG8CuCQBbfpvn5Kbn9I6+Lex3czkjGKFWSroU92K6htAK1YHvjFgomdYR29MKNng5FQrBrKIKR+WmF6ir2tvddaXVDREcUkX/SdS4BjDFf7neJokyubw8V8QEN6ah52nCUrtEHyg18FhzkD/60N4V+gELhNnjphfoHL76t8/qkEK4h0MEqCan+WiUpAeW23Rs1byqcFaasbmKGVip0Gx9XXlcRuD1yjwc8Ab29glnaI5l+Rnh3gMejdVPikruuy56gLijXvea6hmLitOEsdXqDgbnZWeOgqpf+d/D3iGp2hn8gKtbre9NevR7gz/kGVcCxSRpPqd7mt8ACcUd015ernMvu0PjHrM9r1gvoCNYv3OtXBisf1Cyx6WfodfLE9Z9raM9GdbUFKuFpS+C/cbDuqfCKwL3G447S2FJKfujGPiHNH+DuT1yLoOQTQLQD4MYg4pL9+fGDhYjW+HLdtX09xrXv9G6fuES1rpuqAOk+PdclrQCtUVSu17GfidQ19CzwnPN6DUgH9r+Jd40hjyoaEwIeBrdXUr1N30tXa7pn3jS9kV2zLVKfqdvghrvJO1xDwYrg7M6NfCdFEEFaWqJjETRVaUOXMUpvtt2OCyTcIJnYBLjmTXUHdcfIQ9UHHIzbS3VHOAfKnTVW4wPgvy7gKIJtnY9TuQUevKD7xtO1CHztfgskmHJXEVR1dQ21NeuD5A6QCnQPtbfA0l9oPMF1DdWX+V1Jm172D5JzM6Lc4LAxsOG/qgTiU7RxSM7xu4ZK12ga7u6V4c+tO/Zs8rubXJKydGRv6arQ+4BaBCn52tmByDsz/UWgIkgr1M6BqwhyJkatbk6vOOIrcMj5A/+7rlXguoZ7wu1g1kYnThDRP2GMeTzg9QBwHtCHaNIg01RFAm00JQaMhevI2Xd6gaWrNRYQm6B/kBv0DDWQLBSZTqPt+siD6RIsDuMfdF0ssUldC3qFPK4TI2is0kZCRBv/lhp1KwQ20MFkj+97cTu3R12yUs8tMHPCvXbJuZ2XZ43TRt0dgASa8vrpCzqRx4734NdTu+b/15X4/69wAWN3QFfj3q6KwDXFJ5+oPfZARbDldVj6/2DTSwEWQZn/f9rzqabTFs3RrB1EZQZ1CTXXwOh5/uMlZ/vr9m94Vt18r/0otMzBGKMxm7J1+rlysz+4H0jW+O4D51Xb9Fq7MaoBVwTOfdtcE2DVOopgsN1Cg43bAYy0YKOrCKIUMO6rSp4M9CI6MjTwOtq0JSlAESRlqQ/V9QuXrelsJrs++0gfommnw8VPdM4UCqQjhzggWBwKt8HLGBVZj6HDItjrfwBd11ZKngYHo0FytsYnfO1d69O7ytC9iTuWj9P36h3+ZW7P9oO/wwvf1pTXwCqexmhvaKyTtRQuTlDu1HkKtAi8rdrjdxv17Ima+heYLeb21qt3qksIVBEE1k2q2aGjsVPztRTCBmfUuOv+GhFw3yRl+62bz5aqMt7yuhZj64m6Ei23vOYxPY/25tBWYfZ4vY/CDZCr2qbbuEHR3owN6A+SAjowriJIL1I5AuNmwxE3YBxJoBiGhiIQkToRqXVfwH/ROQr2K9qrNV2rNSnATeHx6INdX6YugcABQQAj52ivN7gxC0dMXPe1WWJi1ZfspvXFh1EEbj5+pIGsxAzt/Tfu9Q/GcWUOdMv0NyL+7KiUYEUwzpGjIPTywMa8dLW6EupK/KOndwT4XptrNFYz8jDtzYdSBMb4LYKmvRoHcGmp9yuCjFGa3bPzPR3xCv6AZvUOv2vI26odg7RCv+Uz+UR9n3aayly13cmKEVUuLslZjgz1mpV2+Fc0o2zZL7rKHYxrCdWW+FMMQ7n23PhMzc6u61zFlzVeR6l+ZbnGoQaS+GR/XMm9j0Xg6qVw6CUDK8tQI9A1FAkpudphjVLmUKSuoTRjTHrAa4ox5vGoSBRF2mv0oWpPCWoYU/LUNeQ+gIFm68JvwrXv9moWsR5xA8ZxyeEzAAItgkhwg8WNlQEWgROn6KmI1r7iNpKpQe4n1zXURRE42VhuY97aqK6XuV9WF0jhbG20drzruEa2+HtC6SPV0ggMNhujcz7seFcVbFKWDiQLnFKxpdZRBE7QcuLx2tC72TRuUL16h7qG3J7aro/0P5j5OQ1+u1lW007T9w3PqkLIntA56OfGCLa/rdbSlJO1zv3WZZ0toVC4VWhrd/kf/FABQvc6hnIPVe8AjF/pFh4SPauwO9w4QaTlF4YLbqwwksFkoP/dKT/XTMQoEKlF8DkRyQj4nikiZ0dFoijic1xD3uQgRZCar64ht2eVGXDTejz9k1MdSMdN0E1vICFVe60TFkV2zIR0wOg5uBaB23hE0yKAgLEP4VxDQYogJVctoU9fBG+b9uKNTxury1+ES5/SEcx1JTrQ7Y+H6shX0N551jgN1LoDxXa8C09dA/92bskxCwDTucFtqdNrkzpC/88xR+pgwi2va8/bHeldvd0ZeOX07ut2qyJY9F24/n1/Y5ozUV0cHz/guBODYkhJTozgs6U6EHDMfC3LAVrS4YVbdSaz5hr9/Mgl/jEBboekzqk0G+oagn/syd4QU4O4pdAH2xfvdkr2JUXzQKS3FgFoYLs3aaq9INIYwW3GmI5x+saYauC2brYfkpjaEqpMKvGJSZ1XpOQ7JZ8dRRDtmzYSRQBw2X/hoHN7d8z2Zr9v1nUNRd0icEdDB1kEqSO0yuNB53VeLgLHf18b4cev8PfGCw7WYyRl+Ucwv/x9ff/Imf4irUDjMJWbtYDazve1fEFChprO4J/YI7CeUKvjGnL/27gk3W7L63630MjD9Li+9s4Ne8Yox6UXlOZ36GVQvlYtmxFB6ZfJ2XqclU69prgkVWBjFsAbv4X37tTA9O9n6+f1z/irWAa6hlyLINTI19QRalUGWkfu9qWr1b0W6K4aDJKsIgiJGyOIZFTxABCpIgi1Xf+PaogyUl9KmckiITbIRHYtguqdmvkS7akX3cyh/vydxAz/52DX0GBZBCI6n21eiF7p/GvgpJ9pGuarP1L5A0dn5k3312UaPV8n8ABVbnMvhy+/rOmx95+r2TuHXwlffASOvll94qANpMepYNlS5yiCgMJgE4/XnvOH92ijOXWJWibQOTkgnFvjoHP9RfxCWQSgDfWSX/uXH3KB1q2asEhn1mpr1EGHKXn+4niua6i1Tl1mwVlXLiKdM4d2fqBF33Z+4GS/Tek8wfpg0OEasoqgEwm9DBZHmUgVwYci8n8iMlFEJojIb4EQJSuHNp76MspNJolxQaedmu8EBtd2dgtFi0gtgr4cE/yNUP4MGHV415rv/U3RHA2G9tZ/ueB6nTCktU6tgcA4jMejo2enn6nlgUHPMd4JPo45Qi2mhDQd9zHvKp069IQf+M+/td6vDFvq1NUSOL5j1jkax9j0sqYM5wWMk8iZpC4dCN+IJaT5SwUHpxePma8ze132bOdSCgefr1MunvMP3ffWnTrocN5VKkf5em3YXWtu14ruExWyx/tdQ24lzU9fUEUQjUFivSVjlCqDgagmuj+R2AfXUBSJtFf/NeAHwCPO95eB70dFoigS21hGmZlEYbBF4PZkSz7xzzIWTdxgcX+ahYF13d2HLjEdrnyl/34jHLHxOgNbXzjhNu21h6rseuYf/J/HLNCGPZDM0XDlqxpUTQ9oLAMbnYzR6vevK9H9A91k6UXwtRUa8E0r6tx7TslXS6pmR/e92RN+qHXpgzsQORPhoke7bu9Oq+ji9vTnXaEVX1/6rlZHHXc0rH5UG/nuFGz2eJ1zwefzB9/XPqluzoKrwu83UBz9TZ2Z78AoXtx/dMQIhoZFEGmtoQbg1t4eXEROAX4PxAB/N8bcEbQ+A7gfHZMQC/zaGPPP3v5ORPh8xDWWU8Y8xnexCBzfdnvTwGQ3RNsiiGQA2lBBBI7/Xs/bfeFf+v8Ek17YWQlA5/N3XUF7Nul7cO86Js6fVhmYZZSSp3WjanZ0f0+k5qu7Z19JydX6RSuc23/cQlUE0H2MJ2u8Ko663X5F4FoIQ8EiSEzvOvmMZchZBJFmDb0iIpkB37NEpNvJbp0Jbf4MnArMAC4UkeDI1XXAOmPMIcAi4DciEmFR717SWInHtFNmskiMC44RBPjQB9I11J/+wcB6KUn7kSKIlLQRnWdY647EDHSWMPwNf+Vm/3HC7pepPTXxqDJxg7ED5dY4MmDmtsCpGbtzDbmlJyo2aHA8cAR5cADbMnToiBHsR4oAyHUyhQAwxlTR85zFhwObjTGfGWNagYeBs4K2MUCaM+lNKrAXaI9Qpt7h5KGXmywSYoNOOzDIORBBrWgEiwPdTPuTRRANPDF+ZZuUpQ9bOIsgEBENWCfn6DGmnQZzLh44t0buZA1YJ6RrTz84+ysUbmyiZJVaBNNO03NPK+yaxWUZOrgKOyVncOVwiDRG4BORMcaYHQAiMo4Q1UiDGAkEDnksBoKTYP8EPAPsBtKA841x0zb8iMjVwNUAY8b0sbKFk1YX0iJwy0wYL2QMQOWMaLiGYmI1g6WtYd+qKR4oJGfr4LLEdL3O3eXjB5I7xT9uZPYX9TWQnPknjWl4PBrDaNrbvSJIylTlte1NPd/siTrZjM87cDJbek/hwZrsMHZhz9sOAJEqgu8Bb4rIMuf7MTgNczeE6kYFK4+TgZXohDcTgVdE5A1jTG2nnYy5G7gbYO7cuRFM1BqC+BR25S5kV3FOV4vA4xRlqy8dGIsgKQoWAaiC8cRGpV75fkdHwDxDA3J1qJunpwD9ab/R8gyDRUqOv5eYVuiUuOhBeRUcDJ86ntqscf4JjCxDG3fa1iFApCUmXgTmAhvRzKFvAiEid50oBgId7qPQnn8glwNPGGUzsBUIUeu4Hxh3FC8c8kcqyCIh2CIANaNjErqv0tlfdDRS/dxzT8zQGjcWv1slMcOvcN15m7sjObtr8HmwcFNfe6o/X3CQf5xFuKq3Fks3RDoxzZXADWhjvhKYD7yD9uTD8QEwWUTGA7uAC4BgO3sHcALwhoiMAKYCIcbL9w8t7ep16mIRgI7cbG0cmBrpedPgjD/o5CL9SWIGeAd5ANFQwVW2CQGKINLCgUOFgoNUeSX3MHNYwcH+z5EG1C2WACL1IdwAzAPeNcYcJyLTgG6Lqxtj2kXkeuAlNH30HmPMWhG5xll/F/AT4F8ishp1Jd1ijNnTx3PpkZY29ZuGVATHfbdztcpoIqJTA/Y3R3/D+oZdkgMsAjc7K9qlNvqbuVdosLqnzombJpqU1TmN2GKJkEgVQbMxpllEEJEEY8wGEelxJndjzPPA80HL7gr4vBuITjm9ELS0+0iI9SCh3APuZO/7M1NOHmwJhg6dYgROXGB/UwQeD3gisPAyRqmb0VoDlj4SqSIodsYRPIUGdKvo6u8f8jS3ebtmDFkOTMYfqyWkk3P8ozf3N0UQKSJw2Jf8dX0sll4S6chid0aL20Xkf0AG8GLUpIoSrkVgGQaMPdI/m9n+GiPoDSdGOA2mxRKCXucZGmOW9bzV0MRaBMOUDkVwgFoEFss+Mqy6x9YiGKZ0pI9aRWCxhGJYjTyyFsEwZdrp0FCppaUtFksXhpUiaGn3dZ2LwHLgk1YAi24ZbCksliHLsGoVm9u8XWcns1gslmHOMFME1iKwWCyWYIZVq9jSbi0Ci8ViCWZYKYLmNh8J1iKwWCyWTgyrVlHTR61FYLFYLIEML0XQ5rUxAovFYgliWLWK1iKwWCyWrgwbReD1GVq9NmvIYrFYghk2rWJrx6Q01iKwWCyWQIaNImh2JqWxFoHFYrF0Zti0ii3WIrBYLJaQDBtFYC0Ci8ViCc2waRWb211FYC0Ci8ViCWTYKIKWNtc1NGxO2WKxWCJi2LSKfteQtQgsFoslkKgqAhE5RUQ2ishmEbk1xPpvichK57VGRLwikh0NWfzB4mGj+ywWiyUiotYqikgM8GfgVGAGcKGIzAjcxhjzK2PMbGPMbOA7wDJjzN5oyGMtAovFYglNNLvHhwObjTGfGWNagYeBs7rZ/kLgoWgJYy0Ci8ViCU00W8WRwM6A78XOsi6ISDJwCvB4tIQ5dVYBq24/iQl5qdH6CYvFYtkviaYikBDLTJhtzwDeCucWEpGrReRDEfmwoqKiT8LExnhIT4wjxhNKLIvFYhm+RFMRFAOjA76PAnaH2fYCunELGWPuNsbMNcbMzcvL60cRLRaLxRJNRfABMFlExotIPNrYPxO8kYhkAMcCT0dRFovFYrGEITZaBzbGtIvI9cBLQAxwjzFmrYhc46y/y9n0c8DLxpiGSI67YsWKPSKyvY9i5QJ7+rhvtBmqslm5esdQlQuGrmxWrt7RV7nGhlshxoRz2x94iMiHxpi5gy1HKIaqbFau3jFU5YKhK5uVq3dEQy6bS2mxWCzDHKsILBaLZZgz3BTB3YMtQDcMVdmsXL1jqMoFQ1c2K1fv6He5hlWMwGKxWCxdGW4WgcVisViCGDaKoKdKqAMox2gR+Z+IrBeRtSJyg7P8dhHZFVCNdckgyLZNRFY7v/+hsyxbRF4RkU3Oe9YgyDU14LqsFJFaEblxMK6ZiNwjIuUisiZgWdhrJCLfce65jSJy8gDL9SsR2SAiq0TkSRHJdJaPE5GmgOt2V/gjR0WusP/bQF2vbmR7JECubSKy0lk+INesm/YhuveYMeaAf6HjGLYAE4B44BNgxiDJUggc6nxOAz5Fq7PeDtw8yNdpG5AbtOyXwK3O51uBXwyB/7IUzYke8GsGHAMcCqzp6Ro5/+snQAIw3rkHYwZQrpOAWOfzLwLkGhe43SBcr5D/20Ber3CyBa3/DfDDgbxm3bQPUb3HhotF0NtKqFHDGFNijPnI+VwHrCdMMb4hwlnAvc7ne4GzB1EWgBOALcaYvg4q3CeMMcuB4JpY4a7RWcDDxpgWY8xWYDN6Lw6IXMaYl40x7c7Xd9EyLwNKmOsVjgG7Xj3JJiICnEcUKyKHkSlc+xDVe2y4KIKIK6EOJCIyDpgDvOcsut4x4+8ZDBcMWhTwZRFZISJXO8tGGGNKQG9SIH8Q5AokuC7VYF8zCH+NhtJ992XghYDv40XkYxFZJiJHD4I8of63oXS9jgbKjDGbApYN6DULah+ieo8NF0XQm0qoA4KIpKJlt280xtQCdwITgdlACWqWDjRHGWMORScTuk5EjhkEGcIiWrPqTOA/zqKhcM26Y0jcdyLyPaAdeMBZVAKMMcbMAb4BPCgi6QMoUrj/bUhcL4fg+VEG9JqFaB/CbhpiWa+v2XBRBL2phBp1RCQO/ZMfMMY8AWCMKTPGeI0xPuBvRNEkDocxZrfzXg486chQJiKFjtyFQPlAyxXAqcBHxpgyGBrXzCHcNRr0+05ELgNOBy4yjlPZcSNUOp9XoH7lKQMlUzf/26BfLwARiQU+DzziLhvIaxaqfSDK99hwUQQRVUIdCBzf4z+A9caY/wtYXhiw2eeANcH7RlmuFBFJcz+jgcY16HW6zNnsQhVZ1wAAAthJREFUMga3SmynXtpgX7MAwl2jZ4ALRCRBRMYDk4H3B0ooETkFuAU40xjTGLA8T3QqWURkgiPXZwMoV7j/bVCvVwCLgQ3GmGJ3wUBds3DtA9G+x6IdBR8qL2AJGoHfAnxvEOVYiJpuq4CVzmsJ8G9gtbP8GaBwgOWagGYffAKsda8RkAO8Bmxy3rMH6bolA5VARsCyAb9mqCIqAdrQ3tgV3V0j4HvOPbcROHWA5dqM+o/d++wuZ9tznP/4E+Aj4IwBlivs/zZQ1yucbM7yfwHXBG07INesm/YhqveYHVlssVgsw5zh4hqyWCwWSxisIrBYLJZhjlUEFovFMsyxisBisViGOVYRWCwWyzDHKgKLZQARkUUi8uxgy2GxBGIVgcVisQxzrCKwWEIgIheLyPtO7fm/ikiMiNSLyG9E5CMReU1E8pxtZ4vIu+Kv+5/lLJ8kIq+KyCfOPhOdw6eKyGOicwU84IwmtVgGDasILJYgRGQ6cD5ahG824AUuAlLQWkeHAsuA25xd7gNuMcYcjI6YdZc/APzZGHMIsAAdxQpaUfJGtJb8BOCoqJ+UxdINsYMtgMUyBDkBOAz4wOmsJ6FFvnz4C5HdDzwhIhlApjFmmbP8XuA/Tt2mkcaYJwGMMc0AzvHeN04dG2cGrHHAm9E/LYslNFYRWCxdEeBeY8x3Oi0U+UHQdt3VZ+nO3dMS8NmLfQ4tg4x1DVksXXkNOFdE8qFjvtix6PNyrrPNF4E3jTE1QFXARCWXAMuM1pAvFpGznWMkiEjygJ6FxRIhtidisQRhjFknIt9HZ2vzoNUprwMagJkisgKoQeMIoGWB73Ia+s+Ay53llwB/FZEfO8f4wgCehsUSMbb6qMUSISJSb4xJHWw5LJb+xrqGLBaLZZhjLQKLxWIZ5liLwGKxWIY5VhFYLBbLMMcqAovFYhnmWEVgsVgswxyrCCwWi2WYYxWBxWKxDHP+P7pufnIJn+zbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8993, device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(hist.keys())\n",
    "\n",
    "#### Fill in plot #####\n",
    "#Plot accuracy vs epoch\n",
    "plt.subplot(211)\n",
    "\n",
    "plt.plot(hist['train_acc'])\n",
    "plt.plot(hist['val_acc'])\n",
    "plt.title('accuracy : NN_model')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "#Plot loss vs epoch\n",
    "plt.subplot(212)\n",
    "plt.plot(hist['train_loss'])\n",
    "plt.plot(hist['val_loss'])\n",
    "plt.title('loss : NN_model')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "print(best_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load model and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'conv2.weight', 'conv3.weight', 'bn2.weight', 'bn2.bias', 'bn2.running_mean', 'bn2.running_var', 'bn2.num_batches_tracked', 'conv4.weight', 'conv5.weight', 'bn3.weight', 'bn3.bias', 'bn3.running_mean', 'bn3.running_var', 'bn3.num_batches_tracked', 'conv6.weight', 'fc1.weight', 'fc1.bias', 'bn4.weight', 'bn4.bias', 'bn4.running_mean', 'bn4.running_var', 'bn4.num_batches_tracked', 'fc2.weight', 'fc2.bias', 'bn5.weight', 'bn5.bias', 'bn5.running_mean', 'bn5.running_var', 'bn5.num_batches_tracked', 'fc3.weight', 'fc3.bias', 'bn6.weight', 'bn6.bias', 'bn6.running_mean', 'bn6.running_var', 'bn6.num_batches_tracked', 'fc4.weight', 'fc4.bias', 'bn7.weight', 'bn7.bias', 'bn7.running_mean', 'bn7.running_var', 'bn7.num_batches_tracked'])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for GoogLeNet:\n\tMissing key(s) in state_dict: \"conv1.conv.weight\", \"conv1.bn.weight\", \"conv1.bn.bias\", \"conv1.bn.running_mean\", \"conv1.bn.running_var\", \"conv2.conv.weight\", \"conv2.bn.weight\", \"conv2.bn.bias\", \"conv2.bn.running_mean\", \"conv2.bn.running_var\", \"conv3.conv.weight\", \"conv3.bn.weight\", \"conv3.bn.bias\", \"conv3.bn.running_mean\", \"conv3.bn.running_var\", \"inception3a.branch1.conv.weight\", \"inception3a.branch1.bn.weight\", \"inception3a.branch1.bn.bias\", \"inception3a.branch1.bn.running_mean\", \"inception3a.branch1.bn.running_var\", \"inception3a.branch2.0.conv.weight\", \"inception3a.branch2.0.bn.weight\", \"inception3a.branch2.0.bn.bias\", \"inception3a.branch2.0.bn.running_mean\", \"inception3a.branch2.0.bn.running_var\", \"inception3a.branch2.1.conv.weight\", \"inception3a.branch2.1.bn.weight\", \"inception3a.branch2.1.bn.bias\", \"inception3a.branch2.1.bn.running_mean\", \"inception3a.branch2.1.bn.running_var\", \"inception3a.branch3.0.conv.weight\", \"inception3a.branch3.0.bn.weight\", \"inception3a.branch3.0.bn.bias\", \"inception3a.branch3.0.bn.running_mean\", \"inception3a.branch3.0.bn.running_var\", \"inception3a.branch3.1.conv.weight\", \"inception3a.branch3.1.bn.weight\", \"inception3a.branch3.1.bn.bias\", \"inception3a.branch3.1.bn.running_mean\", \"inception3a.branch3.1.bn.running_var\", \"inception3a.branch4.1.conv.weight\", \"inception3a.branch4.1.bn.weight\", \"inception3a.branch4.1.bn.bias\", \"inception3a.branch4.1.bn.running_mean\", \"inception3a.branch4.1.bn.running_var\", \"inception3b.branch1.conv.weight\", \"inception3b.branch1.bn.weight\", \"inception3b.branch1.bn.bias\", \"inception3b.branch1.bn.running_mean\", \"inception3b.branch1.bn.running_var\", \"inception3b.branch2.0.conv.weight\", \"inception3b.branch2.0.bn.weight\", \"inception3b.branch2.0.bn.bias\", \"inception3b.branch2.0.bn.running_mean\", \"inception3b.branch2.0.bn.running_var\", \"inception3b.branch2.1.conv.weight\", \"inception3b.branch2.1.bn.weight\", \"inception3b.branch2.1.bn.bias\", \"inception3b.branch2.1.bn.running_mean\", \"inception3b.branch2.1.bn.running_var\", \"inception3b.branch3.0.conv.weight\", \"inception3b.branch3.0.bn.weight\", \"inception3b.branch3.0.bn.bias\", \"inception3b.branch3.0.bn.running_mean\", \"inception3b.branch3.0.bn.running_var\", \"inception3b.branch3.1.conv.weight\", \"inception3b.branch3.1.bn.weight\", \"inception3b.branch3.1.bn.bias\", \"inception3b.branch3.1.bn.running_mean\", \"inception3b.branch3.1.bn.running_var\", \"inception3b.branch4.1.conv.weight\", \"inception3b.branch4.1.bn.weight\", \"inception3b.branch4.1.bn.bias\", \"inception3b.branch4.1.bn.running_mean\", \"inception3b.branch4.1.bn.running_var\", \"inception4a.branch1.conv.weight\", \"inception4a.branch1.bn.weight\", \"inception4a.branch1.bn.bias\", \"inception4a.branch1.bn.running_mean\", \"inception4a.branch1.bn.running_var\", \"inception4a.branch2.0.conv.weight\", \"inception4a.branch2.0.bn.weight\", \"inception4a.branch2.0.bn.bias\", \"inception4a.branch2.0.bn.running_mean\", \"inception4a.branch2.0.bn.running_var\", \"inception4a.branch2.1.conv.weight\", \"inception4a.branch2.1.bn.weight\", \"inception4a.branch2.1.bn.bias\", \"inception4a.branch2.1.bn.running_mean\", \"inception4a.branch2.1.bn.running_var\", \"inception4a.branch3.0.conv.weight\", \"inception4a.branch3.0.bn.weight\", \"inception4a.branch3.0.bn.bias\", \"inception4a.branch3.0.bn.running_mean\", \"inception4a.branch3.0.bn.running_var\", \"inception4a.branch3.1.conv.weight\", \"inception4a.branch3.1.bn.weight\", \"inception4a.branch3.1.bn.bias\", \"inception4a.branch3.1.bn.running_mean\", \"inception4a.branch3.1.bn.running_var\", \"inception4a.branch4.1.conv.weight\", \"inception4a.branch4.1.bn.weight\", \"inception4a.branch4.1.bn.bias\", \"inception4a.branch4.1.bn.running_mean\", \"inception4a.branch4.1.bn.running_var\", \"inception4b.branch1.conv.weight\", \"inception4b.branch1.bn.weight\", \"inception4b.branch1.bn.bias\", \"inception4b.branch1.bn.running_mean\", \"inception4b.branch1.bn.running_var\", \"inception4b.branch2.0.conv.weight\", \"inception4b.branch2.0.bn.weight\", \"inception4b.branch2.0.bn.bias\", \"inception4b.branch2.0.bn.running_mean\", \"inception4b.branch2.0.bn.running_var\", \"inception4b.branch2.1.conv.weight\", \"inception4b.branch2.1.bn.weight\", \"inception4b.branch2.1.bn.bias\", \"inception4b.branch2.1.bn.running_mean\", \"inception4b.branch2.1.bn.running_var\", \"inception4b.branch3.0.conv.weight\", \"inception4b.branch3.0.bn.weight\", \"inception4b.branch3.0.bn.bias\", \"inception4b.branch3.0.bn.running_mean\", \"inception4b.branch3.0.bn.running_var\", \"inception4b.branch3.1.conv.weight\", \"inception4b.branch3.1.bn.weight\", \"inception4b.branch3.1.bn.bias\", \"inception4b.branch3.1.bn.running_mean\", \"inception4b.branch3.1.bn.running_var\", \"inception4b.branch4.1.conv.weight\", \"inception4b.branch4.1.bn.weight\", \"inception4b.branch4.1.bn.bias\", \"inception4b.branch4.1.bn.running_mean\", \"inception4b.branch4.1.bn.running_var\", \"inception4c.branch1.conv.weight\", \"inception4c.branch1.bn.weight\", \"inception4c.branch1.bn.bias\", \"inception4c.branch1.bn.running_mean\", \"inception4c.branch1.bn.running_var\", \"inception4c.branch2.0.conv.weight\", \"inception4c.branch2.0.bn.weight\", \"inception4c.branch2.0.bn.bias\", \"inception4c.branch2.0.bn.running_mean\", \"inception4c.branch2.0.bn.running_var\", \"inception4c.branch2.1.conv.weight\", \"inception4c.branch2.1.bn.weight\", \"inception4c.branch2.1.bn.bias\", \"inception4c.branch2.1.bn.running_mean\", \"inception4c.branch2.1.bn.running_var\", \"inception4c.branch3.0.conv.weight\", \"inception4c.branch3.0.bn.weight\", \"inception4c.branch3.0.bn.bias\", \"inception4c.branch3.0.bn.running_mean\", \"inception4c.branch3.0.bn.running_var\", \"inception4c.branch3.1.conv.weight\", \"inception4c.branch3.1.bn.weight\", \"inception4c.branch3.1.bn.bias\", \"inception4c.branch3.1.bn.running_mean\", \"inception4c.branch3.1.bn.running_var\", \"inception4c.branch4.1.conv.weight\", \"inception4c.branch4.1.bn.weight\", \"inception4c.branch4.1.bn.bias\", \"inception4c.branch4.1.bn.running_mean\", \"inception4c.branch4.1.bn.running_var\", \"inception4d.branch1.conv.weight\", \"inception4d.branch1.bn.weight\", \"inception4d.branch1.bn.bias\", \"inception4d.branch1.bn.running_mean\", \"inception4d.branch1.bn.running_var\", \"inception4d.branch2.0.conv.weight\", \"inception4d.branch2.0.bn.weight\", \"inception4d.branch2.0.bn.bias\", \"inception4d.branch2.0.bn.running_mean\", \"inception4d.branch2.0.bn.running_var\", \"inception4d.branch2.1.conv.weight\", \"inception4d.branch2.1.bn.weight\", \"inception4d.branch2.1.bn.bias\", \"inception4d.branch2.1.bn.running_mean\", \"inception4d.branch2.1.bn.running_var\", \"inception4d.branch3.0.conv.weight\", \"inception4d.branch3.0.bn.weight\", \"inception4d.branch3.0.bn.bias\", \"inception4d.branch3.0.bn.running_mean\", \"inception4d.branch3.0.bn.running_var\", \"inception4d.branch3.1.conv.weight\", \"inception4d.branch3.1.bn.weight\", \"inception4d.branch3.1.bn.bias\", \"inception4d.branch3.1.bn.running_mean\", \"inception4d.branch3.1.bn.running_var\", \"inception4d.branch4.1.conv.weight\", \"inception4d.branch4.1.bn.weight\", \"inception4d.branch4.1.bn.bias\", \"inception4d.branch4.1.bn.running_mean\", \"inception4d.branch4.1.bn.running_var\", \"inception4e.branch1.conv.weight\", \"inception4e.branch1.bn.weight\", \"inception4e.branch1.bn.bias\", \"inception4e.branch1.bn.running_mean\", \"inception4e.branch1.bn.running_var\", \"inception4e.branch2.0.conv.weight\", \"inception4e.branch2.0.bn.weight\", \"inception4e.branch2.0.bn.bias\", \"inception4e.branch2.0.bn.running_mean\", \"inception4e.branch2.0.bn.running_var\", \"inception4e.branch2.1.conv.weight\", \"inception4e.branch2.1.bn.weight\", \"inception4e.branch2.1.bn.bias\", \"inception4e.branch2.1.bn.running_mean\", \"inception4e.branch2.1.bn.running_var\", \"inception4e.branch3.0.conv.weight\", \"inception4e.branch3.0.bn.weight\", \"inception4e.branch3.0.bn.bias\", \"inception4e.branch3.0.bn.running_mean\", \"inception4e.branch3.0.bn.running_var\", \"inception4e.branch3.1.conv.weight\", \"inception4e.branch3.1.bn.weight\", \"inception4e.branch3.1.bn.bias\", \"inception4e.branch3.1.bn.running_mean\", \"inception4e.branch3.1.bn.running_var\", \"inception4e.branch4.1.conv.weight\", \"inception4e.branch4.1.bn.weight\", \"inception4e.branch4.1.bn.bias\", \"inception4e.branch4.1.bn.running_mean\", \"inception4e.branch4.1.bn.running_var\", \"inception5a.branch1.conv.weight\", \"inception5a.branch1.bn.weight\", \"inception5a.branch1.bn.bias\", \"inception5a.branch1.bn.running_mean\", \"inception5a.branch1.bn.running_var\", \"inception5a.branch2.0.conv.weight\", \"inception5a.branch2.0.bn.weight\", \"inception5a.branch2.0.bn.bias\", \"inception5a.branch2.0.bn.running_mean\", \"inception5a.branch2.0.bn.running_var\", \"inception5a.branch2.1.conv.weight\", \"inception5a.branch2.1.bn.weight\", \"inception5a.branch2.1.bn.bias\", \"inception5a.branch2.1.bn.running_mean\", \"inception5a.branch2.1.bn.running_var\", \"inception5a.branch3.0.conv.weight\", \"inception5a.branch3.0.bn.weight\", \"inception5a.branch3.0.bn.bias\", \"inception5a.branch3.0.bn.running_mean\", \"inception5a.branch3.0.bn.running_var\", \"inception5a.branch3.1.conv.weight\", \"inception5a.branch3.1.bn.weight\", \"inception5a.branch3.1.bn.bias\", \"inception5a.branch3.1.bn.running_mean\", \"inception5a.branch3.1.bn.running_var\", \"inception5a.branch4.1.conv.weight\", \"inception5a.branch4.1.bn.weight\", \"inception5a.branch4.1.bn.bias\", \"inception5a.branch4.1.bn.running_mean\", \"inception5a.branch4.1.bn.running_var\", \"inception5b.branch1.conv.weight\", \"inception5b.branch1.bn.weight\", \"inception5b.branch1.bn.bias\", \"inception5b.branch1.bn.running_mean\", \"inception5b.branch1.bn.running_var\", \"inception5b.branch2.0.conv.weight\", \"inception5b.branch2.0.bn.weight\", \"inception5b.branch2.0.bn.bias\", \"inception5b.branch2.0.bn.running_mean\", \"inception5b.branch2.0.bn.running_var\", \"inception5b.branch2.1.conv.weight\", \"inception5b.branch2.1.bn.weight\", \"inception5b.branch2.1.bn.bias\", \"inception5b.branch2.1.bn.running_mean\", \"inception5b.branch2.1.bn.running_var\", \"inception5b.branch3.0.conv.weight\", \"inception5b.branch3.0.bn.weight\", \"inception5b.branch3.0.bn.bias\", \"inception5b.branch3.0.bn.running_mean\", \"inception5b.branch3.0.bn.running_var\", \"inception5b.branch3.1.conv.weight\", \"inception5b.branch3.1.bn.weight\", \"inception5b.branch3.1.bn.bias\", \"inception5b.branch3.1.bn.running_mean\", \"inception5b.branch3.1.bn.running_var\", \"inception5b.branch4.1.conv.weight\", \"inception5b.branch4.1.bn.weight\", \"inception5b.branch4.1.bn.bias\", \"inception5b.branch4.1.bn.running_mean\", \"inception5b.branch4.1.bn.running_var\", \"fc.weight\", \"fc.bias\". \n\tUnexpected key(s) in state_dict: \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"bn1.num_batches_tracked\", \"bn2.weight\", \"bn2.bias\", \"bn2.running_mean\", \"bn2.running_var\", \"bn2.num_batches_tracked\", \"conv4.weight\", \"conv5.weight\", \"bn3.weight\", \"bn3.bias\", \"bn3.running_mean\", \"bn3.running_var\", \"bn3.num_batches_tracked\", \"conv6.weight\", \"fc1.weight\", \"fc1.bias\", \"bn4.weight\", \"bn4.bias\", \"bn4.running_mean\", \"bn4.running_var\", \"bn4.num_batches_tracked\", \"fc2.weight\", \"fc2.bias\", \"bn5.weight\", \"bn5.bias\", \"bn5.running_mean\", \"bn5.running_var\", \"bn5.num_batches_tracked\", \"fc3.weight\", \"fc3.bias\", \"bn6.weight\", \"bn6.bias\", \"bn6.running_mean\", \"bn6.running_var\", \"bn6.num_batches_tracked\", \"fc4.weight\", \"fc4.bias\", \"bn7.weight\", \"bn7.bias\", \"bn7.running_mean\", \"bn7.running_var\", \"bn7.num_batches_tracked\", \"conv1.weight\", \"conv2.weight\", \"conv3.weight\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3fcb3cfc0a1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mvis_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvis_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mvis_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_vis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvis_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvis_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvis_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'outputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-3fcb3cfc0a1f>\u001b[0m in \u001b[0;36mforward_vis\u001b[0;34m(vis_loader, groups)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_weight/NN_model_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_weight/NN_model_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# Set model to evaluate mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 839\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    840\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for GoogLeNet:\n\tMissing key(s) in state_dict: \"conv1.conv.weight\", \"conv1.bn.weight\", \"conv1.bn.bias\", \"conv1.bn.running_mean\", \"conv1.bn.running_var\", \"conv2.conv.weight\", \"conv2.bn.weight\", \"conv2.bn.bias\", \"conv2.bn.running_mean\", \"conv2.bn.running_var\", \"conv3.conv.weight\", \"conv3.bn.weight\", \"conv3.bn.bias\", \"conv3.bn.running_mean\", \"conv3.bn.running_var\", \"inception3a.branch1.conv.weight\", \"inception3a.branch1.bn.weight\", \"inception3a.branch1.bn.bias\", \"inception3a.branch1.bn.running_mean\", \"inception3a.branch1.bn.running_var\", \"inception3a.branch2.0.conv.weight\", \"inception3a.branch2.0.bn.weight\", \"inception3a.branch2.0.bn.bias\", \"inception3a.branch2.0.bn.running_mean\", \"inception3a.branch2.0.bn.running_var\", \"inception3a.branch2.1.conv.weight\", \"inception3a.branch2.1.bn.weight\", \"inception3a.branch2.1.bn.bias\", \"inception3a.branch2.1.bn.running_mean\", \"inception3a.branch2.1.bn.running_var\", \"inception3a.branch3.0.conv.weight\", \"inception3a.branch3.0.bn.weight\", \"inception3a.branch3.0.bn.bias\", \"inception3a.branch3.0.bn.running_mean\", \"inception3a.branch3.0.bn.running_var\", \"inception3a.branch3.1.conv.weight\", \"inception3a.branch3.1.bn.weight\", \"inception3a.branch3.1.bn.bias\", \"inception3a.branch3.1.bn.running_mean\", \"inception3a.branch3.1.bn.running_var\", \"inception3a.branch4.1.conv.weight\", \"inception3a.branch4.1.bn.weight\", \"inception3a.branch4.1.bn.bias\", \"inception3a.branch4.1.bn.running_mean\", \"inception3a.branch4.1.bn.running_var\", \"inception3b.branch1.conv.weight\", \"inception3b.branch1.bn.weight\", \"inception3b.branch1.bn.bias\", \"inception3b.branch1.bn.running_mean\", \"inception3b.branch1.bn.running_var\", \"inception3b.branch2.0.conv.weight\", \"inception3b.branch2.0.bn.weight\", \"inception3b.branch2.0.bn.bias\", \"inception3b.branch2.0.bn.running_mean\", \"inception3b.branch2.0.bn.running_var\", \"inception3b.branch2.1.conv.weight\", \"inception3b.branch2.1.bn.weight\", \"inception3b.branch2.1.bn.bias\", \"inception3b.branch2.1.bn.running_mean\", \"inception3b.branch2.1.bn.running_var\", \"inception3b.branch3.0.conv.weight\", \"inception3b.branch3.0.bn.weight\", \"inception3b.branch3.0.bn.bias\", \"inception3b.branch3.0.bn.running_mean\", \"inception3b.branch3.0.bn.running_var\", \"inception3b.branch3.1.conv.weight\", \"inception3b.branch3.1.bn.weight\", \"inception3b.branch3.1.bn.bias\", \"inception3b.branch3.1.bn.running_mean\", \"inception3b.branch3.1.bn.running_var\", \"inception3b.branch4.1.conv.weight\", \"inception3b.branch4.1.bn.weight\", \"inception3b.branch4.1.bn.bias\", \"inception3b.branch4.1.bn.running_mean\", \"inception3b.branch4.1.bn.running_var\", \"inception4a.branch1.conv.weight\", \"inception4a.branch1.bn.weight\", \"inception4a.branch1.bn.bias\", \"inception4a.branch1.bn.running_mean\", \"inception4a.branch1.bn.running_var\", \"inception4a.branch2.0.conv.weight\", \"inception4a.branch2.0.bn.weight\", \"inception4a.branch2.0.bn.bias\", \"inception4a.branch2.0.bn.running_mean\", \"inception4a.branch2.0.bn.running_var\", \"inception4a.branch2.1.conv.weight\", \"inception4a.branch2.1.bn.weight\", \"inception4a.branch2.1.bn.bias\", \"inception4a.branch2.1.bn.running_mean\", \"inception4a.branch2.1.bn.running_var\", \"inception4a.branch3.0.conv.weight\", \"inception4a.branch3.0.bn.weight\", \"inception4a.branch3.0.bn.bias\", \"inception4a.branch3.0.bn.running_mean\", \"inception4a.branch3.0.bn.running_var\", \"inception4a.branch3.1.conv.weight\", \"inception4a.branch3.1.bn.weight\", \"inception4a.branch3.1.bn.bias\", \"inception4a.branch3.1.bn.running_mean\", \"inception4a.branch3.1.bn.running_var\", \"inception4a.branch4.1.conv.weight\", \"inception4a.branch4.1.bn.weight\", \"inception4a.branch4.1.bn.bias\", \"inception4a.branch4.1.bn.running_mean\", \"inception4a.branch4.1.bn.running_var\", \"inception4b.branch1.conv.weight\", \"inception4b.branch1.bn.weight\", \"inception4b.branch1.bn.bias\", \"inception4b.branch1.bn.running_mean\", \"inception4b.branch1.bn.running_var\", \"inception4b.branch2.0.conv.weight\", \"inception4b.branch2.0.bn.weight\", \"inception4b.branch2.0.bn.bias\", \"inception4b.branch2.0.bn.running_mean\", \"inception4b.branch2.0.bn.running_var\", \"inception4b.branch2.1.conv.weight\", \"inception4b.branch2.1.bn.weight\", \"inception4b.branch2.1.bn.bias\", \"inception4b.branch2.1.bn.running_mean\", \"inception4b.branch2.1.bn.running_var\", \"inception4b.branch3.0.conv.weight\", \"inception4b.branch3.0.bn.weight\", \"inception4b.branch3.0.bn.bias\", \"inception4b.branch3.0.bn.running_mean\", \"inception4b.branch3.0.bn.running_var\", \"inception4b.branch3.1.conv.weight\", \"inception4b.branch3.1.bn.weight\", \"inception4b.branch3.1.bn.bias\", \"inception4b.branch3.1.bn.running_mean\", \"inception4b.branch3.1.bn.running_var\", \"inception4b.branch4.1.conv.weight\", \"inception4b.branch4.1.bn.weight\", \"inception4b.branch4.1.bn.bias\", \"inception4b.branch4.1.bn.running_mean\", \"inception4b.branch4.1.bn.running_var\", \"inception4c.branch1.conv.weight\", \"inception4c.branch1.bn.weight\", \"inception4c.branch1.bn.bias\", \"inception4c.branch1.bn.running_mean\", \"inception4c.branch1.bn.running_var\", \"inception4c.branch2.0.conv.weight\", \"inception4c.branch2.0.bn.weight\", \"inception4c.branch2.0.bn.bias\", \"inception4c.branch2.0.bn.running_mean\", \"inception4c.branch2.0.bn.running_var\", \"inception4c.branch2.1.conv.weight\", \"inception4c.branch2.1.bn.weight\", \"inception4c.branch2.1.bn.bias\", \"inception4c.branch2.1.bn.running_mean\", \"inception4c.branch2.1.bn.running_var\", \"inception4c.branch3.0.conv.weight\", \"inception4c.branch3.0.bn.weight\", \"inception4c.branch3.0.bn.bias\", \"inception4c.branch3.0.bn.running_mean\", \"inception4c.branch3.0.bn.running_var\", \"inception4c.branch3.1.conv.weight\", \"inception4c.branch3.1.bn.weight\", \"inception4c.branch3.1.bn.bias\", \"inception4c.branch3.1.bn.running_mean\", \"inception4c.branch3.1.bn.running_var\", \"inception4c.branch4.1.conv.weight\", \"inception4c.branch4.1.bn.weight\", \"inception4c.branch4.1.bn.bias\", \"inception4c.branch4.1.bn.running_mean\", \"inception4c.branch4.1.bn.running_var\", \"inception4d.branch1.conv.weight\", \"inception4d.branch1.bn.weight\", \"inception4d.branch1.bn.bias\", \"inception4d.branch1.bn.running_mean\", \"inception4d.branch1.bn.running_var\", \"inception4d.branch2.0.conv.weight\", \"inception4d.branch2.0.bn.weight\", \"inception4d.branch2.0.bn.bias\", \"inception4d.branch2.0.bn.running_mean\", \"inception4d.branch2.0.bn.running_var\", \"inception4d.branch2.1.conv.weight\", \"inception4d.branch2.1.bn.weight\", \"inception4d.branch2.1.bn.bias\", \"inception4d.branch2.1.bn.running_mean\", \"inception4d.branch2.1.bn.running_var\", \"inception4d.branch3.0.conv.weight\", \"inception4d.branch3.0.bn.weight\", \"inception4d.branch3.0.bn.bias\", \"inception4d.branch3.0.bn.running_mean\", \"inception4d.branch3.0.bn.running_var\", \"inception4d.branch3.1.conv.weight\", \"inception4d.branch3.1.bn.weight\", \"inception4d.branch3.1.bn.bias\", \"inception4d.branch3.1.bn.running_mean\", \"inception4d.branch3.1.bn.running_var\", \"inception4d.branch4.1.conv.weight\", \"inception4d.branch4.1.bn.weight\", \"inception4d.branch4.1.bn.bias\", \"inception4d.branch4.1.bn.running_mean\", \"inception4d.branch4.1.bn.running_var\", \"inception4e.branch1.conv.weight\", \"inception4e.branch1.bn.weight\", \"inception4e.branch1.bn.bias\", \"inception4e.branch1.bn.running_mean\", \"inception4e.branch1.bn.running_var\", \"inception4e.branch2.0.conv.weight\", \"inception4e.branch2.0.bn.weight\", \"inception4e.branch2.0.bn.bias\", \"inception4e.branch2.0.bn.running_mean\", \"inception4e.branch2.0.bn.running_var\", \"inception4e.branch2.1.conv.weight\", \"inception4e.branch2.1.bn.weight\", \"inception4e.branch2.1.bn.bias\", \"inception4e.branch2.1.bn.running_mean\", \"inception4e.branch2.1.bn.running_var\", \"inception4e.branch3.0.conv.weight\", \"inception4e.branch3.0.bn.weight\", \"inception4e.branch3.0.bn.bias\", \"inception4e.branch3.0.bn.running_mean\", \"inception4e.branch3.0.bn.running_var\", \"inception4e.branch3.1.conv.weight\", \"inception4e.branch3.1.bn.weight\", \"inception4e.branch3.1.bn.bias\", \"inception4e.branch3.1.bn.running_mean\", \"inception4e.branch3.1.bn.running_var\", \"inception4e.branch4.1.conv.weight\", \"inception4e.branch4.1.bn.weight\", \"inception4e.branch4.1.bn.bias\", \"inception4e.branch4.1.bn.running_mean\", \"inception4e.branch4.1.bn.running_var\", \"inception5a.branch1.conv.weight\", \"inception5a.branch1.bn.weight\", \"inception5a.branch1.bn.bias\", \"inception5a.branch1.bn.running_mean\", \"inception5a.branch1.bn.running_var\", \"inception5a.branch2.0.conv.weight\", \"inception5a.branch2.0.bn.weight\", \"inception5a.branch2.0.bn.bias\", \"inception5a.branch2.0.bn.running_mean\", \"inception5a.branch2.0.bn.running_var\", \"inception5a.branch2.1.conv.weight\", \"inception5a.branch2.1.bn.weight\", \"inception5a.branch2.1.bn.bias\", \"inception5a.branch2.1.bn.running_mean\", \"inception5a.branch2.1.bn.running_var\", \"inception5a.branch3.0.conv.weight\", \"inception5a.branch3.0.bn.weight\", \"inception5a.branch3.0.bn.bias\", \"inception5a.branch3.0.bn.running_mean\", \"inception5a.branch3.0.bn.running_var\", \"inception5a.branch3.1.conv.weight\", \"inception5a.branch3.1.bn.weight\", \"inception5a.branch3.1.bn.bias\", \"inception5a.branch3.1.bn.running_mean\", \"inception5a.branch3.1.bn.running_var\", \"inception5a.branch4.1.conv.weight\", \"inception5a.branch4.1.bn.weight\", \"inception5a.branch4.1.bn.bias\", \"inception5a.branch4.1.bn.running_mean\", \"inception5a.branch4.1.bn.running_var\", \"inception5b.branch1.conv.weight\", \"inception5b.branch1.bn.weight\", \"inception5b.branch1.bn.bias\", \"inception5b.branch1.bn.running_mean\", \"inception5b.branch1.bn.running_var\", \"inception5b.branch2.0.conv.weight\", \"inception5b.branch2.0.bn.weight\", \"inception5b.branch2.0.bn.bias\", \"inception5b.branch2.0.bn.running_mean\", \"inception5b.branch2.0.bn.running_var\", \"inception5b.branch2.1.conv.weight\", \"inception5b.branch2.1.bn.weight\", \"inception5b.branch2.1.bn.bias\", \"inception5b.branch2.1.bn.running_mean\", \"inception5b.branch2.1.bn.running_var\", \"inception5b.branch3.0.conv.weight\", \"inception5b.branch3.0.bn.weight\", \"inception5b.branch3.0.bn.bias\", \"inception5b.branch3.0.bn.running_mean\", \"inception5b.branch3.0.bn.running_var\", \"inception5b.branch3.1.conv.weight\", \"inception5b.branch3.1.bn.weight\", \"inception5b.branch3.1.bn.bias\", \"inception5b.branch3.1.bn.running_mean\", \"inception5b.branch3.1.bn.running_var\", \"inception5b.branch4.1.conv.weight\", \"inception5b.branch4.1.bn.weight\", \"inception5b.branch4.1.bn.bias\", \"inception5b.branch4.1.bn.running_mean\", \"inception5b.branch4.1.bn.running_var\", \"fc.weight\", \"fc.bias\". \n\tUnexpected key(s) in state_dict: \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"bn1.num_batches_tracked\", \"bn2.weight\", \"bn2.bias\", \"bn2.running_mean\", \"bn2.running_var\", \"bn2.num_batches_tracked\", \"conv4.weight\", \"conv5.weight\", \"bn3.weight\", \"bn3.bias\", \"bn3.running_mean\", \"bn3.running_var\", \"bn3.num_batches_tracked\", \"conv6.weight\", \"fc1.weight\", \"fc1.bias\", \"bn4.weight\", \"bn4.bias\", \"bn4.running_mean\", \"bn4.running_var\", \"bn4.num_batches_tracked\", \"fc2.weight\", \"fc2.bias\", \"bn5.weight\", \"bn5.bias\", \"bn5.running_mean\", \"bn5.running_var\", \"bn5.num_batches_tracked\", \"fc3.weight\", \"fc3.bias\", \"bn6.weight\", \"bn6.bias\", \"bn6.running_mean\", \"bn6.running_var\", \"bn6.num_batches_tracked\", \"fc4.weight\", \"fc4.bias\", \"bn7.weight\", \"bn7.bias\", \"bn7.running_mean\", \"bn7.running_var\", \"bn7.num_batches_tracked\", \"conv1.weight\", \"conv2.weight\", \"conv3.weight\". "
     ]
    }
   ],
   "source": [
    "def forward_vis(vis_loader, groups):\n",
    "    since = time.time()\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    model = models.googlenet(aux_logits=False)\n",
    "    set_parameter_requires_grad(model, feature_extract)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    # load best model weights\n",
    "    state_dict = torch.load('model_weight/NN_model_'+str(num_epochs))\n",
    "    print(state_dict.keys())\n",
    "    model.load_state_dict(torch.load('model_weight/NN_model_'+str(num_epochs)))\n",
    "    model.to(device)\n",
    "    model.eval()   # Set model to evaluate mode\n",
    "    # Iterate over data.\n",
    "    cnt=0\n",
    "    vis_dict = {'inputs':np.empty([groups,vis_batch,3,224,224]),'outputs':np.empty([groups,vis_batch,num_classes]),'labels':np.empty([groups,vis_batch]),'preds':np.empty([groups,vis_batch])}\n",
    "    for inputs, labels in vis_loader:\n",
    "            if(cnt==groups):\n",
    "                break;\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            vis_dict['inputs'][cnt,:,:,:,:]=inputs.cpu().numpy()\n",
    "            vis_dict['labels'][cnt,:]=labels.cpu().numpy()\n",
    "            # forward\n",
    "            # track history if only in train\n",
    "            with torch.set_grad_enabled(False):\n",
    "            # Get model outputs and calculate loss\n",
    "            # Special case for inception because in training it has an auxiliary output. In train\n",
    "            #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "            #   but in testing we only consider the final output.\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                vis_dict['outputs'][cnt,:,:]=outputs.cpu().numpy()\n",
    "                vis_dict['preds'][cnt,:]=preds.cpu().numpy()\n",
    "            cnt+=1\n",
    "            \n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print()\n",
    "    print('Inference complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    return vis_dict\n",
    "\n",
    "vis_loader = torch.utils.data.DataLoader(image_datasets['val'], batch_size=vis_batch, shuffle=True, num_workers=8)\n",
    "vis_dict = forward_vis(vis_loader, groups)\n",
    "print(vis_dict['inputs'].shape)\n",
    "print(vis_dict['outputs'].shape)\n",
    "print(vis_dict['labels'].shape)\n",
    "print(vis_dict['preds'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(groups) :\n",
    "    for j in range(vis_batch) :\n",
    "        plt.figure(figsize=(15,15))\n",
    "        plt.subplot(groups,vis_batch,4*i+j+1)\n",
    "        image = np.moveaxis(np.squeeze(vis_dict['inputs'][i,j]), 0, -1)\n",
    "        image = (image-np.amin(image))/(np.amax(image)-np.amin(image))\n",
    "        plt.imshow(image)\n",
    "        plt.tick_params(\n",
    "        axis='both',          # changes apply to the x-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        bottom=False,      # ticks along the bottom edge are off\n",
    "        left=False,         # ticks along the left edge are off\n",
    "        labelbottom=False,\n",
    "        labelleft=False) # labels along the bottom edge are off\n",
    "        plt.title('preprocessed '+str(i)+' '+str(j))\n",
    "        plt.xlabel('label : '+str(vis_dict['labels'][i,j])+', pred : '+str(vis_dict['preds'][i,j])+', output : '+str(vis_dict['outputs'][i,j,:]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
